{"train_micro_batch_size_per_gpu": 128, "train_batch_size": 5120, "steps_per_print": 100000, "gradient_accumulation_steps": 1, "fp16": {"enabled": false}, "optimizer": {"type": "AdamW", "params": {"lr": 0.0001, "weight_decay": 0.01, "torch_adam": true, "adam_w_mode": true}}, "comms_logger": {"enabled": true, "verbose": false}, "zero_optimization": {"stage": 0}}