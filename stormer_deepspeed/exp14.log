/home/shourya01/.bashrc: line 163: bind: warning: line editing not enabled
/home/shourya01/.bashrc: line 164: bind: warning: line editing not enabled
/home/shourya01/.bashrc: line 163: bind: warning: line editing not enabled
/home/shourya01/.bashrc: line 164: bind: warning: line editing not enabled

Lmod is automatically replacing "nvhpc/23.9" with "gcc-native/12.3".


Lmod is automatically replacing "PrgEnv-nvhpc/8.5.0" with "PrgEnv-gnu/8.5.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-mpich/8.1.28

declare -x APP2_STATE="23.12.0"
declare -x BASH_ENV="/usr/share/lmod/lmod/init/bash"
declare -x C3_RSH="ssh -oConnectTimeout=10 -oForwardX11=no"
declare -x CFLAGS="-I/soft/applications/conda/2024-04-29/mconda3/include"
declare -x COLORTERM="1"
declare -x COMPILER_PATH="/soft/xalt/3.0.2-202408282050/bin"
declare -x CONDA_DEFAULT_ENV="base"
declare -x CONDA_EXE="/soft/applications/conda/2024-04-29/mconda3/bin/conda"
declare -x CONDA_PREFIX="/soft/applications/conda/2024-04-29/mconda3"
declare -x CONDA_PROMPT_MODIFIER="(2024-04-29/base) "
declare -x CONDA_PYTHON_EXE="/soft/applications/conda/2024-04-29/mconda3/bin/python"
declare -x CONDA_SHLVL="1"
declare -x CPU="x86_64"
declare -x CRAYPAT_LD_LIBRARY_PATH="/opt/cray/pe/perftools/23.12.0/lib64"
declare -x CRAYPAT_OPTS_EXECUTABLE="libexec64/opts"
declare -x CRAYPAT_ROOT="/opt/cray/pe/perftools/23.12.0"
declare -x CRAYPE_DIR="/opt/cray/pe/craype/2.7.30"
declare -x CRAYPE_NETWORK_TARGET="ofi"
declare -x CRAYPE_VERSION="2.7.30"
declare -x CRAY_CPU_TARGET="x86-milan"
declare -x CRAY_DSMML_BASEDIR="/opt/cray/pe/dsmml/0.2.2"
declare -x CRAY_DSMML_DIR="/opt/cray/pe/dsmml/0.2.2/dsmml"
declare -x CRAY_DSMML_PREFIX="/opt/cray/pe/dsmml/0.2.2/dsmml"
declare -x CRAY_DSMML_ROOTDIR="/opt/cray/pe/dsmml/0.2.2"
declare -x CRAY_DSMML_VER="0.2.2"
declare -x CRAY_DSMML_VERSION="0.2.2"
declare -x CRAY_HDF5_PARALLEL_DIR="/opt/cray/pe/hdf5-parallel/1.12.2.9"
declare -x CRAY_HDF5_PARALLEL_PREFIX="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3"
declare -x CRAY_HDF5_PARALLEL_VERSION="1.12.2.9"
declare -x CRAY_LD_LIBRARY_PATH="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3/lib:/opt/cray/pe/pmi/6.1.13/lib:/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib:/opt/cray/pe/mpich/8.1.28/gtl/lib:/opt/cray/pe/dsmml/0.2.2/dsmml/lib:/opt/cray/pe/perftools/23.12.0/lib64"
declare -x CRAY_LMOD_COMPILER="gnu/12.0"
declare -x CRAY_LMOD_CPU="x86-milan/1.0"
declare -x CRAY_LMOD_MPI="cray-mpich/8.0"
declare -x CRAY_LMOD_NET="ofi/1.0"
declare -x CRAY_MPICH_BASEDIR="/opt/cray/pe/mpich/8.1.28/ofi"
declare -x CRAY_MPICH_DIR="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3"
declare -x CRAY_MPICH_PREFIX="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3"
declare -x CRAY_MPICH_ROOTDIR="/opt/cray/pe/mpich/8.1.28"
declare -x CRAY_MPICH_VER="8.1.28"
declare -x CRAY_MPICH_VERSION="8.1.28"
declare -x CRAY_PERFTOOLS_PREFIX="/opt/cray/pe/perftools/23.12.0"
declare -x CRAY_PERFTOOLS_VERSION="23.12.0"
declare -x CRAY_PMI_INCLUDE_OPTS="-I/opt/cray/pe/pmi/6.1.13/include"
declare -x CRAY_PMI_POST_LINK_OPTS="-L/opt/cray/pe/pmi/6.1.13/lib"
declare -x CRAY_PMI_PREFIX="/opt/cray/pe/pmi/6.1.13"
declare -x CRAY_PMI_VERSION="6.1.13"
declare -x CSHEDIT="emacs"
declare -x CUDA_HOME="/soft/compilers/cudatoolkit/cuda-12.4.1/"
declare -x CUDA_PATH="/soft/compilers/cudatoolkit/cuda-12.4.1/"
declare -x CUDA_TOOLKIT_BASE="/soft/compilers/cudatoolkit/cuda-12.4.1/"
declare -x CUDNN_HOME="/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/"
declare -x ENVIRONMENT="BATCH"
declare -x ENV_NAME="conda/2024-04-29"
declare -x FROM_HEADER=""
declare -x GCC_PATH="/usr/bin"
declare -x GCC_PREFIX="/usr/lib64/gcc/x86_64-suse-linux/12"
declare -x GCC_VERSION="12.3"
declare -x GNU_VERSION="12.3"
declare -x GPG_TTY="not a tty"
declare -x GSETTINGS_SCHEMA_DIR="/soft/applications/conda/2024-04-29/mconda3/share/glib-2.0/schemas"
declare -x GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=""
declare -x G_BROKEN_FILENAMES="1"
declare -x G_FILENAME_ENCODING="@locale,UTF-8,ISO-8859-15,CP1252"
declare -x HDF5_DIR="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3"
declare -x HDF5_ROOT="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3"
declare -x HISTSIZE="1000"
declare -x HOME="/home/shourya01"
declare -x HOST="x3204c0s31b1n0"
declare -x HOSTNAME="x3204c0s31b1n0"
declare -x HOSTTYPE="x86_64"
declare -x HTTPS_PROXY="http://proxy.alcf.anl.gov:3128"
declare -x HTTP_PROXY="http://proxy.alcf.anl.gov:3128"
declare -x LANG="en_US.UTF-8"
declare -x LANGUAGE="en_US.UTF-8"
declare -x LDFLAGS="-L/soft/applications/conda/2024-04-29/mconda3/lib -Wl,--enable-new-dtags,-rpath,/soft/applications/conda/2024-04-29/mconda3/lib"
declare -x LD_LIBRARY_PATH="/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:/soft/perftools/darshan/darshan-3.4.4/lib:/opt/cray/pe/papi/7.0.1.2/lib64:/opt/cray/libfabric/1.15.2.0/lib64"
declare -x LD_PRELOAD="/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so"
declare -x LESS="-M -I -R"
declare -x LESSCLOSE="lessclose.sh %s %s"
declare -x LESSKEY="/etc/lesskey.bin"
declare -x LESSOPEN="lessopen.sh %s"
declare -x LESS_ADVANCED_PREPROCESSOR="no"
declare -x LMOD_CMD="/usr/share/lmod/lmod/libexec/lmod"
declare -x LMOD_DIR="/usr/share/lmod/lmod/libexec"
declare -x LMOD_FAMILY_COMPILER="gcc-native"
declare -x LMOD_FAMILY_COMPILER_VERSION="12.3"
declare -x LMOD_FAMILY_CRAYPE="craype"
declare -x LMOD_FAMILY_CRAYPE_CPU="craype-x86-milan"
declare -x LMOD_FAMILY_CRAYPE_CPU_VERSION="false"
declare -x LMOD_FAMILY_CRAYPE_NETWORK="craype-network-ofi"
declare -x LMOD_FAMILY_CRAYPE_NETWORK_VERSION="false"
declare -x LMOD_FAMILY_CRAYPE_VERSION="2.7.30"
declare -x LMOD_FAMILY_GCC_COMPILER="gcc-native"
declare -x LMOD_FAMILY_GCC_COMPILER_VERSION="12.3"
declare -x LMOD_FAMILY_HDF5="cray-hdf5-parallel"
declare -x LMOD_FAMILY_HDF5_VERSION="1.12.2.9"
declare -x LMOD_FAMILY_MPI="cray-mpich"
declare -x LMOD_FAMILY_MPI_VERSION="8.1.28"
declare -x LMOD_FAMILY_PRGENV="PrgEnv-gnu"
declare -x LMOD_FAMILY_PRGENV_VERSION="8.5.0"
declare -x LMOD_FAMILY_PYTHON="conda"
declare -x LMOD_FAMILY_PYTHON_VERSION="2024-04-29"
declare -x LMOD_PKG="/usr/share/lmod/lmod"
declare -x LMOD_ROOT="/usr/share/lmod"
declare -x LMOD_SETTARG_FULL_SUPPORT="no"
declare -x LMOD_SYSTEM_DEFAULT_MODULES="PrgEnv-nvhpc:craype-network-ofi:perftools-base:darshan:xalt"
declare -x LMOD_VERSION="8.7.34"
declare -x LMOD_sys="Linux"
declare -x LOADEDMODULES="libfabric/1.15.2.0:craype-network-ofi:perftools-base/23.12.0:darshan/3.4.4:xalt/3.0.2-202408282050:gcc-native/12.3:craype/2.7.30:cray-dsmml/0.2.2:cray-mpich/8.1.28:cray-pmi/6.1.13:cray-pals/1.3.4:cray-libpals/1.3.4:craype-x86-milan:PrgEnv-gnu/8.5.0:cray-hdf5-parallel/1.12.2.9:cudnn/9.1.0:conda/2024-04-29"
declare -x LOGNAME="shourya01"
declare -x MACHTYPE="x86_64-suse-linux"
declare -x MAIL="/var/spool/mail/shourya01"
declare -x MANPATH="/opt/cray/pals/1.3.4/man:/opt/cray/pe/pmi/6.1.13/man:/opt/cray/pe/mpich/8.1.28/ofi/man:/opt/cray/pe/mpich/8.1.28/man/mpich:/opt/cray/pe/dsmml/0.2.2/dsmml/man:/opt/cray/pe/craype/2.7.30/man:/opt/cray/pe/perftools/23.12.0/man:/opt/cray/pe/papi/7.0.1.2/share/pdoc/man:/opt/cray/libfabric/1.15.2.0/share/man:/usr/share/lmod/lmod/share/man:/home/shourya01/.local/man:/usr/local/man:/usr/share/man:/usr/man:/opt/c3/man:/opt/pbs/share/man:/opt/clmgr/man:/opt/sgi/share/man:/opt/clmgr/share/man:/opt/clmgr/lib/cm-cli/man"
declare -x MINICOM="-c on"
declare -x MODULEPATH="/opt/cray/pe/lmod/modulefiles/hdf5-parallel/gnu/12.0/ofi/1.0/cray-mpich/8.0/cray-hdf5-parallel/1.12.2:/opt/cray/pe/lmod/modulefiles/cpu/x86-milan/1.0:/opt/cray/pe/lmod/modulefiles/mpi/gnu/12.0/ofi/1.0/cray-mpich/8.0:/opt/cray/pe/lmod/modulefiles/comnet/gnu/12.0/ofi/1.0:/opt/cray/pe/lmod/modulefiles/mix_compilers:/opt/cray/pe/lmod/modulefiles/compiler/gnu/12.0:/soft/modulefiles:/opt/cray/pe/lmod/modulefiles/perftools/23.12.0:/opt/cray/pe/lmod/modulefiles/net/ofi/1.0:/usr/share/modulefiles/Linux:/usr/share/modulefiles/Core:/usr/share/lmod/lmod/modulefiles/Core:/usr/share/lmod/lmod/modulefiles:/opt/cray/pals/lmod/modulefiles/core:/opt/cray/modulefiles:/opt/cray/pe/lmod/modulefiles/core:/opt/cray/pe/lmod/modulefiles/craype-targets/default:/soft/perftools/darshan/darshan-3.4.4/share/craype-2.x/modulefiles:/soft/xalt/modulefiles"
declare -x MODULEPATH_ROOT="/usr/share/modulefiles"
declare -x MODULESHOME="/usr/share/lmod/lmod"
declare -x MORE="-sl"
declare -x MPI4JAX_USE_CUDA_MPI="1"
declare -x MPICH_DIR="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3"
declare -x MPICH_GPU_SUPPORT_ENABLED="1"
declare -x NCCL_IB_DISABLE="1"
declare -x NCCL_SOCKET_IFNAME="hsn"
declare -x NCPUS="64"
declare -x OFFLOAD_INIT="on_start"
declare -x OLDPWD
declare -x OMP_NUM_THREADS="4"
declare -x OSCAR_HOME="/opt/oscar"
declare -x OSTYPE="linux"
declare -x PAGER="less"
declare -x PALS_TRANSFER="0"
declare -x PATH="/soft/applications/conda/2024-04-29/mconda3/bin:/soft/applications/conda/2024-04-29/mconda3/condabin:/soft/xalt/3.0.2-202408282050/bin:/soft/compilers/cudatoolkit/cuda-12.4.1/bin:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/include:/opt/cray/pe/hdf5-parallel/1.12.2.9/bin:/opt/cray/pe/hdf5/1.12.2.9/bin:/opt/cray/pals/1.3.4/bin:/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/bin:/opt/cray/pe/mpich/8.1.28/bin:/opt/cray/pe/craype/2.7.30/bin:/home/shourya01/.local/bin:/soft/perftools/darshan/darshan-3.4.4/bin:/opt/cray/pe/perftools/23.12.0/bin:/opt/cray/pe/papi/7.0.1.2/bin:/opt/cray/libfabric/1.15.2.0/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/bin:/opt/c3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/pbs/bin:/sbin:/home/shourya01/bin:/opt/cray/pe/bin"
declare -x PAT_RT_PERFCTR_DISABLE_COMPONENTS="nvml,rocm_smi"
declare -x PBS_ACCOUNT="ParaLLMs"
declare -x PBS_ENVIRONMENT="PBS_BATCH"
declare -x PBS_JOBCOOKIE="799BEDD91E9EE7264F57B58A7B64432C"
declare -x PBS_JOBDIR="/home/shourya01"
declare -x PBS_JOBID="5238714.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov"
declare -x PBS_JOBNAME="illi-tfm-parallel-redo"
declare -x PBS_MOMPORT="15003"
declare -x PBS_NODEFILE="/var/spool/pbs/aux/5238714.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov"
declare -x PBS_NODENUM="0"
declare -x PBS_O_HOME="/home/shourya01"
declare -x PBS_O_HOST="polaris-login-04.hsn.cm.polaris.alcf.anl.gov"
declare -x PBS_O_INTERACTIVE_AUTH_METHOD="resvport"
declare -x PBS_O_LANG="en_US.UTF-8"
declare -x PBS_O_LOGNAME="shourya01"
declare -x PBS_O_MAIL="/var/spool/mail/shourya01"
declare -x PBS_O_PATH="/home/shourya01/.local/bin:/home/shourya01/.vscode-server/cli/servers/Stable-dfaf44141ea9deb3b4096f7cd6d24e00c147a4b1/server/bin/remote-cli:/home/shourya01/.local/bin:/home/shourya01/.local/bin:/home/shourya01/.local/bin:/home/shourya01/.local/bin:/soft/xalt/3.0.2-202408282050/bin:/soft/perftools/darshan/darshan-3.4.4/bin:/opt/cray/pe/perftools/23.12.0/bin:/opt/cray/pe/papi/7.0.1.2/bin:/opt/cray/libfabric/1.15.2.0/bin:/opt/cray/pals/1.3.4/bin:/opt/cray/pe/mpich/8.1.28/ofi/nvidia/23.3/bin:/opt/cray/pe/mpich/8.1.28/bin:/opt/cray/pe/craype/2.7.30/bin:/opt/nvidia/hpc_sdk/Linux_x86_64/23.9/compilers/extras/qd/bin:/opt/nvidia/hpc_sdk/Linux_x86_64/23.9/compilers/bin:/opt/nvidia/hpc_sdk/Linux_x86_64/23.9/cuda/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/home/shourya01/.local/bin:/usr/local/bin:/usr/bin:/bin:/opt/c3/bin:/dbhome/db2cat/sqllib/bin:/dbhome/db2cat/sqllib/adm:/dbhome/db2cat/sqllib/misc:/dbhome/db2cat/sqllib/gskit/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/pbs/bin:/sbin:/opt/cray/pe/bin:/home/shourya01/.local/bin:/home/shourya01/bin:/home/shourya01/.local/bin:/home/shourya01/bin:/home/shourya01/.vscode-server/extensions/ms-python.debugpy-2025.8.0/bundled/scripts/noConfigScripts"
declare -x PBS_O_QUEUE="prod"
declare -x PBS_O_SHELL="/bin/bash"
declare -x PBS_O_SYSTEM="Linux"
declare -x PBS_O_WORKDIR="/home/shourya01"
declare -x PBS_QUEUE="small"
declare -x PBS_TASKNUM="1"
declare -x PELOCAL_PRGENV="true"
declare -x PERFTOOLS_VERSION="23.12.0"
declare -x PE_DSMML_MODULE_NAME="cray-dsmml"
declare -x PE_DSMML_PKGCONFIG_LIBS="dsmml"
declare -x PE_ENV="GNU"
declare -x PE_FORTRAN_PKGCONFIG_LIBS="hdf5hl_fortran_parallel:hdf5_fortran_parallel:mpichf90"
declare -x PE_GCC_EXTERNAL="native"
declare -x PE_GCC_LEVEL="12"
declare -x PE_GNU_FIXED_PKGCONFIG_PATH="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib/pkgconfig"
declare -x PE_HDF5_PARALLEL_DIR="/opt/cray/pe/hdf5-parallel/1.12.2.9"
declare -x PE_HDF5_PARALLEL_FORTRAN_PKGCONFIG_LIBS="hdf5hl_fortran_parallel:hdf5_fortran_parallel"
declare -x PE_HDF5_PARALLEL_PKGCONFIG_LIBS="hdf5_hl_parallel:hdf5_parallel"
declare -x PE_MPICH_FIXED_PRGENV="GNU"
declare -x PE_MPICH_FORTRAN_PKGCONFIG_LIBS="mpichf90"
declare -x PE_MPICH_GENCOMPILERS_GNU="12.3"
declare -x PE_MPICH_GTL_DIR_amd_gfx906="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_amd_gfx908="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_amd_gfx90a="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_amd_gfx940="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_amd_gfx942="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_nvidia70="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_nvidia80="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_nvidia90="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_ponteVecchio="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_LIBS_amd_gfx906="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_amd_gfx908="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_amd_gfx90a="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_amd_gfx940="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_amd_gfx942="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_nvidia70="-lmpi_gtl_cuda"
declare -x PE_MPICH_GTL_LIBS_nvidia80="-lmpi_gtl_cuda"
declare -x PE_MPICH_GTL_LIBS_nvidia90="-lmpi_gtl_cuda"
declare -x PE_MPICH_GTL_LIBS_ponteVecchio="-lmpi_gtl_ze"
declare -x PE_MPICH_MODULE_NAME="cray-mpich"
declare -x PE_MPICH_PKGCONFIG_LIBS="mpich"
declare -x PE_MPICH_PKGCONFIG_VARIABLES="PE_MPICH_GTL_DIR_@accelerator@:PE_MPICH_GTL_LIBS_@accelerator@"
declare -x PE_PALS_PKGCONFIG_LIBS="libpals"
declare -x PE_PERFTOOLS_MPICH_LIBDIR="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib"
declare -x PE_PKGCONFIG_LIBS="hdf5_hl_parallel:hdf5_parallel:mpich:dsmml:darshan-runtime"
declare -x PE_PKGCONFIG_PRODUCTS="PE_PALS:PE_PMI:PE_MPICH:PE_DSMML"
declare -x PE_PMI_PKGCONFIG_LIBS="cray-pmi"
declare -x PE_PRODUCT_LIST="CRAYPE_X86_MILAN"
declare -x PKGCONFIG_ENABLED="1"
declare -x PKG_CONFIG_PATH="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3/lib/pkgconfig:/opt/cray/pals/1.3.4/lib/pkgconfig:/opt/cray/pe/pmi/6.1.13/lib/pkgconfig:/opt/cray/pe/dsmml/0.2.2/dsmml/lib/pkgconfig:/opt/cray/pe/craype/2.7.30/pkg-config:/soft/perftools/darshan/darshan-3.4.4/lib/pkgconfig:/opt/cray/libfabric/1.15.2.0/lib64/pkgconfig"
declare -x PROFILEREAD="true"
declare -x PWD="/home/shourya01"
declare -x PYTHONPATH="/soft/xalt/3.0.2-202408282050/site_packages"
declare -x PYTHONUSERBASE="/home/shourya01/.local/polaris/conda/2024-04-29"
declare -x QT_SYSTEM_DIR="/usr/share/desktop-data"
declare -x SHELL="/bin/bash"
declare -x SHLVL="2"
declare -x SLURM_MPI_TYPE="cray_shasta"
declare -x STARSHIP_SESSION_KEY="7211990823202279"
declare -x STARSHIP_SHELL="bash"
declare -x TMPDIR="/var/tmp/pbs.5238714.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov"
declare -x TRITON_DISABLE_AUTOTUNE="1"
declare -x TZ="Etc/UTC"
declare -x USER="shourya01"
declare -x USE_PCM_DB="2"
declare -x WINDOWMANAGER="xterm"
declare -x XALT_DIR="/soft/xalt/3.0.2-202408282050"
declare -x XALT_EXECUTABLE_TRACKING="yes"
declare -x XALT_SAMPLING="no"
declare -x XALT_SCALAR_AND_SPSR_SAMPLING="yes"
declare -x XCURSOR_THEME="DMZ"
declare -x XDG_CONFIG_DIRS="/etc/xdg"
declare -x XDG_DATA_DIRS="/usr/share"
declare -x XKEYSYMDB="/usr/X11R6/lib/X11/XKeysymDB"
declare -x XLA_FLAGS="--xla_gpu_force_compilation_parallelism=1 --xla_gpu_cuda_data_dir=/soft/compilers/cudatoolkit/cuda-12.4.1/"
declare -x XLA_PYTHON_CLIENT_PREALLOCATE="false"
declare -x XML_CATALOG_FILES="file:///soft/applications/conda/2024-04-29/mconda3/etc/xml/catalog file:///etc/xml/catalog"
declare -x XNLSPATH="/usr/X11R6/lib/X11/nls"
declare -x _CE_CONDA=""
declare -x _CE_M=""
declare -x _LMFILES_="/opt/cray/modulefiles/libfabric/1.15.2.0:/opt/cray/pe/lmod/modulefiles/craype-targets/default/craype-network-ofi.lua:/opt/cray/pe/lmod/modulefiles/core/perftools-base/23.12.0.lua:/soft/perftools/darshan/darshan-3.4.4/share/craype-2.x/modulefiles/darshan/3.4.4:/soft/xalt/modulefiles/xalt/3.0.2-202408282050:/opt/cray/pe/lmod/modulefiles/core/gcc-native/12.3.lua:/opt/cray/pe/lmod/modulefiles/core/craype/2.7.30.lua:/opt/cray/pe/lmod/modulefiles/core/cray-dsmml/0.2.2.lua:/opt/cray/pe/lmod/modulefiles/comnet/gnu/12.0/ofi/1.0/cray-mpich/8.1.28.lua:/opt/cray/pe/lmod/modulefiles/core/cray-pmi/6.1.13.lua:/opt/cray/pals/lmod/modulefiles/core/cray-pals/1.3.4.lua:/opt/cray/pals/lmod/modulefiles/core/cray-libpals/1.3.4.lua:/opt/cray/pe/lmod/modulefiles/craype-targets/default/craype-x86-milan.lua:/opt/cray/pe/lmod/modulefiles/core/PrgEnv-gnu/8.5.0.lua:/opt/cray/pe/lmod/modulefiles/mpi/gnu/12.0/ofi/1.0/cray-mpich/8.0/cray-hdf5-parallel/1.12.2.9.lua:/soft/modulefiles/cudnn/9.1.0.lua:/soft/modulefiles/conda/2024-04-29.lua"
declare -x _ModuleTable001_="X01vZHVsZVRhYmxlXyA9IHsKTVR2ZXJzaW9uID0gMywKY19yZWJ1aWxkVGltZSA9IGZhbHNlLApjX3Nob3J0VGltZSA9IGZhbHNlLApkZXB0aFQgPSB7fSwKZmFtaWx5ID0gewpQcmdFbnYgPSAiUHJnRW52LWdudSIsCmNvbXBpbGVyID0gImdjYy1uYXRpdmUiLApjcmF5cGUgPSAiY3JheXBlIiwKY3JheXBlX2NwdSA9ICJjcmF5cGUteDg2LW1pbGFuIiwKY3JheXBlX25ldHdvcmsgPSAiY3JheXBlLW5ldHdvcmstb2ZpIiwKZ2NjX2NvbXBpbGVyID0gImdjYy1uYXRpdmUiLApoZGY1ID0gImNyYXktaGRmNS1wYXJhbGxlbCIsCm1waSA9ICJjcmF5LW1waWNoIiwKcHl0aG9uID0gImNvbmRhIiwKfSwKbVQgPSB7ClsiUHJnRW52LWdudSJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUv"
declare -x _ModuleTable002_="bG1vZC9tb2R1bGVmaWxlcy9jb3JlL1ByZ0Vudi1nbnUvOC41LjAubHVhIiwKZnVsbE5hbWUgPSAiUHJnRW52LWdudS84LjUuMCIsCmxvYWRPcmRlciA9IDE0LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gIlByZ0Vudi1nbnUiLAp3ViA9ICJeMDAwMDAwMDguMDAwMDAwMDA1Lip6ZmluYWwiLAp9LApjb25kYSA9IHsKZm4gPSAiL3NvZnQvbW9kdWxlZmlsZXMvY29uZGEvMjAyNC0wNC0yOS5sdWEiLApmdWxsTmFtZSA9ICJjb25kYS8yMDI0LTA0LTI5IiwKbG9hZE9yZGVyID0gMTcsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAwLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiY29uZGEiLAp3ViA9ICJeMDAw"
declare -x _ModuleTable003_="MDIwMjQuKnpmaW5hbC0uMDAwMDAwMDA0Lip6ZmluYWwtLjAwMDAwMDAyOS4qemZpbmFsIiwKfSwKWyJjcmF5LWRzbW1sIl0gPSB7CmZuID0gIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL2NvcmUvY3JheS1kc21tbC8wLjIuMi5sdWEiLApmdWxsTmFtZSA9ICJjcmF5LWRzbW1sLzAuMi4yIiwKbG9hZE9yZGVyID0gOCwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDIsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJjcmF5LWRzbW1sIiwKd1YgPSAiXjAwMDAwMDAwLjAwMDAwMDAwMi4wMDAwMDAwMDIuKnpmaW5hbCIsCn0sClsiY3JheS1oZGY1LXBhcmFsbGVsIl0gPSB7CmZuID0gIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL21waS9nbnUvMTIuMC9v"
declare -x _ModuleTable004_="ZmkvMS4wL2NyYXktbXBpY2gvOC4wL2NyYXktaGRmNS1wYXJhbGxlbC8xLjEyLjIuOS5sdWEiLApmdWxsTmFtZSA9ICJjcmF5LWhkZjUtcGFyYWxsZWwvMS4xMi4yLjkiLApsb2FkT3JkZXIgPSAxNSwKcHJvcFQgPSB7fSwKcmVmX2NvdW50ID0gMSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJjcmF5LWhkZjUtcGFyYWxsZWwvMS4xMi4yLjkiLAp3ViA9ICJeMDAwMDAwMDEuMDAwMDAwMDEyLjAwMDAwMDAwMi4wMDAwMDAwMDkuKnpmaW5hbCIsCn0sClsiY3JheS1saWJwYWxzIl0gPSB7CmZuID0gIi9vcHQvY3JheS9wYWxzL2xtb2QvbW9kdWxlZmlsZXMvY29yZS9jcmF5LWxpYnBhbHMvMS4zLjQubHVhIiwKZnVsbE5hbWUgPSAiY3JheS1s"
declare -x _ModuleTable005_="aWJwYWxzLzEuMy40IiwKbG9hZE9yZGVyID0gMTIsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAyLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiY3JheS1saWJwYWxzIiwKd1YgPSAiXjAwMDAwMDAxLjAwMDAwMDAwMy4wMDAwMDAwMDQuKnpmaW5hbCIsCn0sClsiY3JheS1tcGljaCJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jb21uZXQvZ251LzEyLjAvb2ZpLzEuMC9jcmF5LW1waWNoLzguMS4yOC5sdWEiLApmdWxsTmFtZSA9ICJjcmF5LW1waWNoLzguMS4yOCIsCmxvYWRPcmRlciA9IDksCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAyLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiY3JheS1tcGljaCIsCndWID0gIl4w"
declare -x _ModuleTable006_="MDAwMDAwOC4wMDAwMDAwMDEuMDAwMDAwMDI4Lip6ZmluYWwiLAp9LApbImNyYXktcGFscyJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGFscy9sbW9kL21vZHVsZWZpbGVzL2NvcmUvY3JheS1wYWxzLzEuMy40Lmx1YSIsCmZ1bGxOYW1lID0gImNyYXktcGFscy8xLjMuNCIsCmxvYWRPcmRlciA9IDExLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXktcGFscyIsCndWID0gIl4wMDAwMDAwMS4wMDAwMDAwMDMuMDAwMDAwMDA0Lip6ZmluYWwiLAp9LApbImNyYXktcG1pIl0gPSB7CmZuID0gIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL2NvcmUvY3JheS1wbWkvNi4xLjEzLmx1YSIsCmZ1bGxOYW1lID0gImNy"
declare -x _ModuleTable007_="YXktcG1pLzYuMS4xMyIsCmxvYWRPcmRlciA9IDEwLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXktcG1pIiwKd1YgPSAiXjAwMDAwMDA2LjAwMDAwMDAwMS4wMDAwMDAwMTMuKnpmaW5hbCIsCn0sCmNyYXlwZSA9IHsKZm4gPSAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY29yZS9jcmF5cGUvMi43LjMwLmx1YSIsCmZ1bGxOYW1lID0gImNyYXlwZS8yLjcuMzAiLApsb2FkT3JkZXIgPSA3LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXlwZSIsCndWID0gIl4wMDAwMDAwMi4wMDAwMDAwMDcuMDAwMDAwMDMwLip6ZmluYWwiLAp9LApb"
declare -x _ModuleTable008_="ImNyYXlwZS1uZXR3b3JrLW9maSJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jcmF5cGUtdGFyZ2V0cy9kZWZhdWx0L2NyYXlwZS1uZXR3b3JrLW9maS5sdWEiLApmdWxsTmFtZSA9ICJjcmF5cGUtbmV0d29yay1vZmkiLApsb2FkT3JkZXIgPSAyLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMCwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXlwZS1uZXR3b3JrLW9maSIsCndWID0gIk0uKnpmaW5hbCIsCn0sClsiY3JheXBlLXg4Ni1taWxhbiJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jcmF5cGUtdGFyZ2V0cy9kZWZhdWx0L2NyYXlwZS14ODYtbWlsYW4ubHVhIiwKZnVsbE5hbWUgPSAiY3JheXBl"
declare -x _ModuleTable009_="LXg4Ni1taWxhbiIsCmxvYWRPcmRlciA9IDEzLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXlwZS14ODYtbWlsYW4iLAp3ViA9ICJNLip6ZmluYWwiLAp9LApjdWRubiA9IHsKZm4gPSAiL3NvZnQvbW9kdWxlZmlsZXMvY3Vkbm4vOS4xLjAubHVhIiwKZnVsbE5hbWUgPSAiY3Vkbm4vOS4xLjAiLApsb2FkT3JkZXIgPSAxNiwKcHJvcFQgPSB7fSwKcmVmX2NvdW50ID0gMSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJjdWRubi85LjEuMCIsCndWID0gIjAwMDAwMDAwOS4wMDAwMDAwMDEuKnpmaW5hbCIsCn0sCmRhcnNoYW4gPSB7CmZuID0gIi9zb2Z0L3BlcmZ0b29scy9k"
declare -x _ModuleTable010_="YXJzaGFuL2RhcnNoYW4tMy40LjQvc2hhcmUvY3JheXBlLTIueC9tb2R1bGVmaWxlcy9kYXJzaGFuLzMuNC40IiwKZnVsbE5hbWUgPSAiZGFyc2hhbi8zLjQuNCIsCmxvYWRPcmRlciA9IDQsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAwLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiZGFyc2hhbiIsCndWID0gIjAwMDAwMDAwMy4wMDAwMDAwMDQuMDAwMDAwMDA0Lip6ZmluYWwiLAp9LApbImdjYy1uYXRpdmUiXSA9IHsKZm4gPSAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY29yZS9nY2MtbmF0aXZlLzEyLjMubHVhIiwKZnVsbE5hbWUgPSAiZ2NjLW5hdGl2ZS8xMi4zIiwKbG9hZE9yZGVyID0gNiwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDIsCnN0"
declare -x _ModuleTable011_="YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJnY2MtbmF0aXZlIiwKd1YgPSAiXjAwMDAwMDEyLjAwMDAwMDAwMy4qemZpbmFsIiwKfSwKbGliZmFicmljID0gewpmbiA9ICIvb3B0L2NyYXkvbW9kdWxlZmlsZXMvbGliZmFicmljLzEuMTUuMi4wIiwKZnVsbE5hbWUgPSAibGliZmFicmljLzEuMTUuMi4wIiwKbG9hZE9yZGVyID0gMSwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJsaWJmYWJyaWMiLAp3ViA9ICJeMDAwMDAwMDEuMDAwMDAwMDE1LjAwMDAwMDAwMi4qemZpbmFsIiwKfSwKWyJwZXJmdG9vbHMtYmFzZSJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jb3JlL3BlcmZ0b29s"
declare -x _ModuleTable012_="cy1iYXNlLzIzLjEyLjAubHVhIiwKZnVsbE5hbWUgPSAicGVyZnRvb2xzLWJhc2UvMjMuMTIuMCIsCmxvYWRPcmRlciA9IDMsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAwLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAicGVyZnRvb2xzLWJhc2UiLAp3ViA9ICJeMDAwMDAwMjMuMDAwMDAwMDEyLip6ZmluYWwiLAp9LAp4YWx0ID0gewpmbiA9ICIvc29mdC94YWx0L21vZHVsZWZpbGVzL3hhbHQvMy4wLjItMjAyNDA4MjgyMDUwIiwKZnVsbE5hbWUgPSAieGFsdC8zLjAuMi0yMDI0MDgyODIwNTAiLApsb2FkT3JkZXIgPSA1LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMCwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gInhhbHQiLAp3ViA9ICJeMDAwMDAw"
declare -x _ModuleTable013_="MDMuMDAwMDAwMDAwLjAwMDAwMDAwMi4qemZpbmFsLS4yMDI0MDgyODIwNTAuKnpmaW5hbCIsCn0sCn0sCm1wYXRoQSA9IHsKCiIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9oZGY1LXBhcmFsbGVsL2dudS8xMi4wL29maS8xLjAvY3JheS1tcGljaC84LjAvY3JheS1oZGY1LXBhcmFsbGVsLzEuMTIuMiIKLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY3B1L3g4Ni1taWxhbi8xLjAiCiwgIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL21waS9nbnUvMTIuMC9vZmkvMS4wL2NyYXktbXBpY2gvOC4wIgosICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jb21uZXQvZ251LzEyLjAvb2ZpLzEuMCIKLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxl"
declare -x _ModuleTable014_="ZmlsZXMvbWl4X2NvbXBpbGVycyIKLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY29tcGlsZXIvZ251LzEyLjAiLCAiL3NvZnQvbW9kdWxlZmlsZXMiCiwgIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL3BlcmZ0b29scy8yMy4xMi4wIgosICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9uZXQvb2ZpLzEuMCIsICIvdXNyL3NoYXJlL21vZHVsZWZpbGVzL0xpbnV4IgosICIvdXNyL3NoYXJlL21vZHVsZWZpbGVzL0NvcmUiLCAiL3Vzci9zaGFyZS9sbW9kL2xtb2QvbW9kdWxlZmlsZXMvQ29yZSIKLCAiL3Vzci9zaGFyZS9sbW9kL2xtb2QvbW9kdWxlZmlsZXMiLCAiL29wdC9jcmF5L3BhbHMvbG1vZC9tb2R1bGVmaWxlcy9jb3JlIgosICIvb3B0L2Ny"
declare -x _ModuleTable015_="YXkvbW9kdWxlZmlsZXMiLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY29yZSIKLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY3JheXBlLXRhcmdldHMvZGVmYXVsdCIKLCAiL3NvZnQvcGVyZnRvb2xzL2RhcnNoYW4vZGFyc2hhbi0zLjQuNC9zaGFyZS9jcmF5cGUtMi54L21vZHVsZWZpbGVzIiwgIi9zb2Z0L3hhbHQvbW9kdWxlZmlsZXMiLAp9LApzeXN0ZW1CYXNlTVBBVEggPSAiL3Vzci9zaGFyZS9tb2R1bGVmaWxlcy9MaW51eDovdXNyL3NoYXJlL21vZHVsZWZpbGVzL0NvcmU6L3Vzci9zaGFyZS9sbW9kL2xtb2QvbW9kdWxlZmlsZXMvQ29yZTovdXNyL3NoYXJlL2xtb2QvbG1vZC9tb2R1bGVmaWxlczovb3B0L2NyYXkvcGFscy9sbW9kL21vZHVs"
declare -x _ModuleTable016_="ZWZpbGVzL2NvcmU6L29wdC9jcmF5L21vZHVsZWZpbGVzOi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL2NvcmU6L29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY3JheXBlLXRhcmdldHMvZGVmYXVsdDovc29mdC9wZXJmdG9vbHMvZGFyc2hhbi9kYXJzaGFuLTMuNC40L3NoYXJlL2NyYXlwZS0yLngvbW9kdWxlZmlsZXM6L3NvZnQveGFsdC9tb2R1bGVmaWxlcyIsCn0K"
declare -x _ModuleTable_Sz_="16"
declare -x __LMOD_Priority_PATH="/soft/xalt/3.0.2-202408282050/bin:-100"
declare -x __LMOD_REF_COUNT_COMPILER_PATH="/soft/xalt/3.0.2-202408282050/bin:1"
declare -x __LMOD_REF_COUNT_CRAY_LD_LIBRARY_PATH="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3/lib:1;/opt/cray/pe/pmi/6.1.13/lib:1;/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib:1;/opt/cray/pe/mpich/8.1.28/gtl/lib:1;/opt/cray/pe/dsmml/0.2.2/dsmml/lib:1;/opt/cray/pe/perftools/23.12.0/lib64:1"
declare -x __LMOD_REF_COUNT_LD_LIBRARY_PATH="/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:1;/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:1;/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:1;/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:1;/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:1;/soft/perftools/darshan/darshan-3.4.4/lib:1;/opt/cray/pe/papi/7.0.1.2/lib64:1;/opt/cray/libfabric/1.15.2.0/lib64:1"
declare -x __LMOD_REF_COUNT_LD_PRELOAD="/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so:1"
declare -x __LMOD_REF_COUNT_MANPATH="/opt/cray/pals/1.3.4/man:2;/opt/cray/pe/pmi/6.1.13/man:1;/opt/cray/pe/mpich/8.1.28/ofi/man:1;/opt/cray/pe/mpich/8.1.28/man/mpich:1;/opt/cray/pe/dsmml/0.2.2/dsmml/man:1;/opt/cray/pe/craype/2.7.30/man:1;/opt/cray/pe/perftools/23.12.0/man:1;/opt/cray/pe/papi/7.0.1.2/share/pdoc/man:1;/opt/cray/libfabric/1.15.2.0/share/man:1;/usr/share/lmod/lmod/share/man:1;/home/shourya01/.local/man:1;/usr/local/man:1;/usr/share/man:1;/usr/man:1;/opt/c3/man:1;/opt/pbs/share/man:1;/opt/clmgr/man:1;/opt/sgi/share/man:1;/opt/clmgr/share/man:1;/opt/clmgr/lib/cm-cli/man:1"
declare -x __LMOD_REF_COUNT_MODULEPATH="/opt/cray/pe/lmod/modulefiles/hdf5-parallel/gnu/12.0/ofi/1.0/cray-mpich/8.0/cray-hdf5-parallel/1.12.2:1;/opt/cray/pe/lmod/modulefiles/cpu/x86-milan/1.0:1;/opt/cray/pe/lmod/modulefiles/mpi/gnu/12.0/ofi/1.0/cray-mpich/8.0:1;/opt/cray/pe/lmod/modulefiles/comnet/gnu/12.0/ofi/1.0:1;/opt/cray/pe/lmod/modulefiles/mix_compilers:1;/opt/cray/pe/lmod/modulefiles/compiler/gnu/12.0:1;/soft/modulefiles:1;/opt/cray/pe/lmod/modulefiles/perftools/23.12.0:1;/opt/cray/pe/lmod/modulefiles/net/ofi/1.0:1;/usr/share/modulefiles/Linux:1;/usr/share/modulefiles/Core:1;/usr/share/lmod/lmod/modulefiles/Core:1;/usr/share/lmod/lmod/modulefiles:1;/opt/cray/pals/lmod/modulefiles/core:1;/opt/cray/modulefiles:1;/opt/cray/pe/lmod/modulefiles/core:1;/opt/cray/pe/lmod/modulefiles/craype-targets/default:1;/soft/perftools/darshan/darshan-3.4.4/share/craype-2.x/modulefiles:1;/soft/xalt/modulefiles:1"
declare -x __LMOD_REF_COUNT_PATH="/soft/xalt/3.0.2-202408282050/bin:1;/soft/compilers/cudatoolkit/cuda-12.4.1/bin:1;/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/include:1;/opt/cray/pe/hdf5-parallel/1.12.2.9/bin:1;/opt/cray/pe/hdf5/1.12.2.9/bin:1;/opt/cray/pals/1.3.4/bin:1;/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/bin:1;/opt/cray/pe/mpich/8.1.28/bin:1;/opt/cray/pe/craype/2.7.30/bin:1;/home/shourya01/.local/bin:4;/soft/perftools/darshan/darshan-3.4.4/bin:1;/opt/cray/pe/perftools/23.12.0/bin:1;/opt/cray/pe/papi/7.0.1.2/bin:1;/opt/cray/libfabric/1.15.2.0/bin:1;/opt/clmgr/sbin:1;/opt/clmgr/bin:1;/opt/sgi/sbin:1;/opt/sgi/bin:1;/usr/local/bin:1;/usr/bin:1;/bin:2;/opt/c3/bin:1;/usr/lib/mit/bin:1;/usr/lib/mit/sbin:1;/opt/pbs/bin:1;/sbin:1;/home/shourya01/bin:1;/opt/cray/pe/bin:1"
declare -x __LMOD_REF_COUNT_PE_DSMML_PKGCONFIG_LIBS="dsmml:1"
declare -x __LMOD_REF_COUNT_PE_FORTRAN_PKGCONFIG_LIBS="hdf5hl_fortran_parallel:1;hdf5_fortran_parallel:1;mpichf90:1"
declare -x __LMOD_REF_COUNT_PE_GNU_FIXED_PKGCONFIG_PATH="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib/pkgconfig:1"
declare -x __LMOD_REF_COUNT_PE_MPICH_FIXED_PRGENV="GNU:1"
declare -x __LMOD_REF_COUNT_PE_MPICH_FORTRAN_PKGCONFIG_LIBS="mpichf90:1"
declare -x __LMOD_REF_COUNT_PE_MPICH_GENCOMPILERS_GNU="12.3:1"
declare -x __LMOD_REF_COUNT_PE_MPICH_PKGCONFIG_LIBS="mpich:1"
declare -x __LMOD_REF_COUNT_PE_PALS_PKGCONFIG_LIBS="libpals:1"
declare -x __LMOD_REF_COUNT_PE_PKGCONFIG_LIBS="hdf5_hl_parallel:1;hdf5_parallel:1;mpich:1;dsmml:1;darshan-runtime:1"
declare -x __LMOD_REF_COUNT_PE_PKGCONFIG_PRODUCTS="PE_PALS:1;PE_PMI:1;PE_MPICH:1;PE_DSMML:1"
declare -x __LMOD_REF_COUNT_PE_PMI_PKGCONFIG_LIBS="cray-pmi:1"
declare -x __LMOD_REF_COUNT_PE_PRODUCT_LIST="CRAYPE_X86_MILAN:1;PERFTOOLS:1;CRAYPAT:1"
declare -x __LMOD_REF_COUNT_PKG_CONFIG_PATH="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3/lib/pkgconfig:1;/opt/cray/pals/1.3.4/lib/pkgconfig:1;/opt/cray/pe/pmi/6.1.13/lib/pkgconfig:1;/opt/cray/pe/dsmml/0.2.2/dsmml/lib/pkgconfig:1;/opt/cray/pe/craype/2.7.30/pkg-config:1;/soft/perftools/darshan/darshan-3.4.4/lib/pkgconfig:1;/opt/cray/libfabric/1.15.2.0/lib64/pkgconfig:1"
declare -x __LMOD_REF_COUNT_PYTHONPATH="/soft/xalt/3.0.2-202408282050/site_packages:1"
declare -x ftp_proxy="http://proxy.alcf.anl.gov:3128"
declare -x http_proxy="http://proxy.alcf.anl.gov:3128"
declare -x https_proxy="http://proxy.alcf.anl.gov:3128"
declare -x no_proxy="admin,polaris-adminvm-01,localhost,*.cm.polaris.alcf.anl.gov,polaris-*,*.polaris.alcf.anl.gov,*.alcf.anl.gov"
Running on 10 nodes
Total number of GPUs: 40
Connected to tcp://x3204c0s31b1n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/applications/conda/2024-04-29/mconda3/bin/python
Launching application ab8d06a9-b16d-4568-9a0a-3776e12c5b52
Using PMI port 39949,39951
[2025-06-25 07:00:06,656] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,656] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,656] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,656] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,878] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,878] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,878] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,878] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,882] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,882] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,882] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,882] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,952] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,952] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,952] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,952] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,978] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,978] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,978] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:06,978] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,011] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,016] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,016] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,016] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,016] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,115] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,115] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,115] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:00:07,115] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,323] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,323] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,324] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,324] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,324] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,324] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,324] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:10,324] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,696] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,696] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,696] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,696] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,696] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,696] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,696] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:10,696] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,804] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,804] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,804] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,804] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,804] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,804] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,804] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,804] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,806] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,806] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,806] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,806] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,806] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,806] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,806] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:10,806] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,856] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,856] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,856] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,856] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,856] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,856] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,856] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:10,856] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,943] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,943] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,943] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,943] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,943] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,943] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,943] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:10,943] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,946] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,946] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,946] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,946] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,946] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,946] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,946] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:10,946] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,978] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,978] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,978] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,978] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,978] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,978] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:10,978] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:10,978] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:11,007] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:11,007] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:11,007] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:11,007] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:11,007] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:11,007] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:11,012] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:11,012] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:11,133] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:11,133] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:11,133] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:11,133] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:11,133] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:00:11,133] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:00:11,133] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,133] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=32, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=33, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=12, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=28, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=13, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=29, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=34, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=14, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=16, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=31, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=35, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=4, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=15, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=20, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=30, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=5, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=8, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=21, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=24, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=36, local_rank=0, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=9, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=23, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=25, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=37, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=6, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=22, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=26, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=39, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=10, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=27, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=11, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=38, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=17, local_rank=1, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=7, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=18, local_rank=2, world_size=40, master_addr=10.140.56.198, master_port=29500
[2025-06-25 07:00:11,134] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=19, local_rank=3, world_size=40, master_addr=10.140.56.198, master_port=29500
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
Initialized deepspeed on global rank 0, local rank 0 with world size 40.
[2025-06-25 07:00:16,147] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:00:39,754] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:00:39,756] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:00:39,756] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:00:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:00:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:00:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:00:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:00:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0005], mom=[(0.9, 0.999)]
[2025-06-25 07:00:39,816] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x152b7f573e10>
[2025-06-25 07:00:39,816] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 0.0005, 'weight_decay': 0.01}
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:00:39,817] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:00:39,818] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:00:39,818] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 0.0005, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Validating lr=0.0005, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=0.0005, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank0]:     _ = train_one_epoch_tfm_parallel(
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank0]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^
[rank0]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 3, local rank 3 with world size 40.
Initialized deepspeed on global rank 2, local rank 2 with world size 40.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank2]:     _ = train_one_epoch_tfm_parallel(
[rank2]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank2]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank2]:     ^^^^^^^^^^^^^^^^^^^^^
[rank2]: ValueError: not enough values to unpack (expected 4, got 3)
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank3]:     _ = train_one_epoch_tfm_parallel(
[rank3]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank3]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank3]:     ^^^^^^^^^^^^^^^^^^^^^
[rank3]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 6, local rank 2 with world size 40.
Initialized deepspeed on global rank 5, local rank 1 with world size 40.
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank6]:     _ = train_one_epoch_tfm_parallel(
[rank6]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank6]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank6]:     ^^^^^^^^^^^^^^^^^^^^^
[rank6]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 7, local rank 3 with world size 40.
Initialized deepspeed on global rank 4, local rank 0 with world size 40.
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank4]:     _ = train_one_epoch_tfm_parallel(
[rank4]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank4]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank4]:     ^^^^^^^^^^^^^^^^^^^^^
[rank4]: ValueError: not enough values to unpack (expected 4, got 3)
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank5]:     _ = train_one_epoch_tfm_parallel(
[rank5]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank5]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank5]:     ^^^^^^^^^^^^^^^^^^^^^
[rank5]: ValueError: not enough values to unpack (expected 4, got 3)
[rank7]: Traceback (most recent call last):
[rank7]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank7]:     _ = train_one_epoch_tfm_parallel(
[rank7]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank7]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank7]:     ^^^^^^^^^^^^^^^^^^^^^
[rank7]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 11, local rank 3 with world size 40.
[rank11]: Traceback (most recent call last):
[rank11]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank11]:     _ = train_one_epoch_tfm_parallel(
[rank11]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank11]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank11]:     ^^^^^^^^^^^^^^^^^^^^^
[rank11]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 10, local rank 2 with world size 40.
[rank10]: Traceback (most recent call last):
[rank10]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank10]:     _ = train_one_epoch_tfm_parallel(
[rank10]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank10]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank10]:     ^^^^^^^^^^^^^^^^^^^^^
[rank10]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 15, local rank 3 with world size 40.
[rank15]: Traceback (most recent call last):
[rank15]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank15]:     _ = train_one_epoch_tfm_parallel(
[rank15]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank15]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank15]:     ^^^^^^^^^^^^^^^^^^^^^
[rank15]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 8, local rank 0 with world size 40.
Initialized deepspeed on global rank 9, local rank 1 with world size 40.
Initialized deepspeed on global rank 13, local rank 1 with world size 40.
[rank8]: Traceback (most recent call last):
[rank8]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank8]:     _ = train_one_epoch_tfm_parallel(
[rank8]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank8]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank8]:     ^^^^^^^^^^^^^^^^^^^^^
[rank8]: ValueError: not enough values to unpack (expected 4, got 3)
[rank9]: Traceback (most recent call last):
[rank9]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank9]:     _ = train_one_epoch_tfm_parallel(
[rank9]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank9]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank9]:     ^^^^^^^^^^^^^^^^^^^^^
[rank9]: ValueError: not enough values to unpack (expected 4, got 3)
[rank13]: Traceback (most recent call last):
[rank13]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank13]:     _ = train_one_epoch_tfm_parallel(
[rank13]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank13]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank13]:     ^^^^^^^^^^^^^^^^^^^^^
[rank13]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 14, local rank 2 with world size 40.
[rank14]: Traceback (most recent call last):
[rank14]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank14]:     _ = train_one_epoch_tfm_parallel(
[rank14]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank14]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank14]:     ^^^^^^^^^^^^^^^^^^^^^
[rank14]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 12, local rank 0 with world size 40.
Initialized deepspeed on global rank 18, local rank 2 with world size 40.
[rank12]: Traceback (most recent call last):
[rank12]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank12]:     _ = train_one_epoch_tfm_parallel(
[rank12]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank12]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank12]:     ^^^^^^^^^^^^^^^^^^^^^
[rank12]: ValueError: not enough values to unpack (expected 4, got 3)
[rank18]: Traceback (most recent call last):
[rank18]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank18]:     _ = train_one_epoch_tfm_parallel(
[rank18]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank18]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank18]:     ^^^^^^^^^^^^^^^^^^^^^
[rank18]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 17, local rank 1 with world size 40.
[rank17]: Traceback (most recent call last):
[rank17]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank17]:     _ = train_one_epoch_tfm_parallel(
[rank17]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank17]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank17]:     ^^^^^^^^^^^^^^^^^^^^^
[rank17]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 19, local rank 3 with world size 40.
Initialized deepspeed on global rank 21, local rank 1 with world size 40.
[rank19]: Traceback (most recent call last):
[rank19]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank19]:     _ = train_one_epoch_tfm_parallel(
[rank19]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank19]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank19]:     ^^^^^^^^^^^^^^^^^^^^^
[rank19]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 26, local rank 2 with world size 40.
Initialized deepspeed on global rank 23, local rank 3 with world size 40.
[rank26]: Traceback (most recent call last):
[rank26]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank26]:     _ = train_one_epoch_tfm_parallel(
[rank26]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank26]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank26]:     ^^^^^^^^^^^^^^^^^^^^^
[rank26]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 25, local rank 1 with world size 40.
Initialized deepspeed on global rank 27, local rank 3 with world size 40.
[rank25]: Traceback (most recent call last):
[rank25]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank25]:     _ = train_one_epoch_tfm_parallel(
[rank25]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank25]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank25]:     ^^^^^^^^^^^^^^^^^^^^^
[rank25]: ValueError: not enough values to unpack (expected 4, got 3)
[rank27]: Traceback (most recent call last):
[rank27]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank27]:     _ = train_one_epoch_tfm_parallel(
[rank27]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank27]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank27]:     ^^^^^^^^^^^^^^^^^^^^^
[rank27]: ValueError: not enough values to unpack (expected 4, got 3)
[rank21]: Traceback (most recent call last):
[rank21]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank21]:     _ = train_one_epoch_tfm_parallel(
[rank21]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank21]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank21]:     ^^^^^^^^^^^^^^^^^^^^^
[rank21]: ValueError: not enough values to unpack (expected 4, got 3)
[rank23]: Traceback (most recent call last):
[rank23]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank23]:     _ = train_one_epoch_tfm_parallel(
[rank23]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank23]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank23]:     ^^^^^^^^^^^^^^^^^^^^^
[rank23]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 24, local rank 0 with world size 40.
Initialized deepspeed on global rank 16, local rank 0 with world size 40.
Initialized deepspeed on global rank 22, local rank 2 with world size 40.
[rank24]: Traceback (most recent call last):
[rank24]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank24]:     _ = train_one_epoch_tfm_parallel(
[rank24]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank24]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank24]:     ^^^^^^^^^^^^^^^^^^^^^
[rank24]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 20, local rank 0 with world size 40.
[rank16]: Traceback (most recent call last):
[rank16]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank16]:     _ = train_one_epoch_tfm_parallel(
[rank16]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank16]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank16]:     ^^^^^^^^^^^^^^^^^^^^^
[rank16]: ValueError: not enough values to unpack (expected 4, got 3)
[rank22]: Traceback (most recent call last):
[rank22]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank22]:     _ = train_one_epoch_tfm_parallel(
[rank22]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank22]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank22]:     ^^^^^^^^^^^^^^^^^^^^^
[rank22]: ValueError: not enough values to unpack (expected 4, got 3)
[rank20]: Traceback (most recent call last):
[rank20]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank20]:     _ = train_one_epoch_tfm_parallel(
[rank20]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank20]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank20]:     ^^^^^^^^^^^^^^^^^^^^^
[rank20]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 34, local rank 2 with world size 40.
Initialized deepspeed on global rank 30, local rank 2 with world size 40.
Initialized deepspeed on global rank 29, local rank 1 with world size 40.
[rank34]: Traceback (most recent call last):
[rank34]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank34]:     _ = train_one_epoch_tfm_parallel(
[rank34]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank34]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank34]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank34]:     ^^^^^^^^^^^^^^^^^^^^^
[rank34]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 33, local rank 1 with world size 40.
Initialized deepspeed on global rank 35, local rank 3 with world size 40.
Initialized deepspeed on global rank 31, local rank 3 with world size 40.
Initialized deepspeed on global rank 28, local rank 0 with world size 40.
Initialized deepspeed on global rank 32, local rank 0 with world size 40.
[rank33]: Traceback (most recent call last):
[rank33]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank33]:     _ = train_one_epoch_tfm_parallel(
[rank33]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank33]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank33]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank33]:     ^^^^^^^^^^^^^^^^^^^^^
[rank33]: ValueError: not enough values to unpack (expected 4, got 3)
[rank35]: Traceback (most recent call last):
[rank35]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank35]:     _ = train_one_epoch_tfm_parallel(
[rank35]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank35]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank35]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank35]:     ^^^^^^^^^^^^^^^^^^^^^
[rank35]: ValueError: not enough values to unpack (expected 4, got 3)
[rank32]: Traceback (most recent call last):
[rank32]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank32]:     _ = train_one_epoch_tfm_parallel(
[rank32]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank32]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank32]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank32]:     ^^^^^^^^^^^^^^^^^^^^^
[rank32]: ValueError: not enough values to unpack (expected 4, got 3)
[rank30]: Traceback (most recent call last):
[rank30]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank30]:     _ = train_one_epoch_tfm_parallel(
[rank30]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank30]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank30]:     ^^^^^^^^^^^^^^^^^^^^^
[rank30]: ValueError: not enough values to unpack (expected 4, got 3)
[rank28]: Traceback (most recent call last):
[rank28]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank28]:     _ = train_one_epoch_tfm_parallel(
[rank28]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank28]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank28]:     ^^^^^^^^^^^^^^^^^^^^^
[rank28]: ValueError: not enough values to unpack (expected 4, got 3)
[rank31]: Traceback (most recent call last):
[rank31]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank31]:     _ = train_one_epoch_tfm_parallel(
[rank31]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank31]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank31]:     ^^^^^^^^^^^^^^^^^^^^^
[rank31]: ValueError: not enough values to unpack (expected 4, got 3)
[rank29]: Traceback (most recent call last):
[rank29]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank29]:     _ = train_one_epoch_tfm_parallel(
[rank29]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank29]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank29]:     ^^^^^^^^^^^^^^^^^^^^^
[rank29]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 38, local rank 2 with world size 40.
[rank38]: Traceback (most recent call last):
[rank38]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank38]:     _ = train_one_epoch_tfm_parallel(
[rank38]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank38]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank38]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank38]:     ^^^^^^^^^^^^^^^^^^^^^
[rank38]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 39, local rank 3 with world size 40.
[rank39]: Traceback (most recent call last):
[rank39]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank39]:     _ = train_one_epoch_tfm_parallel(
[rank39]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank39]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank39]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank39]:     ^^^^^^^^^^^^^^^^^^^^^
[rank39]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 1, local rank 1 with world size 40.
Initialized deepspeed on global rank 37, local rank 1 with world size 40.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank1]:     _ = train_one_epoch_tfm_parallel(
[rank1]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank1]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank1]:     ^^^^^^^^^^^^^^^^^^^^^
[rank1]: ValueError: not enough values to unpack (expected 4, got 3)
[rank37]: Traceback (most recent call last):
[rank37]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank37]:     _ = train_one_epoch_tfm_parallel(
[rank37]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank37]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank37]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank37]:     ^^^^^^^^^^^^^^^^^^^^^
[rank37]: ValueError: not enough values to unpack (expected 4, got 3)
Initialized deepspeed on global rank 36, local rank 0 with world size 40.
[rank36]: Traceback (most recent call last):
[rank36]:   File "/home/shourya01/stormer_deepspeed/train_tfm_parallel.py", line 273, in <module>
[rank36]:     _ = train_one_epoch_tfm_parallel(
[rank36]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank36]:   File "/home/shourya01/stormer_deepspeed/utils.py", line 168, in train_one_epoch_tfm_parallel
[rank36]:     x, y, weather_past, _ = x.cuda(), y.cuda(), weather_past.cuda()
[rank36]:     ^^^^^^^^^^^^^^^^^^^^^
[rank36]: ValueError: not enough values to unpack (expected 4, got 3)
x3204c0s7b1n0.hsn.cm.polaris.alcf.anl.gov: rank 16 exited with code 1
x3204c0s37b1n0.hsn.cm.polaris.alcf.anl.gov: rank 8 exited with code 1
x3204c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 4 exited with code 1
x3204c0s31b1n0.hsn.cm.polaris.alcf.anl.gov: rank 0 exited with code 1
x3001c0s13b1n0.hsn.cm.polaris.alcf.anl.gov: rank 24 exited with code 1
x3001c0s1b0n0.hsn.cm.polaris.alcf.anl.gov: rank 32 exited with code 1
x3204c0s7b0n0.hsn.cm.polaris.alcf.anl.gov: rank 12 exited with code 1
x3001c0s19b1n0.hsn.cm.polaris.alcf.anl.gov: rank 28 exited with code 1
x3001c0s1b1n0.hsn.cm.polaris.alcf.anl.gov: rank 36 exited with code 1
x3204c0s37b1n0.hsn.cm.polaris.alcf.anl.gov: rank 11 exited with code 1
x3204c0s31b1n0.hsn.cm.polaris.alcf.anl.gov: rank 2 exited with code 1
x3204c0s31b1n0.hsn.cm.polaris.alcf.anl.gov: rank 3 exited with code 1
x3206c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 20 exited with code 1
x3001c0s1b0n0.hsn.cm.polaris.alcf.anl.gov: rank 33 exited with code 1
x3001c0s1b0n0.hsn.cm.polaris.alcf.anl.gov: rank 35 exited with code 1
x3204c0s7b0n0.hsn.cm.polaris.alcf.anl.gov: rank 14 exited with code 1
x3001c0s19b1n0.hsn.cm.polaris.alcf.anl.gov: rank 30 exited with code 1
x3001c0s13b1n0.hsn.cm.polaris.alcf.anl.gov: rank 25 exited with code 1
x3204c0s37b1n0.hsn.cm.polaris.alcf.anl.gov: rank 10 exited with code 1
x3001c0s13b1n0.hsn.cm.polaris.alcf.anl.gov: rank 27 exited with code 1
x3001c0s1b1n0.hsn.cm.polaris.alcf.anl.gov: rank 39 exited with code 1
x3204c0s7b1n0.hsn.cm.polaris.alcf.anl.gov: rank 18 exited with code 1
x3001c0s1b1n0.hsn.cm.polaris.alcf.anl.gov: rank 37 exited with code 1
x3204c0s7b1n0.hsn.cm.polaris.alcf.anl.gov: rank 17 exited with code 1
x3204c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 5 exited with code 1
x3204c0s7b0n0.hsn.cm.polaris.alcf.anl.gov: rank 13 exited with code 1
x3001c0s19b1n0.hsn.cm.polaris.alcf.anl.gov: rank 29 exited with code 1
x3204c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 6 exited with code 1
x3001c0s1b0n0.hsn.cm.polaris.alcf.anl.gov: rank 34 exited with code 1
x3204c0s31b1n0.hsn.cm.polaris.alcf.anl.gov: rank 1 exited with code 1
x3204c0s7b0n0.hsn.cm.polaris.alcf.anl.gov: rank 15 exited with code 1
x3204c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 7 exited with code 1
x3001c0s19b1n0.hsn.cm.polaris.alcf.anl.gov: rank 31 exited with code 1
x3204c0s37b1n0.hsn.cm.polaris.alcf.anl.gov: rank 9 exited with code 1
x3001c0s13b1n0.hsn.cm.polaris.alcf.anl.gov: rank 26 exited with code 1
x3204c0s7b1n0.hsn.cm.polaris.alcf.anl.gov: rank 19 exited with code 1
x3001c0s1b1n0.hsn.cm.polaris.alcf.anl.gov: rank 38 exited with code 1
x3206c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 21 exited with code 1
x3206c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 22 exited with code 1
x3206c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 23 exited with code 1
Application ab8d06a9 resources: utime=1028s stime=389s maxrss=4975820KB inblock=958776 oublock=664 minflt=19199755 majflt=26216 nvcsw=2493684 nivcsw=902566
Training completed
/home/shourya01/.bashrc: line 163: bind: warning: line editing not enabled
/home/shourya01/.bashrc: line 164: bind: warning: line editing not enabled
/home/shourya01/.bashrc: line 163: bind: warning: line editing not enabled
/home/shourya01/.bashrc: line 164: bind: warning: line editing not enabled

Lmod is automatically replacing "nvhpc/23.9" with "gcc-native/12.3".


Lmod is automatically replacing "PrgEnv-nvhpc/8.5.0" with "PrgEnv-gnu/8.5.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-mpich/8.1.28

declare -x APP2_STATE="23.12.0"
declare -x BASH_ENV="/usr/share/lmod/lmod/init/bash"
declare -x C3_RSH="ssh -oConnectTimeout=10 -oForwardX11=no"
declare -x CFLAGS="-I/soft/applications/conda/2024-04-29/mconda3/include"
declare -x COLORTERM="1"
declare -x COMPILER_PATH="/soft/xalt/3.0.2-202408282050/bin"
declare -x CONDA_DEFAULT_ENV="base"
declare -x CONDA_EXE="/soft/applications/conda/2024-04-29/mconda3/bin/conda"
declare -x CONDA_PREFIX="/soft/applications/conda/2024-04-29/mconda3"
declare -x CONDA_PROMPT_MODIFIER="(2024-04-29/base) "
declare -x CONDA_PYTHON_EXE="/soft/applications/conda/2024-04-29/mconda3/bin/python"
declare -x CONDA_SHLVL="1"
declare -x CPU="x86_64"
declare -x CRAYPAT_LD_LIBRARY_PATH="/opt/cray/pe/perftools/23.12.0/lib64"
declare -x CRAYPAT_OPTS_EXECUTABLE="libexec64/opts"
declare -x CRAYPAT_ROOT="/opt/cray/pe/perftools/23.12.0"
declare -x CRAYPE_DIR="/opt/cray/pe/craype/2.7.30"
declare -x CRAYPE_NETWORK_TARGET="ofi"
declare -x CRAYPE_VERSION="2.7.30"
declare -x CRAY_CPU_TARGET="x86-milan"
declare -x CRAY_DSMML_BASEDIR="/opt/cray/pe/dsmml/0.2.2"
declare -x CRAY_DSMML_DIR="/opt/cray/pe/dsmml/0.2.2/dsmml"
declare -x CRAY_DSMML_PREFIX="/opt/cray/pe/dsmml/0.2.2/dsmml"
declare -x CRAY_DSMML_ROOTDIR="/opt/cray/pe/dsmml/0.2.2"
declare -x CRAY_DSMML_VER="0.2.2"
declare -x CRAY_DSMML_VERSION="0.2.2"
declare -x CRAY_HDF5_PARALLEL_DIR="/opt/cray/pe/hdf5-parallel/1.12.2.9"
declare -x CRAY_HDF5_PARALLEL_PREFIX="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3"
declare -x CRAY_HDF5_PARALLEL_VERSION="1.12.2.9"
declare -x CRAY_LD_LIBRARY_PATH="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3/lib:/opt/cray/pe/pmi/6.1.13/lib:/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib:/opt/cray/pe/mpich/8.1.28/gtl/lib:/opt/cray/pe/dsmml/0.2.2/dsmml/lib:/opt/cray/pe/perftools/23.12.0/lib64"
declare -x CRAY_LMOD_COMPILER="gnu/12.0"
declare -x CRAY_LMOD_CPU="x86-milan/1.0"
declare -x CRAY_LMOD_MPI="cray-mpich/8.0"
declare -x CRAY_LMOD_NET="ofi/1.0"
declare -x CRAY_MPICH_BASEDIR="/opt/cray/pe/mpich/8.1.28/ofi"
declare -x CRAY_MPICH_DIR="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3"
declare -x CRAY_MPICH_PREFIX="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3"
declare -x CRAY_MPICH_ROOTDIR="/opt/cray/pe/mpich/8.1.28"
declare -x CRAY_MPICH_VER="8.1.28"
declare -x CRAY_MPICH_VERSION="8.1.28"
declare -x CRAY_PERFTOOLS_PREFIX="/opt/cray/pe/perftools/23.12.0"
declare -x CRAY_PERFTOOLS_VERSION="23.12.0"
declare -x CRAY_PMI_INCLUDE_OPTS="-I/opt/cray/pe/pmi/6.1.13/include"
declare -x CRAY_PMI_POST_LINK_OPTS="-L/opt/cray/pe/pmi/6.1.13/lib"
declare -x CRAY_PMI_PREFIX="/opt/cray/pe/pmi/6.1.13"
declare -x CRAY_PMI_VERSION="6.1.13"
declare -x CSHEDIT="emacs"
declare -x CUDA_HOME="/soft/compilers/cudatoolkit/cuda-12.4.1/"
declare -x CUDA_PATH="/soft/compilers/cudatoolkit/cuda-12.4.1/"
declare -x CUDA_TOOLKIT_BASE="/soft/compilers/cudatoolkit/cuda-12.4.1/"
declare -x CUDNN_HOME="/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/"
declare -x ENVIRONMENT="BATCH"
declare -x ENV_NAME="conda/2024-04-29"
declare -x FROM_HEADER=""
declare -x GCC_PATH="/usr/bin"
declare -x GCC_PREFIX="/usr/lib64/gcc/x86_64-suse-linux/12"
declare -x GCC_VERSION="12.3"
declare -x GNU_VERSION="12.3"
declare -x GPG_TTY="not a tty"
declare -x GSETTINGS_SCHEMA_DIR="/soft/applications/conda/2024-04-29/mconda3/share/glib-2.0/schemas"
declare -x GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=""
declare -x G_BROKEN_FILENAMES="1"
declare -x G_FILENAME_ENCODING="@locale,UTF-8,ISO-8859-15,CP1252"
declare -x HDF5_DIR="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3"
declare -x HDF5_ROOT="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3"
declare -x HISTSIZE="1000"
declare -x HOME="/home/shourya01"
declare -x HOST="x3003c0s13b0n0"
declare -x HOSTNAME="x3003c0s13b0n0"
declare -x HOSTTYPE="x86_64"
declare -x HTTPS_PROXY="http://proxy.alcf.anl.gov:3128"
declare -x HTTP_PROXY="http://proxy.alcf.anl.gov:3128"
declare -x LANG="en_US.UTF-8"
declare -x LANGUAGE="en_US.UTF-8"
declare -x LDFLAGS="-L/soft/applications/conda/2024-04-29/mconda3/lib -Wl,--enable-new-dtags,-rpath,/soft/applications/conda/2024-04-29/mconda3/lib"
declare -x LD_LIBRARY_PATH="/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:/soft/perftools/darshan/darshan-3.4.4/lib:/opt/cray/pe/papi/7.0.1.2/lib64:/opt/cray/libfabric/1.15.2.0/lib64"
declare -x LD_PRELOAD="/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so"
declare -x LESS="-M -I -R"
declare -x LESSCLOSE="lessclose.sh %s %s"
declare -x LESSKEY="/etc/lesskey.bin"
declare -x LESSOPEN="lessopen.sh %s"
declare -x LESS_ADVANCED_PREPROCESSOR="no"
declare -x LMOD_CMD="/usr/share/lmod/lmod/libexec/lmod"
declare -x LMOD_DIR="/usr/share/lmod/lmod/libexec"
declare -x LMOD_FAMILY_COMPILER="gcc-native"
declare -x LMOD_FAMILY_COMPILER_VERSION="12.3"
declare -x LMOD_FAMILY_CRAYPE="craype"
declare -x LMOD_FAMILY_CRAYPE_CPU="craype-x86-milan"
declare -x LMOD_FAMILY_CRAYPE_CPU_VERSION="false"
declare -x LMOD_FAMILY_CRAYPE_NETWORK="craype-network-ofi"
declare -x LMOD_FAMILY_CRAYPE_NETWORK_VERSION="false"
declare -x LMOD_FAMILY_CRAYPE_VERSION="2.7.30"
declare -x LMOD_FAMILY_GCC_COMPILER="gcc-native"
declare -x LMOD_FAMILY_GCC_COMPILER_VERSION="12.3"
declare -x LMOD_FAMILY_HDF5="cray-hdf5-parallel"
declare -x LMOD_FAMILY_HDF5_VERSION="1.12.2.9"
declare -x LMOD_FAMILY_MPI="cray-mpich"
declare -x LMOD_FAMILY_MPI_VERSION="8.1.28"
declare -x LMOD_FAMILY_PRGENV="PrgEnv-gnu"
declare -x LMOD_FAMILY_PRGENV_VERSION="8.5.0"
declare -x LMOD_FAMILY_PYTHON="conda"
declare -x LMOD_FAMILY_PYTHON_VERSION="2024-04-29"
declare -x LMOD_PKG="/usr/share/lmod/lmod"
declare -x LMOD_ROOT="/usr/share/lmod"
declare -x LMOD_SETTARG_FULL_SUPPORT="no"
declare -x LMOD_SYSTEM_DEFAULT_MODULES="PrgEnv-nvhpc:craype-network-ofi:perftools-base:darshan:xalt"
declare -x LMOD_VERSION="8.7.34"
declare -x LMOD_sys="Linux"
declare -x LOADEDMODULES="libfabric/1.15.2.0:craype-network-ofi:perftools-base/23.12.0:darshan/3.4.4:xalt/3.0.2-202408282050:gcc-native/12.3:craype/2.7.30:cray-dsmml/0.2.2:cray-mpich/8.1.28:cray-pmi/6.1.13:cray-pals/1.3.4:cray-libpals/1.3.4:craype-x86-milan:PrgEnv-gnu/8.5.0:cray-hdf5-parallel/1.12.2.9:cudnn/9.1.0:conda/2024-04-29"
declare -x LOGNAME="shourya01"
declare -x MACHTYPE="x86_64-suse-linux"
declare -x MAIL="/var/spool/mail/shourya01"
declare -x MANPATH="/opt/cray/pals/1.3.4/man:/opt/cray/pe/pmi/6.1.13/man:/opt/cray/pe/mpich/8.1.28/ofi/man:/opt/cray/pe/mpich/8.1.28/man/mpich:/opt/cray/pe/dsmml/0.2.2/dsmml/man:/opt/cray/pe/craype/2.7.30/man:/opt/cray/pe/perftools/23.12.0/man:/opt/cray/pe/papi/7.0.1.2/share/pdoc/man:/opt/cray/libfabric/1.15.2.0/share/man:/usr/share/lmod/lmod/share/man:/home/shourya01/.local/man:/usr/local/man:/usr/share/man:/usr/man:/opt/c3/man:/opt/pbs/share/man:/opt/clmgr/man:/opt/sgi/share/man:/opt/clmgr/share/man:/opt/clmgr/lib/cm-cli/man"
declare -x MINICOM="-c on"
declare -x MODULEPATH="/opt/cray/pe/lmod/modulefiles/hdf5-parallel/gnu/12.0/ofi/1.0/cray-mpich/8.0/cray-hdf5-parallel/1.12.2:/opt/cray/pe/lmod/modulefiles/cpu/x86-milan/1.0:/opt/cray/pe/lmod/modulefiles/mpi/gnu/12.0/ofi/1.0/cray-mpich/8.0:/opt/cray/pe/lmod/modulefiles/comnet/gnu/12.0/ofi/1.0:/opt/cray/pe/lmod/modulefiles/mix_compilers:/opt/cray/pe/lmod/modulefiles/compiler/gnu/12.0:/soft/modulefiles:/opt/cray/pe/lmod/modulefiles/perftools/23.12.0:/opt/cray/pe/lmod/modulefiles/net/ofi/1.0:/usr/share/modulefiles/Linux:/usr/share/modulefiles/Core:/usr/share/lmod/lmod/modulefiles/Core:/usr/share/lmod/lmod/modulefiles:/opt/cray/pals/lmod/modulefiles/core:/opt/cray/modulefiles:/opt/cray/pe/lmod/modulefiles/core:/opt/cray/pe/lmod/modulefiles/craype-targets/default:/soft/perftools/darshan/darshan-3.4.4/share/craype-2.x/modulefiles:/soft/xalt/modulefiles"
declare -x MODULEPATH_ROOT="/usr/share/modulefiles"
declare -x MODULESHOME="/usr/share/lmod/lmod"
declare -x MORE="-sl"
declare -x MPI4JAX_USE_CUDA_MPI="1"
declare -x MPICH_DIR="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3"
declare -x MPICH_GPU_SUPPORT_ENABLED="1"
declare -x NCCL_IB_DISABLE="1"
declare -x NCCL_SOCKET_IFNAME="hsn"
declare -x NCPUS="64"
declare -x OFFLOAD_INIT="on_start"
declare -x OLDPWD
declare -x OMP_NUM_THREADS="4"
declare -x OSCAR_HOME="/opt/oscar"
declare -x OSTYPE="linux"
declare -x PAGER="less"
declare -x PALS_TRANSFER="0"
declare -x PATH="/soft/applications/conda/2024-04-29/mconda3/bin:/soft/applications/conda/2024-04-29/mconda3/condabin:/soft/xalt/3.0.2-202408282050/bin:/soft/compilers/cudatoolkit/cuda-12.4.1/bin:/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/include:/opt/cray/pe/hdf5-parallel/1.12.2.9/bin:/opt/cray/pe/hdf5/1.12.2.9/bin:/opt/cray/pals/1.3.4/bin:/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/bin:/opt/cray/pe/mpich/8.1.28/bin:/opt/cray/pe/craype/2.7.30/bin:/home/shourya01/.local/bin:/soft/perftools/darshan/darshan-3.4.4/bin:/opt/cray/pe/perftools/23.12.0/bin:/opt/cray/pe/papi/7.0.1.2/bin:/opt/cray/libfabric/1.15.2.0/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/bin:/opt/c3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/pbs/bin:/sbin:/home/shourya01/bin:/opt/cray/pe/bin"
declare -x PAT_RT_PERFCTR_DISABLE_COMPONENTS="nvml,rocm_smi"
declare -x PBS_ACCOUNT="ParaLLMs"
declare -x PBS_ENVIRONMENT="PBS_BATCH"
declare -x PBS_JOBCOOKIE="6B3B5E19187A17390008F88127040125"
declare -x PBS_JOBDIR="/home/shourya01"
declare -x PBS_JOBID="5238718.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov"
declare -x PBS_JOBNAME="illi-tfm-parallel-redo"
declare -x PBS_MOMPORT="15003"
declare -x PBS_NODEFILE="/var/spool/pbs/aux/5238718.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov"
declare -x PBS_NODENUM="0"
declare -x PBS_O_HOME="/home/shourya01"
declare -x PBS_O_HOST="polaris-login-04.hsn.cm.polaris.alcf.anl.gov"
declare -x PBS_O_INTERACTIVE_AUTH_METHOD="resvport"
declare -x PBS_O_LANG="en_US.UTF-8"
declare -x PBS_O_LOGNAME="shourya01"
declare -x PBS_O_MAIL="/var/spool/mail/shourya01"
declare -x PBS_O_PATH="/home/shourya01/.local/bin:/home/shourya01/.vscode-server/cli/servers/Stable-dfaf44141ea9deb3b4096f7cd6d24e00c147a4b1/server/bin/remote-cli:/home/shourya01/.local/bin:/home/shourya01/.local/bin:/home/shourya01/.local/bin:/home/shourya01/.local/bin:/soft/xalt/3.0.2-202408282050/bin:/soft/perftools/darshan/darshan-3.4.4/bin:/opt/cray/pe/perftools/23.12.0/bin:/opt/cray/pe/papi/7.0.1.2/bin:/opt/cray/libfabric/1.15.2.0/bin:/opt/cray/pals/1.3.4/bin:/opt/cray/pe/mpich/8.1.28/ofi/nvidia/23.3/bin:/opt/cray/pe/mpich/8.1.28/bin:/opt/cray/pe/craype/2.7.30/bin:/opt/nvidia/hpc_sdk/Linux_x86_64/23.9/compilers/extras/qd/bin:/opt/nvidia/hpc_sdk/Linux_x86_64/23.9/compilers/bin:/opt/nvidia/hpc_sdk/Linux_x86_64/23.9/cuda/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/home/shourya01/.local/bin:/usr/local/bin:/usr/bin:/bin:/opt/c3/bin:/dbhome/db2cat/sqllib/bin:/dbhome/db2cat/sqllib/adm:/dbhome/db2cat/sqllib/misc:/dbhome/db2cat/sqllib/gskit/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/pbs/bin:/sbin:/opt/cray/pe/bin:/home/shourya01/.local/bin:/home/shourya01/bin:/home/shourya01/.local/bin:/home/shourya01/bin:/home/shourya01/.vscode-server/extensions/ms-python.debugpy-2025.8.0/bundled/scripts/noConfigScripts"
declare -x PBS_O_QUEUE="prod"
declare -x PBS_O_SHELL="/bin/bash"
declare -x PBS_O_SYSTEM="Linux"
declare -x PBS_O_WORKDIR="/home/shourya01"
declare -x PBS_QUEUE="small"
declare -x PBS_TASKNUM="1"
declare -x PELOCAL_PRGENV="true"
declare -x PERFTOOLS_VERSION="23.12.0"
declare -x PE_DSMML_MODULE_NAME="cray-dsmml"
declare -x PE_DSMML_PKGCONFIG_LIBS="dsmml"
declare -x PE_ENV="GNU"
declare -x PE_FORTRAN_PKGCONFIG_LIBS="hdf5hl_fortran_parallel:hdf5_fortran_parallel:mpichf90"
declare -x PE_GCC_EXTERNAL="native"
declare -x PE_GCC_LEVEL="12"
declare -x PE_GNU_FIXED_PKGCONFIG_PATH="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib/pkgconfig"
declare -x PE_HDF5_PARALLEL_DIR="/opt/cray/pe/hdf5-parallel/1.12.2.9"
declare -x PE_HDF5_PARALLEL_FORTRAN_PKGCONFIG_LIBS="hdf5hl_fortran_parallel:hdf5_fortran_parallel"
declare -x PE_HDF5_PARALLEL_PKGCONFIG_LIBS="hdf5_hl_parallel:hdf5_parallel"
declare -x PE_MPICH_FIXED_PRGENV="GNU"
declare -x PE_MPICH_FORTRAN_PKGCONFIG_LIBS="mpichf90"
declare -x PE_MPICH_GENCOMPILERS_GNU="12.3"
declare -x PE_MPICH_GTL_DIR_amd_gfx906="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_amd_gfx908="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_amd_gfx90a="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_amd_gfx940="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_amd_gfx942="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_nvidia70="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_nvidia80="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_nvidia90="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_DIR_ponteVecchio="-L/opt/cray/pe/mpich/8.1.28/gtl/lib"
declare -x PE_MPICH_GTL_LIBS_amd_gfx906="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_amd_gfx908="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_amd_gfx90a="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_amd_gfx940="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_amd_gfx942="-lmpi_gtl_hsa"
declare -x PE_MPICH_GTL_LIBS_nvidia70="-lmpi_gtl_cuda"
declare -x PE_MPICH_GTL_LIBS_nvidia80="-lmpi_gtl_cuda"
declare -x PE_MPICH_GTL_LIBS_nvidia90="-lmpi_gtl_cuda"
declare -x PE_MPICH_GTL_LIBS_ponteVecchio="-lmpi_gtl_ze"
declare -x PE_MPICH_MODULE_NAME="cray-mpich"
declare -x PE_MPICH_PKGCONFIG_LIBS="mpich"
declare -x PE_MPICH_PKGCONFIG_VARIABLES="PE_MPICH_GTL_DIR_@accelerator@:PE_MPICH_GTL_LIBS_@accelerator@"
declare -x PE_PALS_PKGCONFIG_LIBS="libpals"
declare -x PE_PERFTOOLS_MPICH_LIBDIR="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib"
declare -x PE_PKGCONFIG_LIBS="hdf5_hl_parallel:hdf5_parallel:mpich:dsmml:darshan-runtime"
declare -x PE_PKGCONFIG_PRODUCTS="PE_PALS:PE_PMI:PE_MPICH:PE_DSMML"
declare -x PE_PMI_PKGCONFIG_LIBS="cray-pmi"
declare -x PE_PRODUCT_LIST="CRAYPE_X86_MILAN"
declare -x PKGCONFIG_ENABLED="1"
declare -x PKG_CONFIG_PATH="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3/lib/pkgconfig:/opt/cray/pals/1.3.4/lib/pkgconfig:/opt/cray/pe/pmi/6.1.13/lib/pkgconfig:/opt/cray/pe/dsmml/0.2.2/dsmml/lib/pkgconfig:/opt/cray/pe/craype/2.7.30/pkg-config:/soft/perftools/darshan/darshan-3.4.4/lib/pkgconfig:/opt/cray/libfabric/1.15.2.0/lib64/pkgconfig"
declare -x PROFILEREAD="true"
declare -x PWD="/home/shourya01"
declare -x PYTHONPATH="/soft/xalt/3.0.2-202408282050/site_packages"
declare -x PYTHONUSERBASE="/home/shourya01/.local/polaris/conda/2024-04-29"
declare -x QT_SYSTEM_DIR="/usr/share/desktop-data"
declare -x SHELL="/bin/bash"
declare -x SHLVL="2"
declare -x SLURM_MPI_TYPE="cray_shasta"
declare -x STARSHIP_SESSION_KEY="8474918213122458"
declare -x STARSHIP_SHELL="bash"
declare -x TMPDIR="/var/tmp/pbs.5238718.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov"
declare -x TRITON_DISABLE_AUTOTUNE="1"
declare -x TZ="Etc/UTC"
declare -x USER="shourya01"
declare -x USE_PCM_DB="2"
declare -x WINDOWMANAGER="xterm"
declare -x XALT_DIR="/soft/xalt/3.0.2-202408282050"
declare -x XALT_EXECUTABLE_TRACKING="yes"
declare -x XALT_SAMPLING="no"
declare -x XALT_SCALAR_AND_SPSR_SAMPLING="yes"
declare -x XCURSOR_THEME="DMZ"
declare -x XDG_CONFIG_DIRS="/etc/xdg"
declare -x XDG_DATA_DIRS="/usr/share"
declare -x XKEYSYMDB="/usr/X11R6/lib/X11/XKeysymDB"
declare -x XLA_FLAGS="--xla_gpu_force_compilation_parallelism=1 --xla_gpu_cuda_data_dir=/soft/compilers/cudatoolkit/cuda-12.4.1/"
declare -x XLA_PYTHON_CLIENT_PREALLOCATE="false"
declare -x XML_CATALOG_FILES="file:///soft/applications/conda/2024-04-29/mconda3/etc/xml/catalog file:///etc/xml/catalog"
declare -x XNLSPATH="/usr/X11R6/lib/X11/nls"
declare -x _CE_CONDA=""
declare -x _CE_M=""
declare -x _LMFILES_="/opt/cray/modulefiles/libfabric/1.15.2.0:/opt/cray/pe/lmod/modulefiles/craype-targets/default/craype-network-ofi.lua:/opt/cray/pe/lmod/modulefiles/core/perftools-base/23.12.0.lua:/soft/perftools/darshan/darshan-3.4.4/share/craype-2.x/modulefiles/darshan/3.4.4:/soft/xalt/modulefiles/xalt/3.0.2-202408282050:/opt/cray/pe/lmod/modulefiles/core/gcc-native/12.3.lua:/opt/cray/pe/lmod/modulefiles/core/craype/2.7.30.lua:/opt/cray/pe/lmod/modulefiles/core/cray-dsmml/0.2.2.lua:/opt/cray/pe/lmod/modulefiles/comnet/gnu/12.0/ofi/1.0/cray-mpich/8.1.28.lua:/opt/cray/pe/lmod/modulefiles/core/cray-pmi/6.1.13.lua:/opt/cray/pals/lmod/modulefiles/core/cray-pals/1.3.4.lua:/opt/cray/pals/lmod/modulefiles/core/cray-libpals/1.3.4.lua:/opt/cray/pe/lmod/modulefiles/craype-targets/default/craype-x86-milan.lua:/opt/cray/pe/lmod/modulefiles/core/PrgEnv-gnu/8.5.0.lua:/opt/cray/pe/lmod/modulefiles/mpi/gnu/12.0/ofi/1.0/cray-mpich/8.0/cray-hdf5-parallel/1.12.2.9.lua:/soft/modulefiles/cudnn/9.1.0.lua:/soft/modulefiles/conda/2024-04-29.lua"
declare -x _ModuleTable001_="X01vZHVsZVRhYmxlXyA9IHsKTVR2ZXJzaW9uID0gMywKY19yZWJ1aWxkVGltZSA9IGZhbHNlLApjX3Nob3J0VGltZSA9IGZhbHNlLApkZXB0aFQgPSB7fSwKZmFtaWx5ID0gewpQcmdFbnYgPSAiUHJnRW52LWdudSIsCmNvbXBpbGVyID0gImdjYy1uYXRpdmUiLApjcmF5cGUgPSAiY3JheXBlIiwKY3JheXBlX2NwdSA9ICJjcmF5cGUteDg2LW1pbGFuIiwKY3JheXBlX25ldHdvcmsgPSAiY3JheXBlLW5ldHdvcmstb2ZpIiwKZ2NjX2NvbXBpbGVyID0gImdjYy1uYXRpdmUiLApoZGY1ID0gImNyYXktaGRmNS1wYXJhbGxlbCIsCm1waSA9ICJjcmF5LW1waWNoIiwKcHl0aG9uID0gImNvbmRhIiwKfSwKbVQgPSB7ClsiUHJnRW52LWdudSJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUv"
declare -x _ModuleTable002_="bG1vZC9tb2R1bGVmaWxlcy9jb3JlL1ByZ0Vudi1nbnUvOC41LjAubHVhIiwKZnVsbE5hbWUgPSAiUHJnRW52LWdudS84LjUuMCIsCmxvYWRPcmRlciA9IDE0LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gIlByZ0Vudi1nbnUiLAp3ViA9ICJeMDAwMDAwMDguMDAwMDAwMDA1Lip6ZmluYWwiLAp9LApjb25kYSA9IHsKZm4gPSAiL3NvZnQvbW9kdWxlZmlsZXMvY29uZGEvMjAyNC0wNC0yOS5sdWEiLApmdWxsTmFtZSA9ICJjb25kYS8yMDI0LTA0LTI5IiwKbG9hZE9yZGVyID0gMTcsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAwLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiY29uZGEiLAp3ViA9ICJeMDAw"
declare -x _ModuleTable003_="MDIwMjQuKnpmaW5hbC0uMDAwMDAwMDA0Lip6ZmluYWwtLjAwMDAwMDAyOS4qemZpbmFsIiwKfSwKWyJjcmF5LWRzbW1sIl0gPSB7CmZuID0gIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL2NvcmUvY3JheS1kc21tbC8wLjIuMi5sdWEiLApmdWxsTmFtZSA9ICJjcmF5LWRzbW1sLzAuMi4yIiwKbG9hZE9yZGVyID0gOCwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDIsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJjcmF5LWRzbW1sIiwKd1YgPSAiXjAwMDAwMDAwLjAwMDAwMDAwMi4wMDAwMDAwMDIuKnpmaW5hbCIsCn0sClsiY3JheS1oZGY1LXBhcmFsbGVsIl0gPSB7CmZuID0gIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL21waS9nbnUvMTIuMC9v"
declare -x _ModuleTable004_="ZmkvMS4wL2NyYXktbXBpY2gvOC4wL2NyYXktaGRmNS1wYXJhbGxlbC8xLjEyLjIuOS5sdWEiLApmdWxsTmFtZSA9ICJjcmF5LWhkZjUtcGFyYWxsZWwvMS4xMi4yLjkiLApsb2FkT3JkZXIgPSAxNSwKcHJvcFQgPSB7fSwKcmVmX2NvdW50ID0gMSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJjcmF5LWhkZjUtcGFyYWxsZWwvMS4xMi4yLjkiLAp3ViA9ICJeMDAwMDAwMDEuMDAwMDAwMDEyLjAwMDAwMDAwMi4wMDAwMDAwMDkuKnpmaW5hbCIsCn0sClsiY3JheS1saWJwYWxzIl0gPSB7CmZuID0gIi9vcHQvY3JheS9wYWxzL2xtb2QvbW9kdWxlZmlsZXMvY29yZS9jcmF5LWxpYnBhbHMvMS4zLjQubHVhIiwKZnVsbE5hbWUgPSAiY3JheS1s"
declare -x _ModuleTable005_="aWJwYWxzLzEuMy40IiwKbG9hZE9yZGVyID0gMTIsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAyLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiY3JheS1saWJwYWxzIiwKd1YgPSAiXjAwMDAwMDAxLjAwMDAwMDAwMy4wMDAwMDAwMDQuKnpmaW5hbCIsCn0sClsiY3JheS1tcGljaCJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jb21uZXQvZ251LzEyLjAvb2ZpLzEuMC9jcmF5LW1waWNoLzguMS4yOC5sdWEiLApmdWxsTmFtZSA9ICJjcmF5LW1waWNoLzguMS4yOCIsCmxvYWRPcmRlciA9IDksCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAyLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiY3JheS1tcGljaCIsCndWID0gIl4w"
declare -x _ModuleTable006_="MDAwMDAwOC4wMDAwMDAwMDEuMDAwMDAwMDI4Lip6ZmluYWwiLAp9LApbImNyYXktcGFscyJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGFscy9sbW9kL21vZHVsZWZpbGVzL2NvcmUvY3JheS1wYWxzLzEuMy40Lmx1YSIsCmZ1bGxOYW1lID0gImNyYXktcGFscy8xLjMuNCIsCmxvYWRPcmRlciA9IDExLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXktcGFscyIsCndWID0gIl4wMDAwMDAwMS4wMDAwMDAwMDMuMDAwMDAwMDA0Lip6ZmluYWwiLAp9LApbImNyYXktcG1pIl0gPSB7CmZuID0gIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL2NvcmUvY3JheS1wbWkvNi4xLjEzLmx1YSIsCmZ1bGxOYW1lID0gImNy"
declare -x _ModuleTable007_="YXktcG1pLzYuMS4xMyIsCmxvYWRPcmRlciA9IDEwLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXktcG1pIiwKd1YgPSAiXjAwMDAwMDA2LjAwMDAwMDAwMS4wMDAwMDAwMTMuKnpmaW5hbCIsCn0sCmNyYXlwZSA9IHsKZm4gPSAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY29yZS9jcmF5cGUvMi43LjMwLmx1YSIsCmZ1bGxOYW1lID0gImNyYXlwZS8yLjcuMzAiLApsb2FkT3JkZXIgPSA3LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXlwZSIsCndWID0gIl4wMDAwMDAwMi4wMDAwMDAwMDcuMDAwMDAwMDMwLip6ZmluYWwiLAp9LApb"
declare -x _ModuleTable008_="ImNyYXlwZS1uZXR3b3JrLW9maSJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jcmF5cGUtdGFyZ2V0cy9kZWZhdWx0L2NyYXlwZS1uZXR3b3JrLW9maS5sdWEiLApmdWxsTmFtZSA9ICJjcmF5cGUtbmV0d29yay1vZmkiLApsb2FkT3JkZXIgPSAyLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMCwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXlwZS1uZXR3b3JrLW9maSIsCndWID0gIk0uKnpmaW5hbCIsCn0sClsiY3JheXBlLXg4Ni1taWxhbiJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jcmF5cGUtdGFyZ2V0cy9kZWZhdWx0L2NyYXlwZS14ODYtbWlsYW4ubHVhIiwKZnVsbE5hbWUgPSAiY3JheXBl"
declare -x _ModuleTable009_="LXg4Ni1taWxhbiIsCmxvYWRPcmRlciA9IDEzLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImNyYXlwZS14ODYtbWlsYW4iLAp3ViA9ICJNLip6ZmluYWwiLAp9LApjdWRubiA9IHsKZm4gPSAiL3NvZnQvbW9kdWxlZmlsZXMvY3Vkbm4vOS4xLjAubHVhIiwKZnVsbE5hbWUgPSAiY3Vkbm4vOS4xLjAiLApsb2FkT3JkZXIgPSAxNiwKcHJvcFQgPSB7fSwKcmVmX2NvdW50ID0gMSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJjdWRubi85LjEuMCIsCndWID0gIjAwMDAwMDAwOS4wMDAwMDAwMDEuKnpmaW5hbCIsCn0sCmRhcnNoYW4gPSB7CmZuID0gIi9zb2Z0L3BlcmZ0b29scy9k"
declare -x _ModuleTable010_="YXJzaGFuL2RhcnNoYW4tMy40LjQvc2hhcmUvY3JheXBlLTIueC9tb2R1bGVmaWxlcy9kYXJzaGFuLzMuNC40IiwKZnVsbE5hbWUgPSAiZGFyc2hhbi8zLjQuNCIsCmxvYWRPcmRlciA9IDQsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAwLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiZGFyc2hhbiIsCndWID0gIjAwMDAwMDAwMy4wMDAwMDAwMDQuMDAwMDAwMDA0Lip6ZmluYWwiLAp9LApbImdjYy1uYXRpdmUiXSA9IHsKZm4gPSAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY29yZS9nY2MtbmF0aXZlLzEyLjMubHVhIiwKZnVsbE5hbWUgPSAiZ2NjLW5hdGl2ZS8xMi4zIiwKbG9hZE9yZGVyID0gNiwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDIsCnN0"
declare -x _ModuleTable011_="YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJnY2MtbmF0aXZlIiwKd1YgPSAiXjAwMDAwMDEyLjAwMDAwMDAwMy4qemZpbmFsIiwKfSwKbGliZmFicmljID0gewpmbiA9ICIvb3B0L2NyYXkvbW9kdWxlZmlsZXMvbGliZmFicmljLzEuMTUuMi4wIiwKZnVsbE5hbWUgPSAibGliZmFicmljLzEuMTUuMi4wIiwKbG9hZE9yZGVyID0gMSwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJsaWJmYWJyaWMiLAp3ViA9ICJeMDAwMDAwMDEuMDAwMDAwMDE1LjAwMDAwMDAwMi4qemZpbmFsIiwKfSwKWyJwZXJmdG9vbHMtYmFzZSJdID0gewpmbiA9ICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jb3JlL3BlcmZ0b29s"
declare -x _ModuleTable012_="cy1iYXNlLzIzLjEyLjAubHVhIiwKZnVsbE5hbWUgPSAicGVyZnRvb2xzLWJhc2UvMjMuMTIuMCIsCmxvYWRPcmRlciA9IDMsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAwLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAicGVyZnRvb2xzLWJhc2UiLAp3ViA9ICJeMDAwMDAwMjMuMDAwMDAwMDEyLip6ZmluYWwiLAp9LAp4YWx0ID0gewpmbiA9ICIvc29mdC94YWx0L21vZHVsZWZpbGVzL3hhbHQvMy4wLjItMjAyNDA4MjgyMDUwIiwKZnVsbE5hbWUgPSAieGFsdC8zLjAuMi0yMDI0MDgyODIwNTAiLApsb2FkT3JkZXIgPSA1LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMCwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gInhhbHQiLAp3ViA9ICJeMDAwMDAw"
declare -x _ModuleTable013_="MDMuMDAwMDAwMDAwLjAwMDAwMDAwMi4qemZpbmFsLS4yMDI0MDgyODIwNTAuKnpmaW5hbCIsCn0sCn0sCm1wYXRoQSA9IHsKCiIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9oZGY1LXBhcmFsbGVsL2dudS8xMi4wL29maS8xLjAvY3JheS1tcGljaC84LjAvY3JheS1oZGY1LXBhcmFsbGVsLzEuMTIuMiIKLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY3B1L3g4Ni1taWxhbi8xLjAiCiwgIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL21waS9nbnUvMTIuMC9vZmkvMS4wL2NyYXktbXBpY2gvOC4wIgosICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9jb21uZXQvZ251LzEyLjAvb2ZpLzEuMCIKLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxl"
declare -x _ModuleTable014_="ZmlsZXMvbWl4X2NvbXBpbGVycyIKLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY29tcGlsZXIvZ251LzEyLjAiLCAiL3NvZnQvbW9kdWxlZmlsZXMiCiwgIi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL3BlcmZ0b29scy8yMy4xMi4wIgosICIvb3B0L2NyYXkvcGUvbG1vZC9tb2R1bGVmaWxlcy9uZXQvb2ZpLzEuMCIsICIvdXNyL3NoYXJlL21vZHVsZWZpbGVzL0xpbnV4IgosICIvdXNyL3NoYXJlL21vZHVsZWZpbGVzL0NvcmUiLCAiL3Vzci9zaGFyZS9sbW9kL2xtb2QvbW9kdWxlZmlsZXMvQ29yZSIKLCAiL3Vzci9zaGFyZS9sbW9kL2xtb2QvbW9kdWxlZmlsZXMiLCAiL29wdC9jcmF5L3BhbHMvbG1vZC9tb2R1bGVmaWxlcy9jb3JlIgosICIvb3B0L2Ny"
declare -x _ModuleTable015_="YXkvbW9kdWxlZmlsZXMiLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY29yZSIKLCAiL29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY3JheXBlLXRhcmdldHMvZGVmYXVsdCIKLCAiL3NvZnQvcGVyZnRvb2xzL2RhcnNoYW4vZGFyc2hhbi0zLjQuNC9zaGFyZS9jcmF5cGUtMi54L21vZHVsZWZpbGVzIiwgIi9zb2Z0L3hhbHQvbW9kdWxlZmlsZXMiLAp9LApzeXN0ZW1CYXNlTVBBVEggPSAiL3Vzci9zaGFyZS9tb2R1bGVmaWxlcy9MaW51eDovdXNyL3NoYXJlL21vZHVsZWZpbGVzL0NvcmU6L3Vzci9zaGFyZS9sbW9kL2xtb2QvbW9kdWxlZmlsZXMvQ29yZTovdXNyL3NoYXJlL2xtb2QvbG1vZC9tb2R1bGVmaWxlczovb3B0L2NyYXkvcGFscy9sbW9kL21vZHVs"
declare -x _ModuleTable016_="ZWZpbGVzL2NvcmU6L29wdC9jcmF5L21vZHVsZWZpbGVzOi9vcHQvY3JheS9wZS9sbW9kL21vZHVsZWZpbGVzL2NvcmU6L29wdC9jcmF5L3BlL2xtb2QvbW9kdWxlZmlsZXMvY3JheXBlLXRhcmdldHMvZGVmYXVsdDovc29mdC9wZXJmdG9vbHMvZGFyc2hhbi9kYXJzaGFuLTMuNC40L3NoYXJlL2NyYXlwZS0yLngvbW9kdWxlZmlsZXM6L3NvZnQveGFsdC9tb2R1bGVmaWxlcyIsCn0K"
declare -x _ModuleTable_Sz_="16"
declare -x __LMOD_Priority_PATH="/soft/xalt/3.0.2-202408282050/bin:-100"
declare -x __LMOD_REF_COUNT_COMPILER_PATH="/soft/xalt/3.0.2-202408282050/bin:1"
declare -x __LMOD_REF_COUNT_CRAY_LD_LIBRARY_PATH="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3/lib:1;/opt/cray/pe/pmi/6.1.13/lib:1;/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib:1;/opt/cray/pe/mpich/8.1.28/gtl/lib:1;/opt/cray/pe/dsmml/0.2.2/dsmml/lib:1;/opt/cray/pe/perftools/23.12.0/lib64:1"
declare -x __LMOD_REF_COUNT_LD_LIBRARY_PATH="/soft/compilers/cudatoolkit/cuda-12.4.1/extras/CUPTI/lib64:1;/soft/compilers/cudatoolkit/cuda-12.4.1/lib64:1;/soft/libraries/trt/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-12.0/lib:1;/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/lib:1;/soft/libraries/cudnn/cudnn-cuda12-linux-x64-v9.1.0.70/lib:1;/soft/perftools/darshan/darshan-3.4.4/lib:1;/opt/cray/pe/papi/7.0.1.2/lib64:1;/opt/cray/libfabric/1.15.2.0/lib64:1"
declare -x __LMOD_REF_COUNT_LD_PRELOAD="/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so:1"
declare -x __LMOD_REF_COUNT_MANPATH="/opt/cray/pals/1.3.4/man:2;/opt/cray/pe/pmi/6.1.13/man:1;/opt/cray/pe/mpich/8.1.28/ofi/man:1;/opt/cray/pe/mpich/8.1.28/man/mpich:1;/opt/cray/pe/dsmml/0.2.2/dsmml/man:1;/opt/cray/pe/craype/2.7.30/man:1;/opt/cray/pe/perftools/23.12.0/man:1;/opt/cray/pe/papi/7.0.1.2/share/pdoc/man:1;/opt/cray/libfabric/1.15.2.0/share/man:1;/usr/share/lmod/lmod/share/man:1;/home/shourya01/.local/man:1;/usr/local/man:1;/usr/share/man:1;/usr/man:1;/opt/c3/man:1;/opt/pbs/share/man:1;/opt/clmgr/man:1;/opt/sgi/share/man:1;/opt/clmgr/share/man:1;/opt/clmgr/lib/cm-cli/man:1"
declare -x __LMOD_REF_COUNT_MODULEPATH="/opt/cray/pe/lmod/modulefiles/hdf5-parallel/gnu/12.0/ofi/1.0/cray-mpich/8.0/cray-hdf5-parallel/1.12.2:1;/opt/cray/pe/lmod/modulefiles/cpu/x86-milan/1.0:1;/opt/cray/pe/lmod/modulefiles/mpi/gnu/12.0/ofi/1.0/cray-mpich/8.0:1;/opt/cray/pe/lmod/modulefiles/comnet/gnu/12.0/ofi/1.0:1;/opt/cray/pe/lmod/modulefiles/mix_compilers:1;/opt/cray/pe/lmod/modulefiles/compiler/gnu/12.0:1;/soft/modulefiles:1;/opt/cray/pe/lmod/modulefiles/perftools/23.12.0:1;/opt/cray/pe/lmod/modulefiles/net/ofi/1.0:1;/usr/share/modulefiles/Linux:1;/usr/share/modulefiles/Core:1;/usr/share/lmod/lmod/modulefiles/Core:1;/usr/share/lmod/lmod/modulefiles:1;/opt/cray/pals/lmod/modulefiles/core:1;/opt/cray/modulefiles:1;/opt/cray/pe/lmod/modulefiles/core:1;/opt/cray/pe/lmod/modulefiles/craype-targets/default:1;/soft/perftools/darshan/darshan-3.4.4/share/craype-2.x/modulefiles:1;/soft/xalt/modulefiles:1"
declare -x __LMOD_REF_COUNT_PATH="/soft/xalt/3.0.2-202408282050/bin:1;/soft/compilers/cudatoolkit/cuda-12.4.1/bin:1;/soft/libraries/nccl/nccl_2.21.5-1+cuda12.4_x86_64/include:1;/opt/cray/pe/hdf5-parallel/1.12.2.9/bin:1;/opt/cray/pe/hdf5/1.12.2.9/bin:1;/opt/cray/pals/1.3.4/bin:1;/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/bin:1;/opt/cray/pe/mpich/8.1.28/bin:1;/opt/cray/pe/craype/2.7.30/bin:1;/home/shourya01/.local/bin:4;/soft/perftools/darshan/darshan-3.4.4/bin:1;/opt/cray/pe/perftools/23.12.0/bin:1;/opt/cray/pe/papi/7.0.1.2/bin:1;/opt/cray/libfabric/1.15.2.0/bin:1;/opt/clmgr/sbin:1;/opt/clmgr/bin:1;/opt/sgi/sbin:1;/opt/sgi/bin:1;/usr/local/bin:1;/usr/bin:1;/bin:2;/opt/c3/bin:1;/usr/lib/mit/bin:1;/usr/lib/mit/sbin:1;/opt/pbs/bin:1;/sbin:1;/home/shourya01/bin:1;/opt/cray/pe/bin:1"
declare -x __LMOD_REF_COUNT_PE_DSMML_PKGCONFIG_LIBS="dsmml:1"
declare -x __LMOD_REF_COUNT_PE_FORTRAN_PKGCONFIG_LIBS="hdf5hl_fortran_parallel:1;hdf5_fortran_parallel:1;mpichf90:1"
declare -x __LMOD_REF_COUNT_PE_GNU_FIXED_PKGCONFIG_PATH="/opt/cray/pe/mpich/8.1.28/ofi/gnu/12.3/lib/pkgconfig:1"
declare -x __LMOD_REF_COUNT_PE_MPICH_FIXED_PRGENV="GNU:1"
declare -x __LMOD_REF_COUNT_PE_MPICH_FORTRAN_PKGCONFIG_LIBS="mpichf90:1"
declare -x __LMOD_REF_COUNT_PE_MPICH_GENCOMPILERS_GNU="12.3:1"
declare -x __LMOD_REF_COUNT_PE_MPICH_PKGCONFIG_LIBS="mpich:1"
declare -x __LMOD_REF_COUNT_PE_PALS_PKGCONFIG_LIBS="libpals:1"
declare -x __LMOD_REF_COUNT_PE_PKGCONFIG_LIBS="hdf5_hl_parallel:1;hdf5_parallel:1;mpich:1;dsmml:1;darshan-runtime:1"
declare -x __LMOD_REF_COUNT_PE_PKGCONFIG_PRODUCTS="PE_PALS:1;PE_PMI:1;PE_MPICH:1;PE_DSMML:1"
declare -x __LMOD_REF_COUNT_PE_PMI_PKGCONFIG_LIBS="cray-pmi:1"
declare -x __LMOD_REF_COUNT_PE_PRODUCT_LIST="CRAYPE_X86_MILAN:1;PERFTOOLS:1;CRAYPAT:1"
declare -x __LMOD_REF_COUNT_PKG_CONFIG_PATH="/opt/cray/pe/hdf5-parallel/1.12.2.9/gnu/12.3/lib/pkgconfig:1;/opt/cray/pals/1.3.4/lib/pkgconfig:1;/opt/cray/pe/pmi/6.1.13/lib/pkgconfig:1;/opt/cray/pe/dsmml/0.2.2/dsmml/lib/pkgconfig:1;/opt/cray/pe/craype/2.7.30/pkg-config:1;/soft/perftools/darshan/darshan-3.4.4/lib/pkgconfig:1;/opt/cray/libfabric/1.15.2.0/lib64/pkgconfig:1"
declare -x __LMOD_REF_COUNT_PYTHONPATH="/soft/xalt/3.0.2-202408282050/site_packages:1"
declare -x ftp_proxy="http://proxy.alcf.anl.gov:3128"
declare -x http_proxy="http://proxy.alcf.anl.gov:3128"
declare -x https_proxy="http://proxy.alcf.anl.gov:3128"
declare -x no_proxy="admin,polaris-adminvm-01,localhost,*.cm.polaris.alcf.anl.gov,polaris-*,*.polaris.alcf.anl.gov,*.alcf.anl.gov"
Running on 10 nodes
Total number of GPUs: 40
Connected to tcp://x3003c0s13b0n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/applications/conda/2024-04-29/mconda3/bin/python
Launching application 45788fc1-d978-4c33-94fc-84241dda8430
Using PMI port 57110,57111
[2025-06-25 07:10:54,917] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:54,917] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:54,917] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:54,917] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:54,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:54,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:54,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:54,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:55,055] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:55,055] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:55,055] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:55,055] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,064] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,064] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,064] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,064] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,071] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,071] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,071] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,071] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,078] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,078] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,078] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,078] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,086] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,086] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,086] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,086] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,105] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,105] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,105] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,105] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,625] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,625] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,625] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-25 07:10:57,625] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,148] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,148] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,149] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,149] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,149] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,149] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,149] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:00,149] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,898] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,898] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,898] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,898] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,898] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,898] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,898] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:00,898] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,928] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,928] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,928] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,928] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,928] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:00,928] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:00,928] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:00,928] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:02,838] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:02,838] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:02,838] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:02,838] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:02,838] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:02,838] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:02,838] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:02,838] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,343] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,343] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,343] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,343] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,343] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,343] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,343] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:03,343] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,501] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,501] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,501] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,501] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,501] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,501] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,501] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:03,501] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,632] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,632] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,632] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,632] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,632] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,632] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,632] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:03,632] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,811] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,811] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,811] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,811] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,811] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:03,811] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:03,811] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:03,811] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:04,039] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:04,039] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:04,039] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:04,039] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:04,039] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:04,039] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:04,039] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:04,039] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:04,719] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:04,719] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:04,719] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:04,719] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:04,719] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2025-06-25 07:11:04,719] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-06-25 07:11:04,719] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:04,719] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=8, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=12, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=13, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=28, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=29, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=31, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=32, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=20, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=4, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=5, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=9, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=36, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=7, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=10, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=16, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=21, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=37, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=6, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=11, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=15, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=17, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=22, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=24, local_rank=0, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=19, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=23, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=25, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=39, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=14, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=18, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=26, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=30, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=33, local_rank=1, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=27, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=34, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=38, local_rank=2, world_size=40, master_addr=10.140.57.27, master_port=29500
[2025-06-25 07:11:04,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=35, local_rank=3, world_size=40, master_addr=10.140.57.27, master_port=29500
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mean_w = torch.tensor(w.mean(axis=(0,1), keepdims=True), dtype=dtype)
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
/home/shourya01/stormer_deepspeed/stormer_specific_data_utils.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  std_w = torch.tensor(w.std(axis=(0,1), keepdims=True), dtype=dtype) + 1e-6
Initialized deepspeed on global rank 0, local rank 0 with world size 40.
[2025-06-25 07:11:10,226] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:11:33,430] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:11:33,432] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:11:33,432] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:11:33,490] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:11:33,490] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:11:33,490] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:11:33,490] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:11:33,490] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0005], mom=[(0.9, 0.999)]
[2025-06-25 07:11:33,491] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:11:33,491] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:11:33,491] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:11:33,491] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:11:33,491] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15248fcbbf10>
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:11:33,492] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 0.0005, 'weight_decay': 0.01}
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:11:33,493] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:11:33,494] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:11:33,494] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 0.0005, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Validating lr=0.0005, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=0.0005, train epoch 0.:   1%|          | 1/107 [00:01<03:23,  1.92s/it]Validating lr=0.0005, train epoch 0.:   2%|▏         | 2/107 [00:03<02:38,  1.51s/it]Validating lr=0.0005, train epoch 0.:   3%|▎         | 3/107 [00:04<02:23,  1.38s/it]Validating lr=0.0005, train epoch 0.:   4%|▎         | 4/107 [00:05<02:15,  1.32s/it]Validating lr=0.0005, train epoch 0.:   5%|▍         | 5/107 [00:06<02:11,  1.29s/it]Validating lr=0.0005, train epoch 0.:   6%|▌         | 6/107 [00:08<02:06,  1.26s/it]Validating lr=0.0005, train epoch 0.:   7%|▋         | 7/107 [00:09<02:04,  1.24s/it]Validating lr=0.0005, train epoch 0.:   7%|▋         | 8/107 [00:10<02:03,  1.25s/it]Validating lr=0.0005, train epoch 0.:   8%|▊         | 9/107 [00:11<02:01,  1.24s/it]Validating lr=0.0005, train epoch 0.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Validating lr=0.0005, train epoch 0.:  10%|█         | 11/107 [00:14<01:57,  1.23s/it]Validating lr=0.0005, train epoch 0.:  11%|█         | 12/107 [00:15<01:56,  1.23s/it]Validating lr=0.0005, train epoch 0.:  12%|█▏        | 13/107 [00:16<01:54,  1.22s/it]Validating lr=0.0005, train epoch 0.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Validating lr=0.0005, train epoch 0.:  14%|█▍        | 15/107 [00:19<01:53,  1.23s/it]Validating lr=0.0005, train epoch 0.:  15%|█▍        | 16/107 [00:20<01:52,  1.23s/it]Validating lr=0.0005, train epoch 0.:  16%|█▌        | 17/107 [00:21<01:50,  1.23s/it]Validating lr=0.0005, train epoch 0.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Validating lr=0.0005, train epoch 0.:  18%|█▊        | 19/107 [00:23<01:47,  1.23s/it]Validating lr=0.0005, train epoch 0.:  19%|█▊        | 20/107 [00:25<01:47,  1.23s/it]Validating lr=0.0005, train epoch 0.:  20%|█▉        | 21/107 [00:26<01:45,  1.23s/it]Validating lr=0.0005, train epoch 0.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Validating lr=0.0005, train epoch 0.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Validating lr=0.0005, train epoch 0.:  22%|██▏       | 24/107 [00:30<01:41,  1.22s/it]Validating lr=0.0005, train epoch 0.:  23%|██▎       | 25/107 [00:31<01:39,  1.22s/it]Validating lr=0.0005, train epoch 0.:  24%|██▍       | 26/107 [00:32<01:38,  1.22s/it]Validating lr=0.0005, train epoch 0.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Validating lr=0.0005, train epoch 0.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Validating lr=0.0005, train epoch 0.:  27%|██▋       | 29/107 [00:36<01:35,  1.23s/it]Validating lr=0.0005, train epoch 0.:  28%|██▊       | 30/107 [00:37<01:34,  1.22s/it]Validating lr=0.0005, train epoch 0.:  29%|██▉       | 31/107 [00:38<01:32,  1.22s/it]Validating lr=0.0005, train epoch 0.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Validating lr=0.0005, train epoch 0.:  31%|███       | 33/107 [00:41<01:30,  1.23s/it]Validating lr=0.0005, train epoch 0.:  32%|███▏      | 34/107 [00:42<01:29,  1.22s/it]Validating lr=0.0005, train epoch 0.:  33%|███▎      | 35/107 [00:43<01:27,  1.22s/it]Validating lr=0.0005, train epoch 0.:  34%|███▎      | 36/107 [00:44<01:26,  1.21s/it]Validating lr=0.0005, train epoch 0.:  35%|███▍      | 37/107 [00:45<01:24,  1.21s/it]Validating lr=0.0005, train epoch 0.:  36%|███▌      | 38/107 [00:47<01:23,  1.22s/it]Validating lr=0.0005, train epoch 0.:  36%|███▋      | 39/107 [00:48<01:22,  1.21s/it]Validating lr=0.0005, train epoch 0.:  37%|███▋      | 40/107 [00:49<01:21,  1.21s/it]Validating lr=0.0005, train epoch 0.:  38%|███▊      | 41/107 [00:50<01:19,  1.21s/it]Validating lr=0.0005, train epoch 0.:  39%|███▉      | 42/107 [00:52<01:18,  1.21s/it]Validating lr=0.0005, train epoch 0.:  40%|████      | 43/107 [00:53<01:17,  1.21s/it]Validating lr=0.0005, train epoch 0.:  41%|████      | 44/107 [00:54<01:16,  1.22s/it]Validating lr=0.0005, train epoch 0.:  42%|████▏     | 45/107 [00:55<01:15,  1.21s/it]Validating lr=0.0005, train epoch 0.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Validating lr=0.0005, train epoch 0.:  44%|████▍     | 47/107 [00:58<01:12,  1.22s/it]Validating lr=0.0005, train epoch 0.:  45%|████▍     | 48/107 [00:59<01:11,  1.21s/it]Validating lr=0.0005, train epoch 0.:  46%|████▌     | 49/107 [01:00<01:10,  1.22s/it]Validating lr=0.0005, train epoch 0.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Validating lr=0.0005, train epoch 0.:  48%|████▊     | 51/107 [01:02<01:08,  1.21s/it]Validating lr=0.0005, train epoch 0.:  49%|████▊     | 52/107 [01:04<01:06,  1.21s/it]Validating lr=0.0005, train epoch 0.:  50%|████▉     | 53/107 [01:05<01:05,  1.22s/it]Validating lr=0.0005, train epoch 0.:  50%|█████     | 54/107 [01:06<01:04,  1.21s/it]Validating lr=0.0005, train epoch 0.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Validating lr=0.0005, train epoch 0.:  52%|█████▏    | 56/107 [01:09<01:01,  1.21s/it]Validating lr=0.0005, train epoch 0.:  53%|█████▎    | 57/107 [01:10<01:00,  1.21s/it]Validating lr=0.0005, train epoch 0.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Validating lr=0.0005, train epoch 0.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Validating lr=0.0005, train epoch 0.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Validating lr=0.0005, train epoch 0.:  57%|█████▋    | 61/107 [01:15<00:56,  1.22s/it]Validating lr=0.0005, train epoch 0.:  58%|█████▊    | 62/107 [01:16<00:54,  1.22s/it]Validating lr=0.0005, train epoch 0.:  59%|█████▉    | 63/107 [01:17<00:53,  1.23s/it]Validating lr=0.0005, train epoch 0.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Validating lr=0.0005, train epoch 0.:  61%|██████    | 65/107 [01:20<00:51,  1.23s/it]Validating lr=0.0005, train epoch 0.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Validating lr=0.0005, train epoch 0.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Validating lr=0.0005, train epoch 0.:  64%|██████▎   | 68/107 [01:23<00:48,  1.24s/it]Validating lr=0.0005, train epoch 0.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Validating lr=0.0005, train epoch 0.:  65%|██████▌   | 70/107 [01:26<00:45,  1.23s/it]Validating lr=0.0005, train epoch 0.:  66%|██████▋   | 71/107 [01:27<00:44,  1.22s/it]Validating lr=0.0005, train epoch 0.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Validating lr=0.0005, train epoch 0.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Validating lr=0.0005, train epoch 0.:  69%|██████▉   | 74/107 [01:31<00:40,  1.23s/it]Validating lr=0.0005, train epoch 0.:  70%|███████   | 75/107 [01:32<00:39,  1.22s/it]Validating lr=0.0005, train epoch 0.:  71%|███████   | 76/107 [01:33<00:37,  1.22s/it]Validating lr=0.0005, train epoch 0.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Validating lr=0.0005, train epoch 0.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Validating lr=0.0005, train epoch 0.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Validating lr=0.0005, train epoch 0.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Validating lr=0.0005, train epoch 0.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Validating lr=0.0005, train epoch 0.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Validating lr=0.0005, train epoch 0.:  78%|███████▊  | 83/107 [01:42<00:29,  1.22s/it]Validating lr=0.0005, train epoch 0.:  79%|███████▊  | 84/107 [01:43<00:28,  1.22s/it]Validating lr=0.0005, train epoch 0.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Validating lr=0.0005, train epoch 0.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Validating lr=0.0005, train epoch 0.:  81%|████████▏ | 87/107 [01:47<00:24,  1.23s/it]Validating lr=0.0005, train epoch 0.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Validating lr=0.0005, train epoch 0.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Validating lr=0.0005, train epoch 0.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Validating lr=0.0005, train epoch 0.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=0.0005, train epoch 0.:  86%|████████▌ | 92/107 [01:53<00:18,  1.22s/it]Validating lr=0.0005, train epoch 0.:  87%|████████▋ | 93/107 [01:54<00:17,  1.22s/it]Validating lr=0.0005, train epoch 0.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Validating lr=0.0005, train epoch 0.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Validating lr=0.0005, train epoch 0.:  90%|████████▉ | 96/107 [01:58<00:13,  1.23s/it]Validating lr=0.0005, train epoch 0.:  91%|█████████ | 97/107 [01:59<00:12,  1.23s/it]Validating lr=0.0005, train epoch 0.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Validating lr=0.0005, train epoch 0.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=0.0005, train epoch 0.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Validating lr=0.0005, train epoch 0.:  94%|█████████▍| 101/107 [02:04<00:07,  1.22s/it]Validating lr=0.0005, train epoch 0.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Validating lr=0.0005, train epoch 0.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=0.0005, train epoch 0.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Validating lr=0.0005, train epoch 0.:  98%|█████████▊| 105/107 [02:09<00:02,  1.23s/it]Validating lr=0.0005, train epoch 0.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Validating lr=0.0005, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Validating lr=0.0005, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Validating lr=0.0005, train epoch 1.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=0.0005, train epoch 1.:   1%|          | 1/107 [00:01<02:12,  1.25s/it]Validating lr=0.0005, train epoch 1.:   2%|▏         | 2/107 [00:02<02:09,  1.23s/it]Validating lr=0.0005, train epoch 1.:   3%|▎         | 3/107 [00:03<02:07,  1.22s/it]Validating lr=0.0005, train epoch 1.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Validating lr=0.0005, train epoch 1.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Validating lr=0.0005, train epoch 1.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Validating lr=0.0005, train epoch 1.:   7%|▋         | 7/107 [00:08<02:02,  1.22s/it]Validating lr=0.0005, train epoch 1.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Validating lr=0.0005, train epoch 1.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Validating lr=0.0005, train epoch 1.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Validating lr=0.0005, train epoch 1.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Validating lr=0.0005, train epoch 1.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Validating lr=0.0005, train epoch 1.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Validating lr=0.0005, train epoch 1.:  13%|█▎        | 14/107 [00:17<01:52,  1.21s/it]Validating lr=0.0005, train epoch 1.:  14%|█▍        | 15/107 [00:18<01:51,  1.21s/it]Validating lr=0.0005, train epoch 1.:  15%|█▍        | 16/107 [00:19<01:49,  1.21s/it]Validating lr=0.0005, train epoch 1.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Validating lr=0.0005, train epoch 1.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Validating lr=0.0005, train epoch 1.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Validating lr=0.0005, train epoch 1.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Validating lr=0.0005, train epoch 1.:  20%|█▉        | 21/107 [00:25<01:46,  1.24s/it]Validating lr=0.0005, train epoch 1.:  21%|██        | 22/107 [00:27<01:46,  1.26s/it]Validating lr=0.0005, train epoch 1.:  21%|██▏       | 23/107 [00:28<01:44,  1.25s/it]Validating lr=0.0005, train epoch 1.:  22%|██▏       | 24/107 [00:29<01:42,  1.24s/it]Validating lr=0.0005, train epoch 1.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Validating lr=0.0005, train epoch 1.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Validating lr=0.0005, train epoch 1.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Validating lr=0.0005, train epoch 1.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Validating lr=0.0005, train epoch 1.:  27%|██▋       | 29/107 [00:35<01:34,  1.22s/it]Validating lr=0.0005, train epoch 1.:  28%|██▊       | 30/107 [00:36<01:33,  1.22s/it]Validating lr=0.0005, train epoch 1.:  29%|██▉       | 31/107 [00:38<01:32,  1.22s/it]Validating lr=0.0005, train epoch 1.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Validating lr=0.0005, train epoch 1.:  31%|███       | 33/107 [00:40<01:30,  1.22s/it]Validating lr=0.0005, train epoch 1.:  32%|███▏      | 34/107 [00:41<01:28,  1.22s/it]Validating lr=0.0005, train epoch 1.:  33%|███▎      | 35/107 [00:42<01:27,  1.21s/it]Validating lr=0.0005, train epoch 1.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Validating lr=0.0005, train epoch 1.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Validating lr=0.0005, train epoch 1.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Validating lr=0.0005, train epoch 1.:  36%|███▋      | 39/107 [00:47<01:22,  1.22s/it]Validating lr=0.0005, train epoch 1.:  37%|███▋      | 40/107 [00:48<01:22,  1.22s/it]Validating lr=0.0005, train epoch 1.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Validating lr=0.0005, train epoch 1.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Validating lr=0.0005, train epoch 1.:  40%|████      | 43/107 [00:52<01:17,  1.22s/it]Validating lr=0.0005, train epoch 1.:  41%|████      | 44/107 [00:53<01:16,  1.22s/it]Validating lr=0.0005, train epoch 1.:  42%|████▏     | 45/107 [00:55<01:15,  1.21s/it]Validating lr=0.0005, train epoch 1.:  43%|████▎     | 46/107 [00:56<01:14,  1.21s/it]Validating lr=0.0005, train epoch 1.:  44%|████▍     | 47/107 [00:57<01:12,  1.21s/it]Validating lr=0.0005, train epoch 1.:  45%|████▍     | 48/107 [00:58<01:11,  1.22s/it]Validating lr=0.0005, train epoch 1.:  46%|████▌     | 49/107 [00:59<01:10,  1.22s/it]Validating lr=0.0005, train epoch 1.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Validating lr=0.0005, train epoch 1.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Validating lr=0.0005, train epoch 1.:  49%|████▊     | 52/107 [01:03<01:07,  1.23s/it]Validating lr=0.0005, train epoch 1.:  50%|████▉     | 53/107 [01:04<01:05,  1.22s/it]Validating lr=0.0005, train epoch 1.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Validating lr=0.0005, train epoch 1.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Validating lr=0.0005, train epoch 1.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Validating lr=0.0005, train epoch 1.:  53%|█████▎    | 57/107 [01:09<01:01,  1.22s/it]Validating lr=0.0005, train epoch 1.:  54%|█████▍    | 58/107 [01:10<00:59,  1.22s/it]Validating lr=0.0005, train epoch 1.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Validating lr=0.0005, train epoch 1.:  56%|█████▌    | 60/107 [01:13<00:56,  1.21s/it]Validating lr=0.0005, train epoch 1.:  57%|█████▋    | 61/107 [01:14<00:55,  1.22s/it]Validating lr=0.0005, train epoch 1.:  58%|█████▊    | 62/107 [01:15<00:54,  1.22s/it]Validating lr=0.0005, train epoch 1.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Validating lr=0.0005, train epoch 1.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Validating lr=0.0005, train epoch 1.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Validating lr=0.0005, train epoch 1.:  62%|██████▏   | 66/107 [01:20<00:49,  1.22s/it]Validating lr=0.0005, train epoch 1.:  63%|██████▎   | 67/107 [01:21<00:49,  1.23s/it]Validating lr=0.0005, train epoch 1.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Validating lr=0.0005, train epoch 1.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Validating lr=0.0005, train epoch 1.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Validating lr=0.0005, train epoch 1.:  66%|██████▋   | 71/107 [01:26<00:44,  1.23s/it]Validating lr=0.0005, train epoch 1.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Validating lr=0.0005, train epoch 1.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Validating lr=0.0005, train epoch 1.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Validating lr=0.0005, train epoch 1.:  70%|███████   | 75/107 [01:31<00:38,  1.21s/it]Validating lr=0.0005, train epoch 1.:  71%|███████   | 76/107 [01:32<00:37,  1.21s/it]Validating lr=0.0005, train epoch 1.:  72%|███████▏  | 77/107 [01:34<00:36,  1.21s/it]Validating lr=0.0005, train epoch 1.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Validating lr=0.0005, train epoch 1.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Validating lr=0.0005, train epoch 1.:  75%|███████▍  | 80/107 [01:37<00:32,  1.21s/it]Validating lr=0.0005, train epoch 1.:  76%|███████▌  | 81/107 [01:38<00:31,  1.22s/it]Validating lr=0.0005, train epoch 1.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Validating lr=0.0005, train epoch 1.:  78%|███████▊  | 83/107 [01:41<00:29,  1.22s/it]Validating lr=0.0005, train epoch 1.:  79%|███████▊  | 84/107 [01:42<00:28,  1.22s/it]Validating lr=0.0005, train epoch 1.:  79%|███████▉  | 85/107 [01:43<00:27,  1.23s/it]Validating lr=0.0005, train epoch 1.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Validating lr=0.0005, train epoch 1.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Validating lr=0.0005, train epoch 1.:  82%|████████▏ | 88/107 [01:47<00:23,  1.23s/it]Validating lr=0.0005, train epoch 1.:  83%|████████▎ | 89/107 [01:48<00:22,  1.23s/it]Validating lr=0.0005, train epoch 1.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Validating lr=0.0005, train epoch 1.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=0.0005, train epoch 1.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Validating lr=0.0005, train epoch 1.:  87%|████████▋ | 93/107 [01:53<00:17,  1.23s/it]Validating lr=0.0005, train epoch 1.:  88%|████████▊ | 94/107 [01:54<00:15,  1.23s/it]Validating lr=0.0005, train epoch 1.:  89%|████████▉ | 95/107 [01:56<00:14,  1.24s/it]Validating lr=0.0005, train epoch 1.:  90%|████████▉ | 96/107 [01:57<00:13,  1.24s/it]Validating lr=0.0005, train epoch 1.:  91%|█████████ | 97/107 [01:58<00:12,  1.24s/it]Validating lr=0.0005, train epoch 1.:  92%|█████████▏| 98/107 [01:59<00:11,  1.23s/it]Validating lr=0.0005, train epoch 1.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=0.0005, train epoch 1.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Validating lr=0.0005, train epoch 1.:  94%|█████████▍| 101/107 [02:03<00:07,  1.23s/it]Validating lr=0.0005, train epoch 1.:  95%|█████████▌| 102/107 [02:04<00:06,  1.23s/it]Validating lr=0.0005, train epoch 1.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=0.0005, train epoch 1.:  97%|█████████▋| 104/107 [02:07<00:03,  1.24s/it]Validating lr=0.0005, train epoch 1.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Validating lr=0.0005, train epoch 1.:  99%|█████████▉| 106/107 [02:09<00:01,  1.23s/it]Validating lr=0.0005, train epoch 1.: 100%|██████████| 107/107 [02:10<00:00,  1.22s/it]Validating lr=0.0005, train epoch 1.: 100%|██████████| 107/107 [02:10<00:00,  1.22s/it]
Evaluating for lr=0.0005:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating for lr=0.0005:   9%|▉         | 1/11 [00:00<00:04,  2.13it/s]Evaluating for lr=0.0005:  18%|█▊        | 2/11 [00:00<00:04,  2.10it/s]Evaluating for lr=0.0005:  27%|██▋       | 3/11 [00:01<00:03,  2.09it/s]Evaluating for lr=0.0005:  36%|███▋      | 4/11 [00:01<00:03,  2.08it/s]Evaluating for lr=0.0005:  45%|████▌     | 5/11 [00:02<00:02,  2.05it/s]Evaluating for lr=0.0005:  55%|█████▍    | 6/11 [00:02<00:02,  2.03it/s]Evaluating for lr=0.0005:  64%|██████▎   | 7/11 [00:03<00:02,  2.00it/s]Evaluating for lr=0.0005:  73%|███████▎  | 8/11 [00:03<00:01,  2.00it/s]Evaluating for lr=0.0005:  82%|████████▏ | 9/11 [00:04<00:01,  2.00it/s]Evaluating for lr=0.0005:  91%|█████████ | 10/11 [00:04<00:00,  1.97it/s]Evaluating for lr=0.0005: 100%|██████████| 11/11 [00:05<00:00,  1.98it/s]Evaluating for lr=0.0005: 100%|██████████| 11/11 [00:05<00:00,  2.02it/s]
[2025-06-25 07:16:01,981] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:16:23,463] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:16:23,465] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:16:23,465] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:16:23,528] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:16:23,528] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:16:23,528] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:16:23,528] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:16:23,528] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[(0.9, 0.999)]
[2025-06-25 07:16:23,528] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:16:23,528] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15248fb65d10>
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:16:23,529] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 0.0001, 'weight_decay': 0.01}
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:16:23,530] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:16:23,530] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 0.0001, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Validating lr=0.0001, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=0.0001, train epoch 0.:   1%|          | 1/107 [00:01<02:25,  1.37s/it]Validating lr=0.0001, train epoch 0.:   2%|▏         | 2/107 [00:02<02:15,  1.29s/it]Validating lr=0.0001, train epoch 0.:   3%|▎         | 3/107 [00:03<02:11,  1.26s/it]Validating lr=0.0001, train epoch 0.:   4%|▎         | 4/107 [00:05<02:08,  1.25s/it]Validating lr=0.0001, train epoch 0.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Validating lr=0.0001, train epoch 0.:   6%|▌         | 6/107 [00:07<02:05,  1.24s/it]Validating lr=0.0001, train epoch 0.:   7%|▋         | 7/107 [00:08<02:02,  1.23s/it]Validating lr=0.0001, train epoch 0.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Validating lr=0.0001, train epoch 0.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Validating lr=0.0001, train epoch 0.:   9%|▉         | 10/107 [00:12<01:58,  1.23s/it]Validating lr=0.0001, train epoch 0.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Validating lr=0.0001, train epoch 0.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Validating lr=0.0001, train epoch 0.:  12%|█▏        | 13/107 [00:16<01:55,  1.22s/it]Validating lr=0.0001, train epoch 0.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Validating lr=0.0001, train epoch 0.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Validating lr=0.0001, train epoch 0.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Validating lr=0.0001, train epoch 0.:  16%|█▌        | 17/107 [00:21<01:51,  1.23s/it]Validating lr=0.0001, train epoch 0.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Validating lr=0.0001, train epoch 0.:  18%|█▊        | 19/107 [00:23<01:48,  1.24s/it]Validating lr=0.0001, train epoch 0.:  19%|█▊        | 20/107 [00:24<01:47,  1.23s/it]Validating lr=0.0001, train epoch 0.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Validating lr=0.0001, train epoch 0.:  21%|██        | 22/107 [00:27<01:43,  1.22s/it]Validating lr=0.0001, train epoch 0.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Validating lr=0.0001, train epoch 0.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Validating lr=0.0001, train epoch 0.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Validating lr=0.0001, train epoch 0.:  24%|██▍       | 26/107 [00:32<01:39,  1.23s/it]Validating lr=0.0001, train epoch 0.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Validating lr=0.0001, train epoch 0.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Validating lr=0.0001, train epoch 0.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Validating lr=0.0001, train epoch 0.:  28%|██▊       | 30/107 [00:36<01:35,  1.24s/it]Validating lr=0.0001, train epoch 0.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Validating lr=0.0001, train epoch 0.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Validating lr=0.0001, train epoch 0.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Validating lr=0.0001, train epoch 0.:  32%|███▏      | 34/107 [00:41<01:29,  1.22s/it]Validating lr=0.0001, train epoch 0.:  33%|███▎      | 35/107 [00:43<01:28,  1.22s/it]Validating lr=0.0001, train epoch 0.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=0.0001, train epoch 0.:  35%|███▍      | 37/107 [00:45<01:25,  1.23s/it]Validating lr=0.0001, train epoch 0.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Validating lr=0.0001, train epoch 0.:  36%|███▋      | 39/107 [00:48<01:23,  1.22s/it]Validating lr=0.0001, train epoch 0.:  37%|███▋      | 40/107 [00:49<01:22,  1.22s/it]Validating lr=0.0001, train epoch 0.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Validating lr=0.0001, train epoch 0.:  39%|███▉      | 42/107 [00:51<01:20,  1.23s/it]Validating lr=0.0001, train epoch 0.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Validating lr=0.0001, train epoch 0.:  41%|████      | 44/107 [00:54<01:17,  1.23s/it]Validating lr=0.0001, train epoch 0.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Validating lr=0.0001, train epoch 0.:  43%|████▎     | 46/107 [00:56<01:14,  1.23s/it]Validating lr=0.0001, train epoch 0.:  44%|████▍     | 47/107 [00:57<01:14,  1.24s/it]Validating lr=0.0001, train epoch 0.:  45%|████▍     | 48/107 [00:59<01:13,  1.24s/it]Validating lr=0.0001, train epoch 0.:  46%|████▌     | 49/107 [01:00<01:11,  1.24s/it]Validating lr=0.0001, train epoch 0.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Validating lr=0.0001, train epoch 0.:  48%|████▊     | 51/107 [01:02<01:09,  1.25s/it]Validating lr=0.0001, train epoch 0.:  49%|████▊     | 52/107 [01:04<01:08,  1.25s/it]Validating lr=0.0001, train epoch 0.:  50%|████▉     | 53/107 [01:05<01:06,  1.24s/it]Validating lr=0.0001, train epoch 0.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Validating lr=0.0001, train epoch 0.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Validating lr=0.0001, train epoch 0.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Validating lr=0.0001, train epoch 0.:  53%|█████▎    | 57/107 [01:10<01:01,  1.23s/it]Validating lr=0.0001, train epoch 0.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Validating lr=0.0001, train epoch 0.:  55%|█████▌    | 59/107 [01:12<00:59,  1.23s/it]Validating lr=0.0001, train epoch 0.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Validating lr=0.0001, train epoch 0.:  57%|█████▋    | 61/107 [01:15<00:56,  1.23s/it]Validating lr=0.0001, train epoch 0.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Validating lr=0.0001, train epoch 0.:  59%|█████▉    | 63/107 [01:17<00:54,  1.24s/it]Validating lr=0.0001, train epoch 0.:  60%|█████▉    | 64/107 [01:18<00:53,  1.24s/it]Validating lr=0.0001, train epoch 0.:  61%|██████    | 65/107 [01:20<00:51,  1.23s/it]Validating lr=0.0001, train epoch 0.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Validating lr=0.0001, train epoch 0.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Validating lr=0.0001, train epoch 0.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Validating lr=0.0001, train epoch 0.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Validating lr=0.0001, train epoch 0.:  65%|██████▌   | 70/107 [01:26<00:45,  1.23s/it]Validating lr=0.0001, train epoch 0.:  66%|██████▋   | 71/107 [01:27<00:44,  1.22s/it]Validating lr=0.0001, train epoch 0.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Validating lr=0.0001, train epoch 0.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Validating lr=0.0001, train epoch 0.:  69%|██████▉   | 74/107 [01:31<00:40,  1.23s/it]Validating lr=0.0001, train epoch 0.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Validating lr=0.0001, train epoch 0.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Validating lr=0.0001, train epoch 0.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Validating lr=0.0001, train epoch 0.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Validating lr=0.0001, train epoch 0.:  74%|███████▍  | 79/107 [01:37<00:34,  1.22s/it]Validating lr=0.0001, train epoch 0.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Validating lr=0.0001, train epoch 0.:  76%|███████▌  | 81/107 [01:39<00:32,  1.23s/it]Validating lr=0.0001, train epoch 0.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=0.0001, train epoch 0.:  78%|███████▊  | 83/107 [01:42<00:29,  1.23s/it]Validating lr=0.0001, train epoch 0.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Validating lr=0.0001, train epoch 0.:  79%|███████▉  | 85/107 [01:44<00:27,  1.23s/it]Validating lr=0.0001, train epoch 0.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Validating lr=0.0001, train epoch 0.:  81%|████████▏ | 87/107 [01:47<00:24,  1.23s/it]Validating lr=0.0001, train epoch 0.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Validating lr=0.0001, train epoch 0.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Validating lr=0.0001, train epoch 0.:  84%|████████▍ | 90/107 [01:50<00:20,  1.22s/it]Validating lr=0.0001, train epoch 0.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=0.0001, train epoch 0.:  86%|████████▌ | 92/107 [01:53<00:18,  1.23s/it]Validating lr=0.0001, train epoch 0.:  87%|████████▋ | 93/107 [01:54<00:17,  1.22s/it]Validating lr=0.0001, train epoch 0.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Validating lr=0.0001, train epoch 0.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Validating lr=0.0001, train epoch 0.:  90%|████████▉ | 96/107 [01:58<00:13,  1.23s/it]Validating lr=0.0001, train epoch 0.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Validating lr=0.0001, train epoch 0.:  92%|█████████▏| 98/107 [02:00<00:10,  1.22s/it]Validating lr=0.0001, train epoch 0.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Validating lr=0.0001, train epoch 0.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Validating lr=0.0001, train epoch 0.:  94%|█████████▍| 101/107 [02:04<00:07,  1.22s/it]Validating lr=0.0001, train epoch 0.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Validating lr=0.0001, train epoch 0.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Validating lr=0.0001, train epoch 0.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Validating lr=0.0001, train epoch 0.:  98%|█████████▊| 105/107 [02:09<00:02,  1.22s/it]Validating lr=0.0001, train epoch 0.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Validating lr=0.0001, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Validating lr=0.0001, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Validating lr=0.0001, train epoch 1.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=0.0001, train epoch 1.:   1%|          | 1/107 [00:01<02:11,  1.24s/it]Validating lr=0.0001, train epoch 1.:   2%|▏         | 2/107 [00:02<02:08,  1.23s/it]Validating lr=0.0001, train epoch 1.:   3%|▎         | 3/107 [00:03<02:07,  1.23s/it]Validating lr=0.0001, train epoch 1.:   4%|▎         | 4/107 [00:04<02:06,  1.23s/it]Validating lr=0.0001, train epoch 1.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Validating lr=0.0001, train epoch 1.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Validating lr=0.0001, train epoch 1.:   7%|▋         | 7/107 [00:08<02:03,  1.23s/it]Validating lr=0.0001, train epoch 1.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Validating lr=0.0001, train epoch 1.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Validating lr=0.0001, train epoch 1.:   9%|▉         | 10/107 [00:12<01:58,  1.23s/it]Validating lr=0.0001, train epoch 1.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Validating lr=0.0001, train epoch 1.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Validating lr=0.0001, train epoch 1.:  12%|█▏        | 13/107 [00:15<01:54,  1.21s/it]Validating lr=0.0001, train epoch 1.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Validating lr=0.0001, train epoch 1.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Validating lr=0.0001, train epoch 1.:  15%|█▍        | 16/107 [00:19<01:50,  1.22s/it]Validating lr=0.0001, train epoch 1.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Validating lr=0.0001, train epoch 1.:  17%|█▋        | 18/107 [00:21<01:48,  1.21s/it]Validating lr=0.0001, train epoch 1.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Validating lr=0.0001, train epoch 1.:  19%|█▊        | 20/107 [00:24<01:46,  1.22s/it]Validating lr=0.0001, train epoch 1.:  20%|█▉        | 21/107 [00:25<01:45,  1.22s/it]Validating lr=0.0001, train epoch 1.:  21%|██        | 22/107 [00:26<01:44,  1.23s/it]Validating lr=0.0001, train epoch 1.:  21%|██▏       | 23/107 [00:28<01:43,  1.23s/it]Validating lr=0.0001, train epoch 1.:  22%|██▏       | 24/107 [00:29<01:42,  1.23s/it]Validating lr=0.0001, train epoch 1.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Validating lr=0.0001, train epoch 1.:  24%|██▍       | 26/107 [00:31<01:39,  1.22s/it]Validating lr=0.0001, train epoch 1.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Validating lr=0.0001, train epoch 1.:  26%|██▌       | 28/107 [00:34<01:36,  1.23s/it]Validating lr=0.0001, train epoch 1.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Validating lr=0.0001, train epoch 1.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Validating lr=0.0001, train epoch 1.:  29%|██▉       | 31/107 [00:37<01:33,  1.23s/it]Validating lr=0.0001, train epoch 1.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Validating lr=0.0001, train epoch 1.:  31%|███       | 33/107 [00:40<01:30,  1.22s/it]Validating lr=0.0001, train epoch 1.:  32%|███▏      | 34/107 [00:41<01:29,  1.22s/it]Validating lr=0.0001, train epoch 1.:  33%|███▎      | 35/107 [00:42<01:27,  1.22s/it]Validating lr=0.0001, train epoch 1.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Validating lr=0.0001, train epoch 1.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Validating lr=0.0001, train epoch 1.:  36%|███▌      | 38/107 [00:46<01:25,  1.23s/it]Validating lr=0.0001, train epoch 1.:  36%|███▋      | 39/107 [00:47<01:23,  1.24s/it]Validating lr=0.0001, train epoch 1.:  37%|███▋      | 40/107 [00:49<01:22,  1.24s/it]Validating lr=0.0001, train epoch 1.:  38%|███▊      | 41/107 [00:50<01:20,  1.23s/it]Validating lr=0.0001, train epoch 1.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Validating lr=0.0001, train epoch 1.:  40%|████      | 43/107 [00:52<01:17,  1.22s/it]Validating lr=0.0001, train epoch 1.:  41%|████      | 44/107 [00:53<01:16,  1.21s/it]Validating lr=0.0001, train epoch 1.:  42%|████▏     | 45/107 [00:55<01:15,  1.21s/it]Validating lr=0.0001, train epoch 1.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Validating lr=0.0001, train epoch 1.:  44%|████▍     | 47/107 [00:57<01:12,  1.21s/it]Validating lr=0.0001, train epoch 1.:  45%|████▍     | 48/107 [00:58<01:11,  1.21s/it]Validating lr=0.0001, train epoch 1.:  46%|████▌     | 49/107 [00:59<01:10,  1.21s/it]Validating lr=0.0001, train epoch 1.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Validating lr=0.0001, train epoch 1.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Validating lr=0.0001, train epoch 1.:  49%|████▊     | 52/107 [01:03<01:07,  1.23s/it]Validating lr=0.0001, train epoch 1.:  50%|████▉     | 53/107 [01:04<01:06,  1.23s/it]Validating lr=0.0001, train epoch 1.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Validating lr=0.0001, train epoch 1.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Validating lr=0.0001, train epoch 1.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Validating lr=0.0001, train epoch 1.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Validating lr=0.0001, train epoch 1.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Validating lr=0.0001, train epoch 1.:  55%|█████▌    | 59/107 [01:12<00:59,  1.23s/it]Validating lr=0.0001, train epoch 1.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Validating lr=0.0001, train epoch 1.:  57%|█████▋    | 61/107 [01:14<00:56,  1.22s/it]Validating lr=0.0001, train epoch 1.:  58%|█████▊    | 62/107 [01:15<00:54,  1.22s/it]Validating lr=0.0001, train epoch 1.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Validating lr=0.0001, train epoch 1.:  60%|█████▉    | 64/107 [01:18<00:53,  1.23s/it]Validating lr=0.0001, train epoch 1.:  61%|██████    | 65/107 [01:19<00:52,  1.24s/it]Validating lr=0.0001, train epoch 1.:  62%|██████▏   | 66/107 [01:20<00:50,  1.23s/it]Validating lr=0.0001, train epoch 1.:  63%|██████▎   | 67/107 [01:22<00:49,  1.24s/it]Validating lr=0.0001, train epoch 1.:  64%|██████▎   | 68/107 [01:23<00:48,  1.23s/it]Validating lr=0.0001, train epoch 1.:  64%|██████▍   | 69/107 [01:24<00:47,  1.24s/it]Validating lr=0.0001, train epoch 1.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Validating lr=0.0001, train epoch 1.:  66%|██████▋   | 71/107 [01:27<00:44,  1.24s/it]Validating lr=0.0001, train epoch 1.:  67%|██████▋   | 72/107 [01:28<00:43,  1.24s/it]Validating lr=0.0001, train epoch 1.:  68%|██████▊   | 73/107 [01:29<00:42,  1.24s/it]Validating lr=0.0001, train epoch 1.:  69%|██████▉   | 74/107 [01:30<00:40,  1.24s/it]Validating lr=0.0001, train epoch 1.:  70%|███████   | 75/107 [01:31<00:39,  1.23s/it]Validating lr=0.0001, train epoch 1.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Validating lr=0.0001, train epoch 1.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Validating lr=0.0001, train epoch 1.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Validating lr=0.0001, train epoch 1.:  74%|███████▍  | 79/107 [01:36<00:34,  1.23s/it]Validating lr=0.0001, train epoch 1.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Validating lr=0.0001, train epoch 1.:  76%|███████▌  | 81/107 [01:39<00:32,  1.23s/it]Validating lr=0.0001, train epoch 1.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=0.0001, train epoch 1.:  78%|███████▊  | 83/107 [01:41<00:29,  1.22s/it]Validating lr=0.0001, train epoch 1.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Validating lr=0.0001, train epoch 1.:  79%|███████▉  | 85/107 [01:44<00:26,  1.23s/it]Validating lr=0.0001, train epoch 1.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Validating lr=0.0001, train epoch 1.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Validating lr=0.0001, train epoch 1.:  82%|████████▏ | 88/107 [01:47<00:23,  1.23s/it]Validating lr=0.0001, train epoch 1.:  83%|████████▎ | 89/107 [01:49<00:22,  1.24s/it]Validating lr=0.0001, train epoch 1.:  84%|████████▍ | 90/107 [01:50<00:21,  1.24s/it]Validating lr=0.0001, train epoch 1.:  85%|████████▌ | 91/107 [01:51<00:19,  1.24s/it]Validating lr=0.0001, train epoch 1.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Validating lr=0.0001, train epoch 1.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Validating lr=0.0001, train epoch 1.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Validating lr=0.0001, train epoch 1.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Validating lr=0.0001, train epoch 1.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Validating lr=0.0001, train epoch 1.:  91%|█████████ | 97/107 [01:58<00:12,  1.22s/it]Validating lr=0.0001, train epoch 1.:  92%|█████████▏| 98/107 [02:00<00:11,  1.22s/it]Validating lr=0.0001, train epoch 1.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=0.0001, train epoch 1.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Validating lr=0.0001, train epoch 1.:  94%|█████████▍| 101/107 [02:03<00:07,  1.23s/it]Validating lr=0.0001, train epoch 1.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Validating lr=0.0001, train epoch 1.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=0.0001, train epoch 1.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Validating lr=0.0001, train epoch 1.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Validating lr=0.0001, train epoch 1.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Validating lr=0.0001, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Validating lr=0.0001, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Evaluating for lr=0.0001:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating for lr=0.0001:   9%|▉         | 1/11 [00:00<00:05,  1.98it/s]Evaluating for lr=0.0001:  18%|█▊        | 2/11 [00:00<00:04,  2.05it/s]Evaluating for lr=0.0001:  27%|██▋       | 3/11 [00:01<00:03,  2.07it/s]Evaluating for lr=0.0001:  36%|███▋      | 4/11 [00:01<00:03,  2.07it/s]Evaluating for lr=0.0001:  45%|████▌     | 5/11 [00:02<00:02,  2.05it/s]Evaluating for lr=0.0001:  55%|█████▍    | 6/11 [00:02<00:02,  2.09it/s]Evaluating for lr=0.0001:  64%|██████▎   | 7/11 [00:03<00:01,  2.08it/s]Evaluating for lr=0.0001:  73%|███████▎  | 8/11 [00:03<00:01,  2.08it/s]Evaluating for lr=0.0001:  82%|████████▏ | 9/11 [00:04<00:00,  2.08it/s]Evaluating for lr=0.0001:  91%|█████████ | 10/11 [00:04<00:00,  2.08it/s]Evaluating for lr=0.0001: 100%|██████████| 11/11 [00:05<00:00,  2.05it/s]Evaluating for lr=0.0001: 100%|██████████| 11/11 [00:05<00:00,  2.06it/s]
[2025-06-25 07:20:52,192] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:21:14,044] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:21:14,046] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:21:14,046] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:21:14,109] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:21:14,109] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:21:14,109] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:21:14,109] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:21:14,109] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]
[2025-06-25 07:21:14,109] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:21:14,109] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:21:14,109] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:21:14,109] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:21:14,109] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:21:14,109] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x152484ac3e50>
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 5e-05, 'weight_decay': 0.01}
[2025-06-25 07:21:14,110] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:21:14,111] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:21:14,111] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 5e-05, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Validating lr=5e-05, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=5e-05, train epoch 0.:   1%|          | 1/107 [00:01<02:21,  1.34s/it]Validating lr=5e-05, train epoch 0.:   2%|▏         | 2/107 [00:02<02:13,  1.27s/it]Validating lr=5e-05, train epoch 0.:   3%|▎         | 3/107 [00:03<02:08,  1.24s/it]Validating lr=5e-05, train epoch 0.:   4%|▎         | 4/107 [00:04<02:06,  1.23s/it]Validating lr=5e-05, train epoch 0.:   5%|▍         | 5/107 [00:06<02:04,  1.22s/it]Validating lr=5e-05, train epoch 0.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Validating lr=5e-05, train epoch 0.:   7%|▋         | 7/107 [00:08<02:02,  1.23s/it]Validating lr=5e-05, train epoch 0.:   7%|▋         | 8/107 [00:09<02:00,  1.22s/it]Validating lr=5e-05, train epoch 0.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Validating lr=5e-05, train epoch 0.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Validating lr=5e-05, train epoch 0.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Validating lr=5e-05, train epoch 0.:  11%|█         | 12/107 [00:14<01:55,  1.22s/it]Validating lr=5e-05, train epoch 0.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Validating lr=5e-05, train epoch 0.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Validating lr=5e-05, train epoch 0.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Validating lr=5e-05, train epoch 0.:  15%|█▍        | 16/107 [00:19<01:51,  1.23s/it]Validating lr=5e-05, train epoch 0.:  16%|█▌        | 17/107 [00:20<01:50,  1.22s/it]Validating lr=5e-05, train epoch 0.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Validating lr=5e-05, train epoch 0.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Validating lr=5e-05, train epoch 0.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Validating lr=5e-05, train epoch 0.:  20%|█▉        | 21/107 [00:25<01:45,  1.22s/it]Validating lr=5e-05, train epoch 0.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Validating lr=5e-05, train epoch 0.:  21%|██▏       | 23/107 [00:28<01:43,  1.23s/it]Validating lr=5e-05, train epoch 0.:  22%|██▏       | 24/107 [00:29<01:42,  1.24s/it]Validating lr=5e-05, train epoch 0.:  23%|██▎       | 25/107 [00:30<01:41,  1.23s/it]Validating lr=5e-05, train epoch 0.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Validating lr=5e-05, train epoch 0.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Validating lr=5e-05, train epoch 0.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Validating lr=5e-05, train epoch 0.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Validating lr=5e-05, train epoch 0.:  28%|██▊       | 30/107 [00:36<01:34,  1.22s/it]Validating lr=5e-05, train epoch 0.:  29%|██▉       | 31/107 [00:38<01:32,  1.22s/it]Validating lr=5e-05, train epoch 0.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Validating lr=5e-05, train epoch 0.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Validating lr=5e-05, train epoch 0.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Validating lr=5e-05, train epoch 0.:  33%|███▎      | 35/107 [00:43<01:28,  1.23s/it]Validating lr=5e-05, train epoch 0.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=5e-05, train epoch 0.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Validating lr=5e-05, train epoch 0.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Validating lr=5e-05, train epoch 0.:  36%|███▋      | 39/107 [00:47<01:23,  1.22s/it]Validating lr=5e-05, train epoch 0.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Validating lr=5e-05, train epoch 0.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Validating lr=5e-05, train epoch 0.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Validating lr=5e-05, train epoch 0.:  40%|████      | 43/107 [00:52<01:17,  1.22s/it]Validating lr=5e-05, train epoch 0.:  41%|████      | 44/107 [00:53<01:16,  1.21s/it]Validating lr=5e-05, train epoch 0.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Validating lr=5e-05, train epoch 0.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Validating lr=5e-05, train epoch 0.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Validating lr=5e-05, train epoch 0.:  45%|████▍     | 48/107 [00:58<01:12,  1.23s/it]Validating lr=5e-05, train epoch 0.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Validating lr=5e-05, train epoch 0.:  47%|████▋     | 50/107 [01:01<01:09,  1.23s/it]Validating lr=5e-05, train epoch 0.:  48%|████▊     | 51/107 [01:02<01:07,  1.21s/it]Validating lr=5e-05, train epoch 0.:  49%|████▊     | 52/107 [01:03<01:06,  1.21s/it]Validating lr=5e-05, train epoch 0.:  50%|████▉     | 53/107 [01:04<01:05,  1.21s/it]Validating lr=5e-05, train epoch 0.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Validating lr=5e-05, train epoch 0.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Validating lr=5e-05, train epoch 0.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Validating lr=5e-05, train epoch 0.:  53%|█████▎    | 57/107 [01:09<01:00,  1.21s/it]Validating lr=5e-05, train epoch 0.:  54%|█████▍    | 58/107 [01:11<00:59,  1.21s/it]Validating lr=5e-05, train epoch 0.:  55%|█████▌    | 59/107 [01:12<00:58,  1.21s/it]Validating lr=5e-05, train epoch 0.:  56%|█████▌    | 60/107 [01:13<00:56,  1.21s/it]Validating lr=5e-05, train epoch 0.:  57%|█████▋    | 61/107 [01:14<00:55,  1.22s/it]Validating lr=5e-05, train epoch 0.:  58%|█████▊    | 62/107 [01:15<00:54,  1.22s/it]Validating lr=5e-05, train epoch 0.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Validating lr=5e-05, train epoch 0.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Validating lr=5e-05, train epoch 0.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Validating lr=5e-05, train epoch 0.:  62%|██████▏   | 66/107 [01:20<00:50,  1.22s/it]Validating lr=5e-05, train epoch 0.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Validating lr=5e-05, train epoch 0.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Validating lr=5e-05, train epoch 0.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Validating lr=5e-05, train epoch 0.:  65%|██████▌   | 70/107 [01:25<00:45,  1.22s/it]Validating lr=5e-05, train epoch 0.:  66%|██████▋   | 71/107 [01:26<00:43,  1.21s/it]Validating lr=5e-05, train epoch 0.:  67%|██████▋   | 72/107 [01:28<00:42,  1.21s/it]Validating lr=5e-05, train epoch 0.:  68%|██████▊   | 73/107 [01:29<00:41,  1.21s/it]Validating lr=5e-05, train epoch 0.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Validating lr=5e-05, train epoch 0.:  70%|███████   | 75/107 [01:31<00:38,  1.22s/it]Validating lr=5e-05, train epoch 0.:  71%|███████   | 76/107 [01:32<00:37,  1.22s/it]Validating lr=5e-05, train epoch 0.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Validating lr=5e-05, train epoch 0.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Validating lr=5e-05, train epoch 0.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Validating lr=5e-05, train epoch 0.:  75%|███████▍  | 80/107 [01:37<00:33,  1.23s/it]Validating lr=5e-05, train epoch 0.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Validating lr=5e-05, train epoch 0.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=5e-05, train epoch 0.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Validating lr=5e-05, train epoch 0.:  79%|███████▊  | 84/107 [01:42<00:28,  1.22s/it]Validating lr=5e-05, train epoch 0.:  79%|███████▉  | 85/107 [01:44<00:27,  1.23s/it]Validating lr=5e-05, train epoch 0.:  80%|████████  | 86/107 [01:45<00:25,  1.24s/it]Validating lr=5e-05, train epoch 0.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Validating lr=5e-05, train epoch 0.:  82%|████████▏ | 88/107 [01:47<00:23,  1.22s/it]Validating lr=5e-05, train epoch 0.:  83%|████████▎ | 89/107 [01:48<00:22,  1.23s/it]Validating lr=5e-05, train epoch 0.:  84%|████████▍ | 90/107 [01:50<00:20,  1.22s/it]Validating lr=5e-05, train epoch 0.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=5e-05, train epoch 0.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Validating lr=5e-05, train epoch 0.:  87%|████████▋ | 93/107 [01:53<00:17,  1.23s/it]Validating lr=5e-05, train epoch 0.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Validating lr=5e-05, train epoch 0.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Validating lr=5e-05, train epoch 0.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Validating lr=5e-05, train epoch 0.:  91%|█████████ | 97/107 [01:58<00:12,  1.23s/it]Validating lr=5e-05, train epoch 0.:  92%|█████████▏| 98/107 [01:59<00:11,  1.22s/it]Validating lr=5e-05, train epoch 0.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=5e-05, train epoch 0.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Validating lr=5e-05, train epoch 0.:  94%|█████████▍| 101/107 [02:03<00:07,  1.23s/it]Validating lr=5e-05, train epoch 0.:  95%|█████████▌| 102/107 [02:04<00:06,  1.23s/it]Validating lr=5e-05, train epoch 0.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=5e-05, train epoch 0.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Validating lr=5e-05, train epoch 0.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Validating lr=5e-05, train epoch 0.:  99%|█████████▉| 106/107 [02:09<00:01,  1.22s/it]Validating lr=5e-05, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Validating lr=5e-05, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]
Validating lr=5e-05, train epoch 1.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=5e-05, train epoch 1.:   1%|          | 1/107 [00:01<02:11,  1.24s/it]Validating lr=5e-05, train epoch 1.:   2%|▏         | 2/107 [00:02<02:08,  1.22s/it]Validating lr=5e-05, train epoch 1.:   3%|▎         | 3/107 [00:03<02:06,  1.22s/it]Validating lr=5e-05, train epoch 1.:   4%|▎         | 4/107 [00:04<02:05,  1.22s/it]Validating lr=5e-05, train epoch 1.:   5%|▍         | 5/107 [00:06<02:04,  1.22s/it]Validating lr=5e-05, train epoch 1.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Validating lr=5e-05, train epoch 1.:   7%|▋         | 7/107 [00:08<02:01,  1.21s/it]Validating lr=5e-05, train epoch 1.:   7%|▋         | 8/107 [00:09<02:00,  1.21s/it]Validating lr=5e-05, train epoch 1.:   8%|▊         | 9/107 [00:10<01:59,  1.22s/it]Validating lr=5e-05, train epoch 1.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Validating lr=5e-05, train epoch 1.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Validating lr=5e-05, train epoch 1.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Validating lr=5e-05, train epoch 1.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Validating lr=5e-05, train epoch 1.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Validating lr=5e-05, train epoch 1.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Validating lr=5e-05, train epoch 1.:  15%|█▍        | 16/107 [00:19<01:50,  1.22s/it]Validating lr=5e-05, train epoch 1.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Validating lr=5e-05, train epoch 1.:  17%|█▋        | 18/107 [00:21<01:48,  1.22s/it]Validating lr=5e-05, train epoch 1.:  18%|█▊        | 19/107 [00:23<01:46,  1.22s/it]Validating lr=5e-05, train epoch 1.:  19%|█▊        | 20/107 [00:24<01:45,  1.22s/it]Validating lr=5e-05, train epoch 1.:  20%|█▉        | 21/107 [00:25<01:45,  1.22s/it]Validating lr=5e-05, train epoch 1.:  21%|██        | 22/107 [00:26<01:44,  1.23s/it]Validating lr=5e-05, train epoch 1.:  21%|██▏       | 23/107 [00:28<01:44,  1.24s/it]Validating lr=5e-05, train epoch 1.:  22%|██▏       | 24/107 [00:29<01:42,  1.24s/it]Validating lr=5e-05, train epoch 1.:  23%|██▎       | 25/107 [00:30<01:41,  1.24s/it]Validating lr=5e-05, train epoch 1.:  24%|██▍       | 26/107 [00:31<01:40,  1.25s/it]Validating lr=5e-05, train epoch 1.:  25%|██▌       | 27/107 [00:33<01:39,  1.25s/it]Validating lr=5e-05, train epoch 1.:  26%|██▌       | 28/107 [00:34<01:38,  1.25s/it]Validating lr=5e-05, train epoch 1.:  27%|██▋       | 29/107 [00:35<01:36,  1.24s/it]Validating lr=5e-05, train epoch 1.:  28%|██▊       | 30/107 [00:36<01:35,  1.24s/it]Validating lr=5e-05, train epoch 1.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Validating lr=5e-05, train epoch 1.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Validating lr=5e-05, train epoch 1.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Validating lr=5e-05, train epoch 1.:  32%|███▏      | 34/107 [00:41<01:30,  1.23s/it]Validating lr=5e-05, train epoch 1.:  33%|███▎      | 35/107 [00:42<01:28,  1.23s/it]Validating lr=5e-05, train epoch 1.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=5e-05, train epoch 1.:  35%|███▍      | 37/107 [00:45<01:26,  1.23s/it]Validating lr=5e-05, train epoch 1.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Validating lr=5e-05, train epoch 1.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Validating lr=5e-05, train epoch 1.:  37%|███▋      | 40/107 [00:49<01:22,  1.24s/it]Validating lr=5e-05, train epoch 1.:  38%|███▊      | 41/107 [00:50<01:21,  1.24s/it]Validating lr=5e-05, train epoch 1.:  39%|███▉      | 42/107 [00:51<01:20,  1.24s/it]Validating lr=5e-05, train epoch 1.:  40%|████      | 43/107 [00:52<01:19,  1.24s/it]Validating lr=5e-05, train epoch 1.:  41%|████      | 44/107 [00:54<01:17,  1.23s/it]Validating lr=5e-05, train epoch 1.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Validating lr=5e-05, train epoch 1.:  43%|████▎     | 46/107 [00:56<01:15,  1.24s/it]Validating lr=5e-05, train epoch 1.:  44%|████▍     | 47/107 [00:57<01:15,  1.25s/it]Validating lr=5e-05, train epoch 1.:  45%|████▍     | 48/107 [00:59<01:13,  1.25s/it]Validating lr=5e-05, train epoch 1.:  46%|████▌     | 49/107 [01:00<01:12,  1.26s/it]Validating lr=5e-05, train epoch 1.:  47%|████▋     | 50/107 [01:01<01:11,  1.25s/it]Validating lr=5e-05, train epoch 1.:  48%|████▊     | 51/107 [01:02<01:09,  1.24s/it]Validating lr=5e-05, train epoch 1.:  49%|████▊     | 52/107 [01:04<01:08,  1.24s/it]Validating lr=5e-05, train epoch 1.:  50%|████▉     | 53/107 [01:05<01:06,  1.24s/it]Validating lr=5e-05, train epoch 1.:  50%|█████     | 54/107 [01:06<01:05,  1.24s/it]Validating lr=5e-05, train epoch 1.:  51%|█████▏    | 55/107 [01:07<01:04,  1.23s/it]Validating lr=5e-05, train epoch 1.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Validating lr=5e-05, train epoch 1.:  53%|█████▎    | 57/107 [01:10<01:01,  1.23s/it]Validating lr=5e-05, train epoch 1.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Validating lr=5e-05, train epoch 1.:  55%|█████▌    | 59/107 [01:12<00:59,  1.24s/it]Validating lr=5e-05, train epoch 1.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Validating lr=5e-05, train epoch 1.:  57%|█████▋    | 61/107 [01:15<00:56,  1.23s/it]Validating lr=5e-05, train epoch 1.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Validating lr=5e-05, train epoch 1.:  59%|█████▉    | 63/107 [01:17<00:53,  1.23s/it]Validating lr=5e-05, train epoch 1.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Validating lr=5e-05, train epoch 1.:  61%|██████    | 65/107 [01:20<00:51,  1.23s/it]Validating lr=5e-05, train epoch 1.:  62%|██████▏   | 66/107 [01:21<00:50,  1.22s/it]Validating lr=5e-05, train epoch 1.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Validating lr=5e-05, train epoch 1.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Validating lr=5e-05, train epoch 1.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Validating lr=5e-05, train epoch 1.:  65%|██████▌   | 70/107 [01:26<00:45,  1.24s/it]Validating lr=5e-05, train epoch 1.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Validating lr=5e-05, train epoch 1.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Validating lr=5e-05, train epoch 1.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Validating lr=5e-05, train epoch 1.:  69%|██████▉   | 74/107 [01:31<00:40,  1.23s/it]Validating lr=5e-05, train epoch 1.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Validating lr=5e-05, train epoch 1.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Validating lr=5e-05, train epoch 1.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Validating lr=5e-05, train epoch 1.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Validating lr=5e-05, train epoch 1.:  74%|███████▍  | 79/107 [01:37<00:34,  1.22s/it]Validating lr=5e-05, train epoch 1.:  75%|███████▍  | 80/107 [01:38<00:33,  1.22s/it]Validating lr=5e-05, train epoch 1.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Validating lr=5e-05, train epoch 1.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=5e-05, train epoch 1.:  78%|███████▊  | 83/107 [01:42<00:29,  1.23s/it]Validating lr=5e-05, train epoch 1.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Validating lr=5e-05, train epoch 1.:  79%|███████▉  | 85/107 [01:44<00:26,  1.23s/it]Validating lr=5e-05, train epoch 1.:  80%|████████  | 86/107 [01:45<00:26,  1.24s/it]Validating lr=5e-05, train epoch 1.:  81%|████████▏ | 87/107 [01:47<00:24,  1.24s/it]Validating lr=5e-05, train epoch 1.:  82%|████████▏ | 88/107 [01:48<00:23,  1.24s/it]Validating lr=5e-05, train epoch 1.:  83%|████████▎ | 89/107 [01:49<00:22,  1.24s/it]Validating lr=5e-05, train epoch 1.:  84%|████████▍ | 90/107 [01:50<00:21,  1.24s/it]Validating lr=5e-05, train epoch 1.:  85%|████████▌ | 91/107 [01:52<00:19,  1.24s/it]Validating lr=5e-05, train epoch 1.:  86%|████████▌ | 92/107 [01:53<00:18,  1.23s/it]Validating lr=5e-05, train epoch 1.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Validating lr=5e-05, train epoch 1.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Validating lr=5e-05, train epoch 1.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Validating lr=5e-05, train epoch 1.:  90%|████████▉ | 96/107 [01:58<00:13,  1.22s/it]Validating lr=5e-05, train epoch 1.:  91%|█████████ | 97/107 [01:59<00:12,  1.21s/it]Validating lr=5e-05, train epoch 1.:  92%|█████████▏| 98/107 [02:00<00:11,  1.22s/it]Validating lr=5e-05, train epoch 1.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Validating lr=5e-05, train epoch 1.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Validating lr=5e-05, train epoch 1.:  94%|█████████▍| 101/107 [02:04<00:07,  1.22s/it]Validating lr=5e-05, train epoch 1.:  95%|█████████▌| 102/107 [02:05<00:06,  1.21s/it]Validating lr=5e-05, train epoch 1.:  96%|█████████▋| 103/107 [02:06<00:04,  1.21s/it]Validating lr=5e-05, train epoch 1.:  97%|█████████▋| 104/107 [02:07<00:03,  1.21s/it]Validating lr=5e-05, train epoch 1.:  98%|█████████▊| 105/107 [02:09<00:02,  1.22s/it]Validating lr=5e-05, train epoch 1.:  99%|█████████▉| 106/107 [02:10<00:01,  1.21s/it]Validating lr=5e-05, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.21s/it]Validating lr=5e-05, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Evaluating for lr=5e-05:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating for lr=5e-05:   9%|▉         | 1/11 [00:00<00:04,  2.08it/s]Evaluating for lr=5e-05:  18%|█▊        | 2/11 [00:00<00:04,  2.01it/s]Evaluating for lr=5e-05:  27%|██▋       | 3/11 [00:01<00:03,  2.02it/s]Evaluating for lr=5e-05:  36%|███▋      | 4/11 [00:01<00:03,  2.03it/s]Evaluating for lr=5e-05:  45%|████▌     | 5/11 [00:02<00:02,  2.03it/s]Evaluating for lr=5e-05:  55%|█████▍    | 6/11 [00:02<00:02,  2.03it/s]Evaluating for lr=5e-05:  64%|██████▎   | 7/11 [00:03<00:01,  2.05it/s]Evaluating for lr=5e-05:  73%|███████▎  | 8/11 [00:03<00:01,  2.06it/s]Evaluating for lr=5e-05:  82%|████████▏ | 9/11 [00:04<00:00,  2.08it/s]Evaluating for lr=5e-05:  91%|█████████ | 10/11 [00:04<00:00,  2.07it/s]Evaluating for lr=5e-05: 100%|██████████| 11/11 [00:05<00:00,  2.08it/s]Evaluating for lr=5e-05: 100%|██████████| 11/11 [00:05<00:00,  2.05it/s]
[2025-06-25 07:25:42,530] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:26:05,363] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:26:05,365] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:26:05,365] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:26:05,427] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:26:05,427] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:26:05,427] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:26:05,427] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:26:05,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]
[2025-06-25 07:26:05,428] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x152484a8db90>
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:26:05,428] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 1e-05, 'weight_decay': 0.01}
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:26:05,429] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:26:05,429] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 1e-05, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Validating lr=1e-05, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=1e-05, train epoch 0.:   1%|          | 1/107 [00:01<02:19,  1.31s/it]Validating lr=1e-05, train epoch 0.:   2%|▏         | 2/107 [00:02<02:13,  1.27s/it]Validating lr=1e-05, train epoch 0.:   3%|▎         | 3/107 [00:03<02:10,  1.25s/it]Validating lr=1e-05, train epoch 0.:   4%|▎         | 4/107 [00:04<02:07,  1.23s/it]Validating lr=1e-05, train epoch 0.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Validating lr=1e-05, train epoch 0.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Validating lr=1e-05, train epoch 0.:   7%|▋         | 7/107 [00:08<02:01,  1.22s/it]Validating lr=1e-05, train epoch 0.:   7%|▋         | 8/107 [00:09<02:00,  1.22s/it]Validating lr=1e-05, train epoch 0.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Validating lr=1e-05, train epoch 0.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Validating lr=1e-05, train epoch 0.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Validating lr=1e-05, train epoch 0.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Validating lr=1e-05, train epoch 0.:  12%|█▏        | 13/107 [00:15<01:55,  1.22s/it]Validating lr=1e-05, train epoch 0.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Validating lr=1e-05, train epoch 0.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Validating lr=1e-05, train epoch 0.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Validating lr=1e-05, train epoch 0.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Validating lr=1e-05, train epoch 0.:  17%|█▋        | 18/107 [00:22<01:50,  1.24s/it]Validating lr=1e-05, train epoch 0.:  18%|█▊        | 19/107 [00:23<01:48,  1.24s/it]Validating lr=1e-05, train epoch 0.:  19%|█▊        | 20/107 [00:24<01:47,  1.24s/it]Validating lr=1e-05, train epoch 0.:  20%|█▉        | 21/107 [00:25<01:46,  1.24s/it]Validating lr=1e-05, train epoch 0.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Validating lr=1e-05, train epoch 0.:  21%|██▏       | 23/107 [00:28<01:43,  1.24s/it]Validating lr=1e-05, train epoch 0.:  22%|██▏       | 24/107 [00:29<01:42,  1.23s/it]Validating lr=1e-05, train epoch 0.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Validating lr=1e-05, train epoch 0.:  24%|██▍       | 26/107 [00:32<01:39,  1.23s/it]Validating lr=1e-05, train epoch 0.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Validating lr=1e-05, train epoch 0.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Validating lr=1e-05, train epoch 0.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Validating lr=1e-05, train epoch 0.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Validating lr=1e-05, train epoch 0.:  29%|██▉       | 31/107 [00:38<01:32,  1.22s/it]Validating lr=1e-05, train epoch 0.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Validating lr=1e-05, train epoch 0.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Validating lr=1e-05, train epoch 0.:  32%|███▏      | 34/107 [00:41<01:30,  1.24s/it]Validating lr=1e-05, train epoch 0.:  33%|███▎      | 35/107 [00:43<01:28,  1.24s/it]Validating lr=1e-05, train epoch 0.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=1e-05, train epoch 0.:  35%|███▍      | 37/107 [00:45<01:26,  1.23s/it]Validating lr=1e-05, train epoch 0.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Validating lr=1e-05, train epoch 0.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Validating lr=1e-05, train epoch 0.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Validating lr=1e-05, train epoch 0.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Validating lr=1e-05, train epoch 0.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Validating lr=1e-05, train epoch 0.:  40%|████      | 43/107 [00:52<01:18,  1.22s/it]Validating lr=1e-05, train epoch 0.:  41%|████      | 44/107 [00:54<01:16,  1.22s/it]Validating lr=1e-05, train epoch 0.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Validating lr=1e-05, train epoch 0.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Validating lr=1e-05, train epoch 0.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Validating lr=1e-05, train epoch 0.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Validating lr=1e-05, train epoch 0.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Validating lr=1e-05, train epoch 0.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Validating lr=1e-05, train epoch 0.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Validating lr=1e-05, train epoch 0.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Validating lr=1e-05, train epoch 0.:  50%|████▉     | 53/107 [01:05<01:06,  1.22s/it]Validating lr=1e-05, train epoch 0.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Validating lr=1e-05, train epoch 0.:  51%|█████▏    | 55/107 [01:07<01:03,  1.21s/it]Validating lr=1e-05, train epoch 0.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Validating lr=1e-05, train epoch 0.:  53%|█████▎    | 57/107 [01:09<01:01,  1.22s/it]Validating lr=1e-05, train epoch 0.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Validating lr=1e-05, train epoch 0.:  55%|█████▌    | 59/107 [01:12<00:58,  1.23s/it]Validating lr=1e-05, train epoch 0.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Validating lr=1e-05, train epoch 0.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Validating lr=1e-05, train epoch 0.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Validating lr=1e-05, train epoch 0.:  59%|█████▉    | 63/107 [01:17<00:54,  1.23s/it]Validating lr=1e-05, train epoch 0.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Validating lr=1e-05, train epoch 0.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Validating lr=1e-05, train epoch 0.:  62%|██████▏   | 66/107 [01:20<00:50,  1.22s/it]Validating lr=1e-05, train epoch 0.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Validating lr=1e-05, train epoch 0.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Validating lr=1e-05, train epoch 0.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Validating lr=1e-05, train epoch 0.:  65%|██████▌   | 70/107 [01:25<00:45,  1.22s/it]Validating lr=1e-05, train epoch 0.:  66%|██████▋   | 71/107 [01:27<00:44,  1.22s/it]Validating lr=1e-05, train epoch 0.:  67%|██████▋   | 72/107 [01:28<00:42,  1.23s/it]Validating lr=1e-05, train epoch 0.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Validating lr=1e-05, train epoch 0.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Validating lr=1e-05, train epoch 0.:  70%|███████   | 75/107 [01:31<00:39,  1.22s/it]Validating lr=1e-05, train epoch 0.:  71%|███████   | 76/107 [01:33<00:37,  1.23s/it]Validating lr=1e-05, train epoch 0.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Validating lr=1e-05, train epoch 0.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Validating lr=1e-05, train epoch 0.:  74%|███████▍  | 79/107 [01:36<00:34,  1.23s/it]Validating lr=1e-05, train epoch 0.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Validating lr=1e-05, train epoch 0.:  76%|███████▌  | 81/107 [01:39<00:32,  1.23s/it]Validating lr=1e-05, train epoch 0.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=1e-05, train epoch 0.:  78%|███████▊  | 83/107 [01:41<00:29,  1.22s/it]Validating lr=1e-05, train epoch 0.:  79%|███████▊  | 84/107 [01:43<00:28,  1.22s/it]Validating lr=1e-05, train epoch 0.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Validating lr=1e-05, train epoch 0.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Validating lr=1e-05, train epoch 0.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Validating lr=1e-05, train epoch 0.:  82%|████████▏ | 88/107 [01:47<00:23,  1.22s/it]Validating lr=1e-05, train epoch 0.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Validating lr=1e-05, train epoch 0.:  84%|████████▍ | 90/107 [01:50<00:21,  1.24s/it]Validating lr=1e-05, train epoch 0.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=1e-05, train epoch 0.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Validating lr=1e-05, train epoch 0.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Validating lr=1e-05, train epoch 0.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Validating lr=1e-05, train epoch 0.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Validating lr=1e-05, train epoch 0.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Validating lr=1e-05, train epoch 0.:  91%|█████████ | 97/107 [01:59<00:12,  1.23s/it]Validating lr=1e-05, train epoch 0.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Validating lr=1e-05, train epoch 0.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=1e-05, train epoch 0.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Validating lr=1e-05, train epoch 0.:  94%|█████████▍| 101/107 [02:03<00:07,  1.23s/it]Validating lr=1e-05, train epoch 0.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Validating lr=1e-05, train epoch 0.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=1e-05, train epoch 0.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Validating lr=1e-05, train epoch 0.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Validating lr=1e-05, train epoch 0.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Validating lr=1e-05, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Validating lr=1e-05, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Validating lr=1e-05, train epoch 1.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=1e-05, train epoch 1.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Validating lr=1e-05, train epoch 1.:   2%|▏         | 2/107 [00:02<02:11,  1.25s/it]Validating lr=1e-05, train epoch 1.:   3%|▎         | 3/107 [00:03<02:09,  1.24s/it]Validating lr=1e-05, train epoch 1.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Validating lr=1e-05, train epoch 1.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Validating lr=1e-05, train epoch 1.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Validating lr=1e-05, train epoch 1.:   7%|▋         | 7/107 [00:08<02:03,  1.24s/it]Validating lr=1e-05, train epoch 1.:   7%|▋         | 8/107 [00:09<02:02,  1.24s/it]Validating lr=1e-05, train epoch 1.:   8%|▊         | 9/107 [00:11<02:01,  1.24s/it]Validating lr=1e-05, train epoch 1.:   9%|▉         | 10/107 [00:12<01:59,  1.24s/it]Validating lr=1e-05, train epoch 1.:  10%|█         | 11/107 [00:13<01:58,  1.23s/it]Validating lr=1e-05, train epoch 1.:  11%|█         | 12/107 [00:14<01:57,  1.24s/it]Validating lr=1e-05, train epoch 1.:  12%|█▏        | 13/107 [00:16<01:56,  1.24s/it]Validating lr=1e-05, train epoch 1.:  13%|█▎        | 14/107 [00:17<01:55,  1.24s/it]Validating lr=1e-05, train epoch 1.:  14%|█▍        | 15/107 [00:18<01:53,  1.24s/it]Validating lr=1e-05, train epoch 1.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Validating lr=1e-05, train epoch 1.:  16%|█▌        | 17/107 [00:21<01:50,  1.23s/it]Validating lr=1e-05, train epoch 1.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Validating lr=1e-05, train epoch 1.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Validating lr=1e-05, train epoch 1.:  19%|█▊        | 20/107 [00:24<01:48,  1.24s/it]Validating lr=1e-05, train epoch 1.:  20%|█▉        | 21/107 [00:26<01:46,  1.24s/it]Validating lr=1e-05, train epoch 1.:  21%|██        | 22/107 [00:27<01:45,  1.24s/it]Validating lr=1e-05, train epoch 1.:  21%|██▏       | 23/107 [00:28<01:43,  1.23s/it]Validating lr=1e-05, train epoch 1.:  22%|██▏       | 24/107 [00:29<01:42,  1.23s/it]Validating lr=1e-05, train epoch 1.:  23%|██▎       | 25/107 [00:30<01:41,  1.23s/it]Validating lr=1e-05, train epoch 1.:  24%|██▍       | 26/107 [00:32<01:40,  1.24s/it]Validating lr=1e-05, train epoch 1.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Validating lr=1e-05, train epoch 1.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Validating lr=1e-05, train epoch 1.:  27%|██▋       | 29/107 [00:35<01:36,  1.24s/it]Validating lr=1e-05, train epoch 1.:  28%|██▊       | 30/107 [00:37<01:35,  1.23s/it]Validating lr=1e-05, train epoch 1.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Validating lr=1e-05, train epoch 1.:  30%|██▉       | 32/107 [00:39<01:31,  1.23s/it]Validating lr=1e-05, train epoch 1.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Validating lr=1e-05, train epoch 1.:  32%|███▏      | 34/107 [00:41<01:29,  1.22s/it]Validating lr=1e-05, train epoch 1.:  33%|███▎      | 35/107 [00:43<01:28,  1.23s/it]Validating lr=1e-05, train epoch 1.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=1e-05, train epoch 1.:  35%|███▍      | 37/107 [00:45<01:26,  1.23s/it]Validating lr=1e-05, train epoch 1.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Validating lr=1e-05, train epoch 1.:  36%|███▋      | 39/107 [00:48<01:23,  1.22s/it]Validating lr=1e-05, train epoch 1.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Validating lr=1e-05, train epoch 1.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Validating lr=1e-05, train epoch 1.:  39%|███▉      | 42/107 [00:51<01:20,  1.23s/it]Validating lr=1e-05, train epoch 1.:  40%|████      | 43/107 [00:53<01:18,  1.23s/it]Validating lr=1e-05, train epoch 1.:  41%|████      | 44/107 [00:54<01:17,  1.24s/it]Validating lr=1e-05, train epoch 1.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Validating lr=1e-05, train epoch 1.:  43%|████▎     | 46/107 [00:56<01:15,  1.24s/it]Validating lr=1e-05, train epoch 1.:  44%|████▍     | 47/107 [00:58<01:14,  1.24s/it]Validating lr=1e-05, train epoch 1.:  45%|████▍     | 48/107 [00:59<01:12,  1.24s/it]Validating lr=1e-05, train epoch 1.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Validating lr=1e-05, train epoch 1.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Validating lr=1e-05, train epoch 1.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Validating lr=1e-05, train epoch 1.:  49%|████▊     | 52/107 [01:04<01:07,  1.22s/it]Validating lr=1e-05, train epoch 1.:  50%|████▉     | 53/107 [01:05<01:05,  1.22s/it]Validating lr=1e-05, train epoch 1.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Validating lr=1e-05, train epoch 1.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Validating lr=1e-05, train epoch 1.:  52%|█████▏    | 56/107 [01:09<01:02,  1.22s/it]Validating lr=1e-05, train epoch 1.:  53%|█████▎    | 57/107 [01:10<01:00,  1.21s/it]Validating lr=1e-05, train epoch 1.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Validating lr=1e-05, train epoch 1.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Validating lr=1e-05, train epoch 1.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Validating lr=1e-05, train epoch 1.:  57%|█████▋    | 61/107 [01:15<00:55,  1.21s/it]Validating lr=1e-05, train epoch 1.:  58%|█████▊    | 62/107 [01:16<00:54,  1.21s/it]Validating lr=1e-05, train epoch 1.:  59%|█████▉    | 63/107 [01:17<00:53,  1.21s/it]Validating lr=1e-05, train epoch 1.:  60%|█████▉    | 64/107 [01:18<00:52,  1.21s/it]Validating lr=1e-05, train epoch 1.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Validating lr=1e-05, train epoch 1.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Validating lr=1e-05, train epoch 1.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Validating lr=1e-05, train epoch 1.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Validating lr=1e-05, train epoch 1.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Validating lr=1e-05, train epoch 1.:  65%|██████▌   | 70/107 [01:26<00:45,  1.23s/it]Validating lr=1e-05, train epoch 1.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Validating lr=1e-05, train epoch 1.:  67%|██████▋   | 72/107 [01:28<00:42,  1.23s/it]Validating lr=1e-05, train epoch 1.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Validating lr=1e-05, train epoch 1.:  69%|██████▉   | 74/107 [01:31<00:40,  1.22s/it]Validating lr=1e-05, train epoch 1.:  70%|███████   | 75/107 [01:32<00:38,  1.21s/it]Validating lr=1e-05, train epoch 1.:  71%|███████   | 76/107 [01:33<00:37,  1.21s/it]Validating lr=1e-05, train epoch 1.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Validating lr=1e-05, train epoch 1.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Validating lr=1e-05, train epoch 1.:  74%|███████▍  | 79/107 [01:37<00:34,  1.22s/it]Validating lr=1e-05, train epoch 1.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Validating lr=1e-05, train epoch 1.:  76%|███████▌  | 81/107 [01:39<00:32,  1.23s/it]Validating lr=1e-05, train epoch 1.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=1e-05, train epoch 1.:  78%|███████▊  | 83/107 [01:42<00:29,  1.23s/it]Validating lr=1e-05, train epoch 1.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Validating lr=1e-05, train epoch 1.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Validating lr=1e-05, train epoch 1.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Validating lr=1e-05, train epoch 1.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Validating lr=1e-05, train epoch 1.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Validating lr=1e-05, train epoch 1.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Validating lr=1e-05, train epoch 1.:  84%|████████▍ | 90/107 [01:50<00:21,  1.24s/it]Validating lr=1e-05, train epoch 1.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=1e-05, train epoch 1.:  86%|████████▌ | 92/107 [01:53<00:18,  1.23s/it]Validating lr=1e-05, train epoch 1.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Validating lr=1e-05, train epoch 1.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Validating lr=1e-05, train epoch 1.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Validating lr=1e-05, train epoch 1.:  90%|████████▉ | 96/107 [01:58<00:13,  1.23s/it]Validating lr=1e-05, train epoch 1.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Validating lr=1e-05, train epoch 1.:  92%|█████████▏| 98/107 [02:00<00:11,  1.22s/it]Validating lr=1e-05, train epoch 1.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Validating lr=1e-05, train epoch 1.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Validating lr=1e-05, train epoch 1.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Validating lr=1e-05, train epoch 1.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Validating lr=1e-05, train epoch 1.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=1e-05, train epoch 1.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Validating lr=1e-05, train epoch 1.:  98%|█████████▊| 105/107 [02:09<00:02,  1.22s/it]Validating lr=1e-05, train epoch 1.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Validating lr=1e-05, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Validating lr=1e-05, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Evaluating for lr=1e-05:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating for lr=1e-05:   9%|▉         | 1/11 [00:00<00:04,  2.03it/s]Evaluating for lr=1e-05:  18%|█▊        | 2/11 [00:00<00:04,  2.04it/s]Evaluating for lr=1e-05:  27%|██▋       | 3/11 [00:01<00:03,  2.06it/s]Evaluating for lr=1e-05:  36%|███▋      | 4/11 [00:01<00:03,  2.04it/s]Evaluating for lr=1e-05:  45%|████▌     | 5/11 [00:02<00:02,  2.02it/s]Evaluating for lr=1e-05:  55%|█████▍    | 6/11 [00:02<00:02,  2.01it/s]Evaluating for lr=1e-05:  64%|██████▎   | 7/11 [00:03<00:01,  2.00it/s]Evaluating for lr=1e-05:  73%|███████▎  | 8/11 [00:03<00:01,  2.01it/s]Evaluating for lr=1e-05:  82%|████████▏ | 9/11 [00:04<00:00,  2.04it/s]Evaluating for lr=1e-05:  91%|█████████ | 10/11 [00:04<00:00,  2.04it/s]Evaluating for lr=1e-05: 100%|██████████| 11/11 [00:05<00:00,  2.08it/s]Evaluating for lr=1e-05: 100%|██████████| 11/11 [00:05<00:00,  2.04it/s]
[2025-06-25 07:30:34,201] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:30:56,386] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:30:56,388] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:30:56,388] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:30:56,453] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:30:56,453] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:30:56,453] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:30:56,453] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:30:56,453] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-06], mom=[(0.9, 0.999)]
[2025-06-25 07:30:56,454] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15248fc96190>
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:30:56,454] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 5e-06, 'weight_decay': 0.01}
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:30:56,455] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:30:56,456] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:30:56,456] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:30:56,456] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:30:56,456] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:30:56,456] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 5e-06, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Validating lr=5e-06, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=5e-06, train epoch 0.:   1%|          | 1/107 [00:01<02:22,  1.34s/it]Validating lr=5e-06, train epoch 0.:   2%|▏         | 2/107 [00:02<02:15,  1.29s/it]Validating lr=5e-06, train epoch 0.:   3%|▎         | 3/107 [00:03<02:10,  1.26s/it]Validating lr=5e-06, train epoch 0.:   4%|▎         | 4/107 [00:05<02:07,  1.24s/it]Validating lr=5e-06, train epoch 0.:   5%|▍         | 5/107 [00:06<02:07,  1.25s/it]Validating lr=5e-06, train epoch 0.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Validating lr=5e-06, train epoch 0.:   7%|▋         | 7/107 [00:08<02:03,  1.24s/it]Validating lr=5e-06, train epoch 0.:   7%|▋         | 8/107 [00:09<02:02,  1.23s/it]Validating lr=5e-06, train epoch 0.:   8%|▊         | 9/107 [00:11<02:01,  1.24s/it]Validating lr=5e-06, train epoch 0.:   9%|▉         | 10/107 [00:12<02:00,  1.24s/it]Validating lr=5e-06, train epoch 0.:  10%|█         | 11/107 [00:13<01:59,  1.24s/it]Validating lr=5e-06, train epoch 0.:  11%|█         | 12/107 [00:14<01:57,  1.23s/it]Validating lr=5e-06, train epoch 0.:  12%|█▏        | 13/107 [00:16<01:55,  1.23s/it]Validating lr=5e-06, train epoch 0.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Validating lr=5e-06, train epoch 0.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Validating lr=5e-06, train epoch 0.:  15%|█▍        | 16/107 [00:19<01:51,  1.22s/it]Validating lr=5e-06, train epoch 0.:  16%|█▌        | 17/107 [00:21<01:50,  1.23s/it]Validating lr=5e-06, train epoch 0.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Validating lr=5e-06, train epoch 0.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Validating lr=5e-06, train epoch 0.:  19%|█▊        | 20/107 [00:24<01:46,  1.22s/it]Validating lr=5e-06, train epoch 0.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Validating lr=5e-06, train epoch 0.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Validating lr=5e-06, train epoch 0.:  21%|██▏       | 23/107 [00:28<01:42,  1.23s/it]Validating lr=5e-06, train epoch 0.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Validating lr=5e-06, train epoch 0.:  23%|██▎       | 25/107 [00:30<01:40,  1.22s/it]Validating lr=5e-06, train epoch 0.:  24%|██▍       | 26/107 [00:32<01:39,  1.22s/it]Validating lr=5e-06, train epoch 0.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Validating lr=5e-06, train epoch 0.:  26%|██▌       | 28/107 [00:34<01:36,  1.23s/it]Validating lr=5e-06, train epoch 0.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Validating lr=5e-06, train epoch 0.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Validating lr=5e-06, train epoch 0.:  29%|██▉       | 31/107 [00:38<01:34,  1.24s/it]Validating lr=5e-06, train epoch 0.:  30%|██▉       | 32/107 [00:39<01:32,  1.24s/it]Validating lr=5e-06, train epoch 0.:  31%|███       | 33/107 [00:40<01:31,  1.24s/it]Validating lr=5e-06, train epoch 0.:  32%|███▏      | 34/107 [00:41<01:30,  1.23s/it]Validating lr=5e-06, train epoch 0.:  33%|███▎      | 35/107 [00:43<01:28,  1.23s/it]Validating lr=5e-06, train epoch 0.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=5e-06, train epoch 0.:  35%|███▍      | 37/107 [00:45<01:26,  1.23s/it]Validating lr=5e-06, train epoch 0.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Validating lr=5e-06, train epoch 0.:  36%|███▋      | 39/107 [00:48<01:23,  1.23s/it]Validating lr=5e-06, train epoch 0.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Validating lr=5e-06, train epoch 0.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Validating lr=5e-06, train epoch 0.:  39%|███▉      | 42/107 [00:51<01:18,  1.21s/it]Validating lr=5e-06, train epoch 0.:  40%|████      | 43/107 [00:52<01:18,  1.22s/it]Validating lr=5e-06, train epoch 0.:  41%|████      | 44/107 [00:54<01:16,  1.22s/it]Validating lr=5e-06, train epoch 0.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Validating lr=5e-06, train epoch 0.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Validating lr=5e-06, train epoch 0.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Validating lr=5e-06, train epoch 0.:  45%|████▍     | 48/107 [00:59<01:12,  1.23s/it]Validating lr=5e-06, train epoch 0.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Validating lr=5e-06, train epoch 0.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Validating lr=5e-06, train epoch 0.:  48%|████▊     | 51/107 [01:02<01:09,  1.23s/it]Validating lr=5e-06, train epoch 0.:  49%|████▊     | 52/107 [01:03<01:07,  1.23s/it]Validating lr=5e-06, train epoch 0.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Validating lr=5e-06, train epoch 0.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Validating lr=5e-06, train epoch 0.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Validating lr=5e-06, train epoch 0.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Validating lr=5e-06, train epoch 0.:  53%|█████▎    | 57/107 [01:10<01:01,  1.23s/it]Validating lr=5e-06, train epoch 0.:  54%|█████▍    | 58/107 [01:11<01:00,  1.24s/it]Validating lr=5e-06, train epoch 0.:  55%|█████▌    | 59/107 [01:12<00:59,  1.24s/it]Validating lr=5e-06, train epoch 0.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Validating lr=5e-06, train epoch 0.:  57%|█████▋    | 61/107 [01:15<00:56,  1.22s/it]Validating lr=5e-06, train epoch 0.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Validating lr=5e-06, train epoch 0.:  59%|█████▉    | 63/107 [01:17<00:54,  1.24s/it]Validating lr=5e-06, train epoch 0.:  60%|█████▉    | 64/107 [01:18<00:53,  1.23s/it]Validating lr=5e-06, train epoch 0.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Validating lr=5e-06, train epoch 0.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Validating lr=5e-06, train epoch 0.:  63%|██████▎   | 67/107 [01:22<00:49,  1.24s/it]Validating lr=5e-06, train epoch 0.:  64%|██████▎   | 68/107 [01:23<00:48,  1.23s/it]Validating lr=5e-06, train epoch 0.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Validating lr=5e-06, train epoch 0.:  65%|██████▌   | 70/107 [01:26<00:45,  1.23s/it]Validating lr=5e-06, train epoch 0.:  66%|██████▋   | 71/107 [01:27<00:44,  1.24s/it]Validating lr=5e-06, train epoch 0.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Validating lr=5e-06, train epoch 0.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Validating lr=5e-06, train epoch 0.:  69%|██████▉   | 74/107 [01:31<00:40,  1.23s/it]Validating lr=5e-06, train epoch 0.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Validating lr=5e-06, train epoch 0.:  71%|███████   | 76/107 [01:33<00:37,  1.23s/it]Validating lr=5e-06, train epoch 0.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Validating lr=5e-06, train epoch 0.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Validating lr=5e-06, train epoch 0.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Validating lr=5e-06, train epoch 0.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Validating lr=5e-06, train epoch 0.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Validating lr=5e-06, train epoch 0.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=5e-06, train epoch 0.:  78%|███████▊  | 83/107 [01:42<00:29,  1.22s/it]Validating lr=5e-06, train epoch 0.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Validating lr=5e-06, train epoch 0.:  79%|███████▉  | 85/107 [01:44<00:26,  1.23s/it]Validating lr=5e-06, train epoch 0.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Validating lr=5e-06, train epoch 0.:  81%|████████▏ | 87/107 [01:46<00:24,  1.22s/it]Validating lr=5e-06, train epoch 0.:  82%|████████▏ | 88/107 [01:48<00:23,  1.22s/it]Validating lr=5e-06, train epoch 0.:  83%|████████▎ | 89/107 [01:49<00:21,  1.22s/it]Validating lr=5e-06, train epoch 0.:  84%|████████▍ | 90/107 [01:50<00:20,  1.22s/it]Validating lr=5e-06, train epoch 0.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=5e-06, train epoch 0.:  86%|████████▌ | 92/107 [01:53<00:18,  1.24s/it]Validating lr=5e-06, train epoch 0.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Validating lr=5e-06, train epoch 0.:  88%|████████▊ | 94/107 [01:55<00:16,  1.23s/it]Validating lr=5e-06, train epoch 0.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Validating lr=5e-06, train epoch 0.:  90%|████████▉ | 96/107 [01:58<00:13,  1.23s/it]Validating lr=5e-06, train epoch 0.:  91%|█████████ | 97/107 [01:59<00:12,  1.23s/it]Validating lr=5e-06, train epoch 0.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Validating lr=5e-06, train epoch 0.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=5e-06, train epoch 0.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Validating lr=5e-06, train epoch 0.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Validating lr=5e-06, train epoch 0.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Validating lr=5e-06, train epoch 0.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=5e-06, train epoch 0.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Validating lr=5e-06, train epoch 0.:  98%|█████████▊| 105/107 [02:09<00:02,  1.24s/it]Validating lr=5e-06, train epoch 0.:  99%|█████████▉| 106/107 [02:10<00:01,  1.24s/it]Validating lr=5e-06, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.24s/it]Validating lr=5e-06, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Validating lr=5e-06, train epoch 1.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=5e-06, train epoch 1.:   1%|          | 1/107 [00:01<02:11,  1.24s/it]Validating lr=5e-06, train epoch 1.:   2%|▏         | 2/107 [00:02<02:08,  1.23s/it]Validating lr=5e-06, train epoch 1.:   3%|▎         | 3/107 [00:03<02:07,  1.23s/it]Validating lr=5e-06, train epoch 1.:   4%|▎         | 4/107 [00:04<02:06,  1.23s/it]Validating lr=5e-06, train epoch 1.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Validating lr=5e-06, train epoch 1.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Validating lr=5e-06, train epoch 1.:   7%|▋         | 7/107 [00:08<02:03,  1.23s/it]Validating lr=5e-06, train epoch 1.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Validating lr=5e-06, train epoch 1.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Validating lr=5e-06, train epoch 1.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Validating lr=5e-06, train epoch 1.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Validating lr=5e-06, train epoch 1.:  11%|█         | 12/107 [00:14<01:57,  1.23s/it]Validating lr=5e-06, train epoch 1.:  12%|█▏        | 13/107 [00:16<01:55,  1.23s/it]Validating lr=5e-06, train epoch 1.:  13%|█▎        | 14/107 [00:17<01:54,  1.24s/it]Validating lr=5e-06, train epoch 1.:  14%|█▍        | 15/107 [00:18<01:54,  1.24s/it]Validating lr=5e-06, train epoch 1.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Validating lr=5e-06, train epoch 1.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Validating lr=5e-06, train epoch 1.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Validating lr=5e-06, train epoch 1.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Validating lr=5e-06, train epoch 1.:  19%|█▊        | 20/107 [00:24<01:47,  1.23s/it]Validating lr=5e-06, train epoch 1.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Validating lr=5e-06, train epoch 1.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Validating lr=5e-06, train epoch 1.:  21%|██▏       | 23/107 [00:28<01:43,  1.23s/it]Validating lr=5e-06, train epoch 1.:  22%|██▏       | 24/107 [00:29<01:42,  1.23s/it]Validating lr=5e-06, train epoch 1.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Validating lr=5e-06, train epoch 1.:  24%|██▍       | 26/107 [00:32<01:40,  1.24s/it]Validating lr=5e-06, train epoch 1.:  25%|██▌       | 27/107 [00:33<01:39,  1.25s/it]Validating lr=5e-06, train epoch 1.:  26%|██▌       | 28/107 [00:34<01:38,  1.25s/it]Validating lr=5e-06, train epoch 1.:  27%|██▋       | 29/107 [00:35<01:36,  1.24s/it]Validating lr=5e-06, train epoch 1.:  28%|██▊       | 30/107 [00:37<01:35,  1.24s/it]Validating lr=5e-06, train epoch 1.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Validating lr=5e-06, train epoch 1.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Validating lr=5e-06, train epoch 1.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Validating lr=5e-06, train epoch 1.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Validating lr=5e-06, train epoch 1.:  33%|███▎      | 35/107 [00:43<01:28,  1.23s/it]Validating lr=5e-06, train epoch 1.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Validating lr=5e-06, train epoch 1.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Validating lr=5e-06, train epoch 1.:  36%|███▌      | 38/107 [00:46<01:25,  1.23s/it]Validating lr=5e-06, train epoch 1.:  36%|███▋      | 39/107 [00:48<01:23,  1.23s/it]Validating lr=5e-06, train epoch 1.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Validating lr=5e-06, train epoch 1.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Validating lr=5e-06, train epoch 1.:  39%|███▉      | 42/107 [00:51<01:20,  1.23s/it]Validating lr=5e-06, train epoch 1.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Validating lr=5e-06, train epoch 1.:  41%|████      | 44/107 [00:54<01:17,  1.22s/it]Validating lr=5e-06, train epoch 1.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Validating lr=5e-06, train epoch 1.:  43%|████▎     | 46/107 [00:56<01:14,  1.21s/it]Validating lr=5e-06, train epoch 1.:  44%|████▍     | 47/107 [00:57<01:12,  1.21s/it]Validating lr=5e-06, train epoch 1.:  45%|████▍     | 48/107 [00:59<01:11,  1.22s/it]Validating lr=5e-06, train epoch 1.:  46%|████▌     | 49/107 [01:00<01:10,  1.21s/it]Validating lr=5e-06, train epoch 1.:  47%|████▋     | 50/107 [01:01<01:09,  1.21s/it]Validating lr=5e-06, train epoch 1.:  48%|████▊     | 51/107 [01:02<01:07,  1.21s/it]Validating lr=5e-06, train epoch 1.:  49%|████▊     | 52/107 [01:03<01:06,  1.21s/it]Validating lr=5e-06, train epoch 1.:  50%|████▉     | 53/107 [01:05<01:05,  1.21s/it]Validating lr=5e-06, train epoch 1.:  50%|█████     | 54/107 [01:06<01:04,  1.21s/it]Validating lr=5e-06, train epoch 1.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Validating lr=5e-06, train epoch 1.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Validating lr=5e-06, train epoch 1.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Validating lr=5e-06, train epoch 1.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Validating lr=5e-06, train epoch 1.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Validating lr=5e-06, train epoch 1.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Validating lr=5e-06, train epoch 1.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Validating lr=5e-06, train epoch 1.:  58%|█████▊    | 62/107 [01:16<00:55,  1.22s/it]Validating lr=5e-06, train epoch 1.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Validating lr=5e-06, train epoch 1.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Validating lr=5e-06, train epoch 1.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Validating lr=5e-06, train epoch 1.:  62%|██████▏   | 66/107 [01:21<00:50,  1.22s/it]Validating lr=5e-06, train epoch 1.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Validating lr=5e-06, train epoch 1.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Validating lr=5e-06, train epoch 1.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Validating lr=5e-06, train epoch 1.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Validating lr=5e-06, train epoch 1.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Validating lr=5e-06, train epoch 1.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Validating lr=5e-06, train epoch 1.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Validating lr=5e-06, train epoch 1.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Validating lr=5e-06, train epoch 1.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Validating lr=5e-06, train epoch 1.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Validating lr=5e-06, train epoch 1.:  72%|███████▏  | 77/107 [01:34<00:37,  1.24s/it]Validating lr=5e-06, train epoch 1.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Validating lr=5e-06, train epoch 1.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Validating lr=5e-06, train epoch 1.:  75%|███████▍  | 80/107 [01:38<00:32,  1.22s/it]Validating lr=5e-06, train epoch 1.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Validating lr=5e-06, train epoch 1.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=5e-06, train epoch 1.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Validating lr=5e-06, train epoch 1.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Validating lr=5e-06, train epoch 1.:  79%|███████▉  | 85/107 [01:44<00:27,  1.23s/it]Validating lr=5e-06, train epoch 1.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Validating lr=5e-06, train epoch 1.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Validating lr=5e-06, train epoch 1.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Validating lr=5e-06, train epoch 1.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Validating lr=5e-06, train epoch 1.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Validating lr=5e-06, train epoch 1.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=5e-06, train epoch 1.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Validating lr=5e-06, train epoch 1.:  87%|████████▋ | 93/107 [01:54<00:17,  1.22s/it]Validating lr=5e-06, train epoch 1.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Validating lr=5e-06, train epoch 1.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Validating lr=5e-06, train epoch 1.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Validating lr=5e-06, train epoch 1.:  91%|█████████ | 97/107 [01:59<00:12,  1.24s/it]Validating lr=5e-06, train epoch 1.:  92%|█████████▏| 98/107 [02:00<00:11,  1.24s/it]Validating lr=5e-06, train epoch 1.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=5e-06, train epoch 1.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Validating lr=5e-06, train epoch 1.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Validating lr=5e-06, train epoch 1.:  95%|█████████▌| 102/107 [02:05<00:06,  1.24s/it]Validating lr=5e-06, train epoch 1.:  96%|█████████▋| 103/107 [02:06<00:05,  1.25s/it]Validating lr=5e-06, train epoch 1.:  97%|█████████▋| 104/107 [02:07<00:03,  1.25s/it]Validating lr=5e-06, train epoch 1.:  98%|█████████▊| 105/107 [02:09<00:02,  1.25s/it]Validating lr=5e-06, train epoch 1.:  99%|█████████▉| 106/107 [02:10<00:01,  1.25s/it]Validating lr=5e-06, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.24s/it]Validating lr=5e-06, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Evaluating for lr=5e-06:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating for lr=5e-06:   9%|▉         | 1/11 [00:00<00:05,  1.98it/s]Evaluating for lr=5e-06:  18%|█▊        | 2/11 [00:00<00:04,  2.04it/s]Evaluating for lr=5e-06:  27%|██▋       | 3/11 [00:01<00:03,  2.05it/s]Evaluating for lr=5e-06:  36%|███▋      | 4/11 [00:01<00:03,  2.05it/s]Evaluating for lr=5e-06:  45%|████▌     | 5/11 [00:02<00:02,  2.03it/s]Evaluating for lr=5e-06:  55%|█████▍    | 6/11 [00:02<00:02,  2.05it/s]Evaluating for lr=5e-06:  64%|██████▎   | 7/11 [00:03<00:01,  2.05it/s]Evaluating for lr=5e-06:  73%|███████▎  | 8/11 [00:03<00:01,  2.04it/s]Evaluating for lr=5e-06:  82%|████████▏ | 9/11 [00:04<00:00,  2.05it/s]Evaluating for lr=5e-06:  91%|█████████ | 10/11 [00:04<00:00,  2.03it/s]Evaluating for lr=5e-06: 100%|██████████| 11/11 [00:05<00:00,  2.02it/s]Evaluating for lr=5e-06: 100%|██████████| 11/11 [00:05<00:00,  2.03it/s]
[2025-06-25 07:35:25,625] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:35:47,613] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:35:47,615] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:35:47,615] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:35:47,678] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:35:47,678] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:35:47,678] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:35:47,678] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:35:47,678] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-06], mom=[(0.9, 0.999)]
[2025-06-25 07:35:47,679] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15248fb64110>
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:35:47,679] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 1e-06, 'weight_decay': 0.01}
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:35:47,680] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:35:47,681] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:35:47,681] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 1e-06, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Validating lr=1e-06, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=1e-06, train epoch 0.:   1%|          | 1/107 [00:01<02:22,  1.35s/it]Validating lr=1e-06, train epoch 0.:   2%|▏         | 2/107 [00:02<02:14,  1.28s/it]Validating lr=1e-06, train epoch 0.:   3%|▎         | 3/107 [00:03<02:11,  1.26s/it]Validating lr=1e-06, train epoch 0.:   4%|▎         | 4/107 [00:05<02:07,  1.24s/it]Validating lr=1e-06, train epoch 0.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Validating lr=1e-06, train epoch 0.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Validating lr=1e-06, train epoch 0.:   7%|▋         | 7/107 [00:08<02:02,  1.22s/it]Validating lr=1e-06, train epoch 0.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Validating lr=1e-06, train epoch 0.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Validating lr=1e-06, train epoch 0.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Validating lr=1e-06, train epoch 0.:  10%|█         | 11/107 [00:13<01:58,  1.23s/it]Validating lr=1e-06, train epoch 0.:  11%|█         | 12/107 [00:14<01:57,  1.24s/it]Validating lr=1e-06, train epoch 0.:  12%|█▏        | 13/107 [00:16<01:56,  1.24s/it]Validating lr=1e-06, train epoch 0.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Validating lr=1e-06, train epoch 0.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Validating lr=1e-06, train epoch 0.:  15%|█▍        | 16/107 [00:19<01:51,  1.23s/it]Validating lr=1e-06, train epoch 0.:  16%|█▌        | 17/107 [00:21<01:50,  1.23s/it]Validating lr=1e-06, train epoch 0.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Validating lr=1e-06, train epoch 0.:  18%|█▊        | 19/107 [00:23<01:47,  1.23s/it]Validating lr=1e-06, train epoch 0.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Validating lr=1e-06, train epoch 0.:  20%|█▉        | 21/107 [00:25<01:46,  1.24s/it]Validating lr=1e-06, train epoch 0.:  21%|██        | 22/107 [00:27<01:45,  1.24s/it]Validating lr=1e-06, train epoch 0.:  21%|██▏       | 23/107 [00:28<01:43,  1.23s/it]Validating lr=1e-06, train epoch 0.:  22%|██▏       | 24/107 [00:29<01:42,  1.23s/it]Validating lr=1e-06, train epoch 0.:  23%|██▎       | 25/107 [00:30<01:41,  1.24s/it]Validating lr=1e-06, train epoch 0.:  24%|██▍       | 26/107 [00:32<01:40,  1.24s/it]Validating lr=1e-06, train epoch 0.:  25%|██▌       | 27/107 [00:33<01:39,  1.25s/it]Validating lr=1e-06, train epoch 0.:  26%|██▌       | 28/107 [00:34<01:38,  1.24s/it]Validating lr=1e-06, train epoch 0.:  27%|██▋       | 29/107 [00:35<01:36,  1.24s/it]Validating lr=1e-06, train epoch 0.:  28%|██▊       | 30/107 [00:37<01:35,  1.24s/it]Validating lr=1e-06, train epoch 0.:  29%|██▉       | 31/107 [00:38<01:34,  1.25s/it]Validating lr=1e-06, train epoch 0.:  30%|██▉       | 32/107 [00:39<01:33,  1.24s/it]Validating lr=1e-06, train epoch 0.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Validating lr=1e-06, train epoch 0.:  32%|███▏      | 34/107 [00:42<01:30,  1.24s/it]Validating lr=1e-06, train epoch 0.:  33%|███▎      | 35/107 [00:43<01:28,  1.23s/it]Validating lr=1e-06, train epoch 0.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=1e-06, train epoch 0.:  35%|███▍      | 37/107 [00:45<01:26,  1.24s/it]Validating lr=1e-06, train epoch 0.:  36%|███▌      | 38/107 [00:46<01:25,  1.24s/it]Validating lr=1e-06, train epoch 0.:  36%|███▋      | 39/107 [00:48<01:23,  1.23s/it]Validating lr=1e-06, train epoch 0.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Validating lr=1e-06, train epoch 0.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Validating lr=1e-06, train epoch 0.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Validating lr=1e-06, train epoch 0.:  40%|████      | 43/107 [00:53<01:18,  1.22s/it]Validating lr=1e-06, train epoch 0.:  41%|████      | 44/107 [00:54<01:17,  1.23s/it]Validating lr=1e-06, train epoch 0.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Validating lr=1e-06, train epoch 0.:  43%|████▎     | 46/107 [00:56<01:15,  1.23s/it]Validating lr=1e-06, train epoch 0.:  44%|████▍     | 47/107 [00:58<01:14,  1.23s/it]Validating lr=1e-06, train epoch 0.:  45%|████▍     | 48/107 [00:59<01:12,  1.23s/it]Validating lr=1e-06, train epoch 0.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Validating lr=1e-06, train epoch 0.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Validating lr=1e-06, train epoch 0.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Validating lr=1e-06, train epoch 0.:  49%|████▊     | 52/107 [01:04<01:06,  1.22s/it]Validating lr=1e-06, train epoch 0.:  50%|████▉     | 53/107 [01:05<01:05,  1.22s/it]Validating lr=1e-06, train epoch 0.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Validating lr=1e-06, train epoch 0.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Validating lr=1e-06, train epoch 0.:  52%|█████▏    | 56/107 [01:09<01:02,  1.23s/it]Validating lr=1e-06, train epoch 0.:  53%|█████▎    | 57/107 [01:10<01:01,  1.22s/it]Validating lr=1e-06, train epoch 0.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Validating lr=1e-06, train epoch 0.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Validating lr=1e-06, train epoch 0.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Validating lr=1e-06, train epoch 0.:  57%|█████▋    | 61/107 [01:15<00:55,  1.21s/it]Validating lr=1e-06, train epoch 0.:  58%|█████▊    | 62/107 [01:16<00:54,  1.21s/it]Validating lr=1e-06, train epoch 0.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Validating lr=1e-06, train epoch 0.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Validating lr=1e-06, train epoch 0.:  61%|██████    | 65/107 [01:20<00:51,  1.23s/it]Validating lr=1e-06, train epoch 0.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Validating lr=1e-06, train epoch 0.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Validating lr=1e-06, train epoch 0.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Validating lr=1e-06, train epoch 0.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Validating lr=1e-06, train epoch 0.:  65%|██████▌   | 70/107 [01:26<00:45,  1.22s/it]Validating lr=1e-06, train epoch 0.:  66%|██████▋   | 71/107 [01:27<00:43,  1.21s/it]Validating lr=1e-06, train epoch 0.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Validating lr=1e-06, train epoch 0.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Validating lr=1e-06, train epoch 0.:  69%|██████▉   | 74/107 [01:31<00:40,  1.23s/it]Validating lr=1e-06, train epoch 0.:  70%|███████   | 75/107 [01:32<00:39,  1.22s/it]Validating lr=1e-06, train epoch 0.:  71%|███████   | 76/107 [01:33<00:37,  1.22s/it]Validating lr=1e-06, train epoch 0.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Validating lr=1e-06, train epoch 0.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Validating lr=1e-06, train epoch 0.:  74%|███████▍  | 79/107 [01:37<00:34,  1.22s/it]Validating lr=1e-06, train epoch 0.:  75%|███████▍  | 80/107 [01:38<00:33,  1.22s/it]Validating lr=1e-06, train epoch 0.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Validating lr=1e-06, train epoch 0.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=1e-06, train epoch 0.:  78%|███████▊  | 83/107 [01:42<00:29,  1.23s/it]Validating lr=1e-06, train epoch 0.:  79%|███████▊  | 84/107 [01:43<00:28,  1.24s/it]Validating lr=1e-06, train epoch 0.:  79%|███████▉  | 85/107 [01:44<00:27,  1.23s/it]Validating lr=1e-06, train epoch 0.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Validating lr=1e-06, train epoch 0.:  81%|████████▏ | 87/107 [01:46<00:24,  1.22s/it]Validating lr=1e-06, train epoch 0.:  82%|████████▏ | 88/107 [01:48<00:23,  1.22s/it]Validating lr=1e-06, train epoch 0.:  83%|████████▎ | 89/107 [01:49<00:21,  1.22s/it]Validating lr=1e-06, train epoch 0.:  84%|████████▍ | 90/107 [01:50<00:20,  1.22s/it]Validating lr=1e-06, train epoch 0.:  85%|████████▌ | 91/107 [01:51<00:19,  1.22s/it]Validating lr=1e-06, train epoch 0.:  86%|████████▌ | 92/107 [01:53<00:18,  1.22s/it]Validating lr=1e-06, train epoch 0.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Validating lr=1e-06, train epoch 0.:  88%|████████▊ | 94/107 [01:55<00:16,  1.23s/it]Validating lr=1e-06, train epoch 0.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Validating lr=1e-06, train epoch 0.:  90%|████████▉ | 96/107 [01:57<00:13,  1.22s/it]Validating lr=1e-06, train epoch 0.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Validating lr=1e-06, train epoch 0.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Validating lr=1e-06, train epoch 0.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=1e-06, train epoch 0.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Validating lr=1e-06, train epoch 0.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Validating lr=1e-06, train epoch 0.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Validating lr=1e-06, train epoch 0.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=1e-06, train epoch 0.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Validating lr=1e-06, train epoch 0.:  98%|█████████▊| 105/107 [02:08<00:02,  1.22s/it]Validating lr=1e-06, train epoch 0.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Validating lr=1e-06, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Validating lr=1e-06, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Validating lr=1e-06, train epoch 1.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=1e-06, train epoch 1.:   1%|          | 1/107 [00:01<02:11,  1.24s/it]Validating lr=1e-06, train epoch 1.:   2%|▏         | 2/107 [00:02<02:09,  1.24s/it]Validating lr=1e-06, train epoch 1.:   3%|▎         | 3/107 [00:03<02:08,  1.24s/it]Validating lr=1e-06, train epoch 1.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Validating lr=1e-06, train epoch 1.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Validating lr=1e-06, train epoch 1.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Validating lr=1e-06, train epoch 1.:   7%|▋         | 7/107 [00:08<02:02,  1.23s/it]Validating lr=1e-06, train epoch 1.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Validating lr=1e-06, train epoch 1.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Validating lr=1e-06, train epoch 1.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Validating lr=1e-06, train epoch 1.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Validating lr=1e-06, train epoch 1.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Validating lr=1e-06, train epoch 1.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Validating lr=1e-06, train epoch 1.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Validating lr=1e-06, train epoch 1.:  14%|█▍        | 15/107 [00:18<01:53,  1.24s/it]Validating lr=1e-06, train epoch 1.:  15%|█▍        | 16/107 [00:19<01:51,  1.23s/it]Validating lr=1e-06, train epoch 1.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Validating lr=1e-06, train epoch 1.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Validating lr=1e-06, train epoch 1.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Validating lr=1e-06, train epoch 1.:  19%|█▊        | 20/107 [00:24<01:46,  1.22s/it]Validating lr=1e-06, train epoch 1.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Validating lr=1e-06, train epoch 1.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Validating lr=1e-06, train epoch 1.:  21%|██▏       | 23/107 [00:28<01:43,  1.23s/it]Validating lr=1e-06, train epoch 1.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Validating lr=1e-06, train epoch 1.:  23%|██▎       | 25/107 [00:30<01:39,  1.22s/it]Validating lr=1e-06, train epoch 1.:  24%|██▍       | 26/107 [00:31<01:38,  1.22s/it]Validating lr=1e-06, train epoch 1.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Validating lr=1e-06, train epoch 1.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Validating lr=1e-06, train epoch 1.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Validating lr=1e-06, train epoch 1.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Validating lr=1e-06, train epoch 1.:  29%|██▉       | 31/107 [00:38<01:33,  1.22s/it]Validating lr=1e-06, train epoch 1.:  30%|██▉       | 32/107 [00:39<01:31,  1.23s/it]Validating lr=1e-06, train epoch 1.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Validating lr=1e-06, train epoch 1.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Validating lr=1e-06, train epoch 1.:  33%|███▎      | 35/107 [00:42<01:28,  1.22s/it]Validating lr=1e-06, train epoch 1.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Validating lr=1e-06, train epoch 1.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Validating lr=1e-06, train epoch 1.:  36%|███▌      | 38/107 [00:46<01:25,  1.23s/it]Validating lr=1e-06, train epoch 1.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Validating lr=1e-06, train epoch 1.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Validating lr=1e-06, train epoch 1.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Validating lr=1e-06, train epoch 1.:  39%|███▉      | 42/107 [00:51<01:19,  1.23s/it]Validating lr=1e-06, train epoch 1.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Validating lr=1e-06, train epoch 1.:  41%|████      | 44/107 [00:53<01:16,  1.22s/it]Validating lr=1e-06, train epoch 1.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Validating lr=1e-06, train epoch 1.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Validating lr=1e-06, train epoch 1.:  44%|████▍     | 47/107 [00:57<01:13,  1.22s/it]Validating lr=1e-06, train epoch 1.:  45%|████▍     | 48/107 [00:58<01:11,  1.22s/it]Validating lr=1e-06, train epoch 1.:  46%|████▌     | 49/107 [01:00<01:10,  1.22s/it]Validating lr=1e-06, train epoch 1.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Validating lr=1e-06, train epoch 1.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Validating lr=1e-06, train epoch 1.:  49%|████▊     | 52/107 [01:03<01:07,  1.23s/it]Validating lr=1e-06, train epoch 1.:  50%|████▉     | 53/107 [01:04<01:06,  1.23s/it]Validating lr=1e-06, train epoch 1.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Validating lr=1e-06, train epoch 1.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Validating lr=1e-06, train epoch 1.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Validating lr=1e-06, train epoch 1.:  53%|█████▎    | 57/107 [01:09<01:00,  1.22s/it]Validating lr=1e-06, train epoch 1.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Validating lr=1e-06, train epoch 1.:  55%|█████▌    | 59/107 [01:12<00:58,  1.23s/it]Validating lr=1e-06, train epoch 1.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Validating lr=1e-06, train epoch 1.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Validating lr=1e-06, train epoch 1.:  58%|█████▊    | 62/107 [01:16<00:55,  1.24s/it]Validating lr=1e-06, train epoch 1.:  59%|█████▉    | 63/107 [01:17<00:54,  1.24s/it]Validating lr=1e-06, train epoch 1.:  60%|█████▉    | 64/107 [01:18<00:53,  1.24s/it]Validating lr=1e-06, train epoch 1.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Validating lr=1e-06, train epoch 1.:  62%|██████▏   | 66/107 [01:20<00:50,  1.23s/it]Validating lr=1e-06, train epoch 1.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Validating lr=1e-06, train epoch 1.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Validating lr=1e-06, train epoch 1.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Validating lr=1e-06, train epoch 1.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Validating lr=1e-06, train epoch 1.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Validating lr=1e-06, train epoch 1.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Validating lr=1e-06, train epoch 1.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Validating lr=1e-06, train epoch 1.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Validating lr=1e-06, train epoch 1.:  70%|███████   | 75/107 [01:31<00:38,  1.22s/it]Validating lr=1e-06, train epoch 1.:  71%|███████   | 76/107 [01:33<00:37,  1.21s/it]Validating lr=1e-06, train epoch 1.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Validating lr=1e-06, train epoch 1.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Validating lr=1e-06, train epoch 1.:  74%|███████▍  | 79/107 [01:36<00:33,  1.21s/it]Validating lr=1e-06, train epoch 1.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Validating lr=1e-06, train epoch 1.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Validating lr=1e-06, train epoch 1.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Validating lr=1e-06, train epoch 1.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Validating lr=1e-06, train epoch 1.:  79%|███████▊  | 84/107 [01:42<00:28,  1.22s/it]Validating lr=1e-06, train epoch 1.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Validating lr=1e-06, train epoch 1.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Validating lr=1e-06, train epoch 1.:  81%|████████▏ | 87/107 [01:46<00:24,  1.22s/it]Validating lr=1e-06, train epoch 1.:  82%|████████▏ | 88/107 [01:47<00:23,  1.23s/it]Validating lr=1e-06, train epoch 1.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Validating lr=1e-06, train epoch 1.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Validating lr=1e-06, train epoch 1.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=1e-06, train epoch 1.:  86%|████████▌ | 92/107 [01:52<00:18,  1.24s/it]Validating lr=1e-06, train epoch 1.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Validating lr=1e-06, train epoch 1.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Validating lr=1e-06, train epoch 1.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Validating lr=1e-06, train epoch 1.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Validating lr=1e-06, train epoch 1.:  91%|█████████ | 97/107 [01:58<00:12,  1.23s/it]Validating lr=1e-06, train epoch 1.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Validating lr=1e-06, train epoch 1.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Validating lr=1e-06, train epoch 1.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Validating lr=1e-06, train epoch 1.:  94%|█████████▍| 101/107 [02:03<00:07,  1.22s/it]Validating lr=1e-06, train epoch 1.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Validating lr=1e-06, train epoch 1.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=1e-06, train epoch 1.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Validating lr=1e-06, train epoch 1.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Validating lr=1e-06, train epoch 1.:  99%|█████████▉| 106/107 [02:09<00:01,  1.23s/it]Validating lr=1e-06, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Validating lr=1e-06, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Evaluating for lr=1e-06:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating for lr=1e-06:   9%|▉         | 1/11 [00:00<00:04,  2.03it/s]Evaluating for lr=1e-06:  18%|█▊        | 2/11 [00:00<00:04,  2.01it/s]Evaluating for lr=1e-06:  27%|██▋       | 3/11 [00:01<00:04,  1.99it/s]Evaluating for lr=1e-06:  36%|███▋      | 4/11 [00:01<00:03,  2.03it/s]Evaluating for lr=1e-06:  45%|████▌     | 5/11 [00:02<00:02,  2.05it/s]Evaluating for lr=1e-06:  55%|█████▍    | 6/11 [00:02<00:02,  2.01it/s]Evaluating for lr=1e-06:  64%|██████▎   | 7/11 [00:03<00:01,  2.01it/s]Evaluating for lr=1e-06:  73%|███████▎  | 8/11 [00:03<00:01,  2.02it/s]Evaluating for lr=1e-06:  82%|████████▏ | 9/11 [00:04<00:01,  1.97it/s]Evaluating for lr=1e-06:  91%|█████████ | 10/11 [00:04<00:00,  1.98it/s]Evaluating for lr=1e-06: 100%|██████████| 11/11 [00:05<00:00,  1.98it/s]Evaluating for lr=1e-06: 100%|██████████| 11/11 [00:05<00:00,  2.00it/s]
[2025-06-25 07:40:16,424] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:40:38,437] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:40:38,439] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:40:38,439] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:40:38,503] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:40:38,503] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:40:38,503] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:40:38,503] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:40:38,503] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-07], mom=[(0.9, 0.999)]
[2025-06-25 07:40:38,504] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15248fc20210>
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:40:38,504] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 5e-07, 'weight_decay': 0.01}
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:40:38,505] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:40:38,505] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 5e-07, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Validating lr=5e-07, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=5e-07, train epoch 0.:   1%|          | 1/107 [00:01<02:22,  1.34s/it]Validating lr=5e-07, train epoch 0.:   2%|▏         | 2/107 [00:02<02:12,  1.26s/it]Validating lr=5e-07, train epoch 0.:   3%|▎         | 3/107 [00:03<02:09,  1.25s/it]Validating lr=5e-07, train epoch 0.:   4%|▎         | 4/107 [00:05<02:07,  1.24s/it]Validating lr=5e-07, train epoch 0.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Validating lr=5e-07, train epoch 0.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Validating lr=5e-07, train epoch 0.:   7%|▋         | 7/107 [00:08<02:02,  1.22s/it]Validating lr=5e-07, train epoch 0.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Validating lr=5e-07, train epoch 0.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Validating lr=5e-07, train epoch 0.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Validating lr=5e-07, train epoch 0.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Validating lr=5e-07, train epoch 0.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Validating lr=5e-07, train epoch 0.:  12%|█▏        | 13/107 [00:16<01:55,  1.23s/it]Validating lr=5e-07, train epoch 0.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Validating lr=5e-07, train epoch 0.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Validating lr=5e-07, train epoch 0.:  15%|█▍        | 16/107 [00:19<01:51,  1.22s/it]Validating lr=5e-07, train epoch 0.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Validating lr=5e-07, train epoch 0.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Validating lr=5e-07, train epoch 0.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Validating lr=5e-07, train epoch 0.:  19%|█▊        | 20/107 [00:24<01:46,  1.22s/it]Validating lr=5e-07, train epoch 0.:  20%|█▉        | 21/107 [00:25<01:44,  1.22s/it]Validating lr=5e-07, train epoch 0.:  21%|██        | 22/107 [00:27<01:43,  1.22s/it]Validating lr=5e-07, train epoch 0.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Validating lr=5e-07, train epoch 0.:  22%|██▏       | 24/107 [00:29<01:42,  1.24s/it]Validating lr=5e-07, train epoch 0.:  23%|██▎       | 25/107 [00:30<01:41,  1.23s/it]Validating lr=5e-07, train epoch 0.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Validating lr=5e-07, train epoch 0.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Validating lr=5e-07, train epoch 0.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Validating lr=5e-07, train epoch 0.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Validating lr=5e-07, train epoch 0.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Validating lr=5e-07, train epoch 0.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Validating lr=5e-07, train epoch 0.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Validating lr=5e-07, train epoch 0.:  31%|███       | 33/107 [00:40<01:31,  1.24s/it]Validating lr=5e-07, train epoch 0.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Validating lr=5e-07, train epoch 0.:  33%|███▎      | 35/107 [00:43<01:28,  1.23s/it]Validating lr=5e-07, train epoch 0.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=5e-07, train epoch 0.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Validating lr=5e-07, train epoch 0.:  36%|███▌      | 38/107 [00:46<01:23,  1.21s/it]Validating lr=5e-07, train epoch 0.:  36%|███▋      | 39/107 [00:47<01:22,  1.22s/it]Validating lr=5e-07, train epoch 0.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Validating lr=5e-07, train epoch 0.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Validating lr=5e-07, train epoch 0.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Validating lr=5e-07, train epoch 0.:  40%|████      | 43/107 [00:52<01:17,  1.21s/it]Validating lr=5e-07, train epoch 0.:  41%|████      | 44/107 [00:53<01:16,  1.21s/it]Validating lr=5e-07, train epoch 0.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Validating lr=5e-07, train epoch 0.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Validating lr=5e-07, train epoch 0.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Validating lr=5e-07, train epoch 0.:  45%|████▍     | 48/107 [00:58<01:12,  1.23s/it]Validating lr=5e-07, train epoch 0.:  46%|████▌     | 49/107 [01:00<01:11,  1.24s/it]Validating lr=5e-07, train epoch 0.:  47%|████▋     | 50/107 [01:01<01:10,  1.24s/it]Validating lr=5e-07, train epoch 0.:  48%|████▊     | 51/107 [01:02<01:09,  1.24s/it]Validating lr=5e-07, train epoch 0.:  49%|████▊     | 52/107 [01:03<01:07,  1.24s/it]Validating lr=5e-07, train epoch 0.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Validating lr=5e-07, train epoch 0.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Validating lr=5e-07, train epoch 0.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Validating lr=5e-07, train epoch 0.:  52%|█████▏    | 56/107 [01:08<01:01,  1.21s/it]Validating lr=5e-07, train epoch 0.:  53%|█████▎    | 57/107 [01:09<01:00,  1.22s/it]Validating lr=5e-07, train epoch 0.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Validating lr=5e-07, train epoch 0.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Validating lr=5e-07, train epoch 0.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Validating lr=5e-07, train epoch 0.:  57%|█████▋    | 61/107 [01:14<00:56,  1.22s/it]Validating lr=5e-07, train epoch 0.:  58%|█████▊    | 62/107 [01:16<00:54,  1.22s/it]Validating lr=5e-07, train epoch 0.:  59%|█████▉    | 63/107 [01:17<00:53,  1.23s/it]Validating lr=5e-07, train epoch 0.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Validating lr=5e-07, train epoch 0.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Validating lr=5e-07, train epoch 0.:  62%|██████▏   | 66/107 [01:20<00:50,  1.24s/it]Validating lr=5e-07, train epoch 0.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Validating lr=5e-07, train epoch 0.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Validating lr=5e-07, train epoch 0.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Validating lr=5e-07, train epoch 0.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Validating lr=5e-07, train epoch 0.:  66%|██████▋   | 71/107 [01:27<00:44,  1.22s/it]Validating lr=5e-07, train epoch 0.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Validating lr=5e-07, train epoch 0.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Validating lr=5e-07, train epoch 0.:  69%|██████▉   | 74/107 [01:30<00:40,  1.24s/it]Validating lr=5e-07, train epoch 0.:  70%|███████   | 75/107 [01:32<00:39,  1.24s/it]Validating lr=5e-07, train epoch 0.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Validating lr=5e-07, train epoch 0.:  72%|███████▏  | 77/107 [01:34<00:37,  1.24s/it]Validating lr=5e-07, train epoch 0.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Validating lr=5e-07, train epoch 0.:  74%|███████▍  | 79/107 [01:36<00:34,  1.23s/it]Validating lr=5e-07, train epoch 0.:  75%|███████▍  | 80/107 [01:38<00:33,  1.22s/it]Validating lr=5e-07, train epoch 0.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Validating lr=5e-07, train epoch 0.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Validating lr=5e-07, train epoch 0.:  78%|███████▊  | 83/107 [01:41<00:29,  1.22s/it]Validating lr=5e-07, train epoch 0.:  79%|███████▊  | 84/107 [01:43<00:28,  1.22s/it]Validating lr=5e-07, train epoch 0.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Validating lr=5e-07, train epoch 0.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Validating lr=5e-07, train epoch 0.:  81%|████████▏ | 87/107 [01:46<00:24,  1.22s/it]Validating lr=5e-07, train epoch 0.:  82%|████████▏ | 88/107 [01:47<00:23,  1.23s/it]Validating lr=5e-07, train epoch 0.:  83%|████████▎ | 89/107 [01:49<00:22,  1.22s/it]Validating lr=5e-07, train epoch 0.:  84%|████████▍ | 90/107 [01:50<00:20,  1.22s/it]Validating lr=5e-07, train epoch 0.:  85%|████████▌ | 91/107 [01:51<00:19,  1.22s/it]Validating lr=5e-07, train epoch 0.:  86%|████████▌ | 92/107 [01:52<00:18,  1.22s/it]Validating lr=5e-07, train epoch 0.:  87%|████████▋ | 93/107 [01:54<00:17,  1.22s/it]Validating lr=5e-07, train epoch 0.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Validating lr=5e-07, train epoch 0.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Validating lr=5e-07, train epoch 0.:  90%|████████▉ | 96/107 [01:57<00:13,  1.24s/it]Validating lr=5e-07, train epoch 0.:  91%|█████████ | 97/107 [01:58<00:12,  1.23s/it]Validating lr=5e-07, train epoch 0.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Validating lr=5e-07, train epoch 0.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=5e-07, train epoch 0.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Validating lr=5e-07, train epoch 0.:  94%|█████████▍| 101/107 [02:03<00:07,  1.24s/it]Validating lr=5e-07, train epoch 0.:  95%|█████████▌| 102/107 [02:05<00:06,  1.24s/it]Validating lr=5e-07, train epoch 0.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Validating lr=5e-07, train epoch 0.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Validating lr=5e-07, train epoch 0.:  98%|█████████▊| 105/107 [02:08<00:02,  1.24s/it]Validating lr=5e-07, train epoch 0.:  99%|█████████▉| 106/107 [02:10<00:01,  1.24s/it]Validating lr=5e-07, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.24s/it]Validating lr=5e-07, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Validating lr=5e-07, train epoch 1.:   0%|          | 0/107 [00:00<?, ?it/s]Validating lr=5e-07, train epoch 1.:   1%|          | 1/107 [00:01<02:12,  1.25s/it]Validating lr=5e-07, train epoch 1.:   2%|▏         | 2/107 [00:02<02:10,  1.24s/it]Validating lr=5e-07, train epoch 1.:   3%|▎         | 3/107 [00:03<02:08,  1.24s/it]Validating lr=5e-07, train epoch 1.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Validating lr=5e-07, train epoch 1.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Validating lr=5e-07, train epoch 1.:   6%|▌         | 6/107 [00:07<02:04,  1.24s/it]Validating lr=5e-07, train epoch 1.:   7%|▋         | 7/107 [00:08<02:03,  1.23s/it]Validating lr=5e-07, train epoch 1.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Validating lr=5e-07, train epoch 1.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Validating lr=5e-07, train epoch 1.:   9%|▉         | 10/107 [00:12<01:58,  1.23s/it]Validating lr=5e-07, train epoch 1.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Validating lr=5e-07, train epoch 1.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Validating lr=5e-07, train epoch 1.:  12%|█▏        | 13/107 [00:15<01:55,  1.23s/it]Validating lr=5e-07, train epoch 1.:  13%|█▎        | 14/107 [00:17<01:57,  1.26s/it]Validating lr=5e-07, train epoch 1.:  14%|█▍        | 15/107 [00:18<01:55,  1.26s/it]Validating lr=5e-07, train epoch 1.:  15%|█▍        | 16/107 [00:19<01:53,  1.25s/it]Validating lr=5e-07, train epoch 1.:  16%|█▌        | 17/107 [00:21<01:52,  1.24s/it]Validating lr=5e-07, train epoch 1.:  17%|█▋        | 18/107 [00:22<01:50,  1.24s/it]Validating lr=5e-07, train epoch 1.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Validating lr=5e-07, train epoch 1.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Validating lr=5e-07, train epoch 1.:  20%|█▉        | 21/107 [00:25<01:44,  1.22s/it]Validating lr=5e-07, train epoch 1.:  21%|██        | 22/107 [00:27<01:43,  1.22s/it]Validating lr=5e-07, train epoch 1.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Validating lr=5e-07, train epoch 1.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Validating lr=5e-07, train epoch 1.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Validating lr=5e-07, train epoch 1.:  24%|██▍       | 26/107 [00:32<01:39,  1.23s/it]Validating lr=5e-07, train epoch 1.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Validating lr=5e-07, train epoch 1.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Validating lr=5e-07, train epoch 1.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Validating lr=5e-07, train epoch 1.:  28%|██▊       | 30/107 [00:36<01:33,  1.22s/it]Validating lr=5e-07, train epoch 1.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Validating lr=5e-07, train epoch 1.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Validating lr=5e-07, train epoch 1.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Validating lr=5e-07, train epoch 1.:  32%|███▏      | 34/107 [00:41<01:30,  1.24s/it]Validating lr=5e-07, train epoch 1.:  33%|███▎      | 35/107 [00:43<01:28,  1.23s/it]Validating lr=5e-07, train epoch 1.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Validating lr=5e-07, train epoch 1.:  35%|███▍      | 37/107 [00:45<01:25,  1.23s/it]Validating lr=5e-07, train epoch 1.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Validating lr=5e-07, train epoch 1.:  36%|███▋      | 39/107 [00:47<01:22,  1.22s/it]Validating lr=5e-07, train epoch 1.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Validating lr=5e-07, train epoch 1.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Validating lr=5e-07, train epoch 1.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Validating lr=5e-07, train epoch 1.:  40%|████      | 43/107 [00:52<01:17,  1.22s/it]Validating lr=5e-07, train epoch 1.:  41%|████      | 44/107 [00:54<01:16,  1.22s/it]Validating lr=5e-07, train epoch 1.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Validating lr=5e-07, train epoch 1.:  43%|████▎     | 46/107 [00:56<01:14,  1.23s/it]Validating lr=5e-07, train epoch 1.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Validating lr=5e-07, train epoch 1.:  45%|████▍     | 48/107 [00:58<01:12,  1.23s/it]Validating lr=5e-07, train epoch 1.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Validating lr=5e-07, train epoch 1.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Validating lr=5e-07, train epoch 1.:  48%|████▊     | 51/107 [01:02<01:09,  1.23s/it]Validating lr=5e-07, train epoch 1.:  49%|████▊     | 52/107 [01:03<01:07,  1.24s/it]Validating lr=5e-07, train epoch 1.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Validating lr=5e-07, train epoch 1.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Validating lr=5e-07, train epoch 1.:  51%|█████▏    | 55/107 [01:07<01:04,  1.24s/it]Validating lr=5e-07, train epoch 1.:  52%|█████▏    | 56/107 [01:08<01:03,  1.24s/it]Validating lr=5e-07, train epoch 1.:  53%|█████▎    | 57/107 [01:10<01:01,  1.24s/it]Validating lr=5e-07, train epoch 1.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Validating lr=5e-07, train epoch 1.:  55%|█████▌    | 59/107 [01:12<00:59,  1.23s/it]Validating lr=5e-07, train epoch 1.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Validating lr=5e-07, train epoch 1.:  57%|█████▋    | 61/107 [01:15<00:56,  1.23s/it]Validating lr=5e-07, train epoch 1.:  58%|█████▊    | 62/107 [01:16<00:54,  1.22s/it]Validating lr=5e-07, train epoch 1.:  59%|█████▉    | 63/107 [01:17<00:53,  1.23s/it]Validating lr=5e-07, train epoch 1.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Validating lr=5e-07, train epoch 1.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Validating lr=5e-07, train epoch 1.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Validating lr=5e-07, train epoch 1.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Validating lr=5e-07, train epoch 1.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Validating lr=5e-07, train epoch 1.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Validating lr=5e-07, train epoch 1.:  65%|██████▌   | 70/107 [01:26<00:44,  1.21s/it]Validating lr=5e-07, train epoch 1.:  66%|██████▋   | 71/107 [01:27<00:43,  1.22s/it]Validating lr=5e-07, train epoch 1.:  67%|██████▋   | 72/107 [01:28<00:42,  1.23s/it]Validating lr=5e-07, train epoch 1.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Validating lr=5e-07, train epoch 1.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Validating lr=5e-07, train epoch 1.:  70%|███████   | 75/107 [01:32<00:39,  1.22s/it]Validating lr=5e-07, train epoch 1.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Validating lr=5e-07, train epoch 1.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Validating lr=5e-07, train epoch 1.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Validating lr=5e-07, train epoch 1.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Validating lr=5e-07, train epoch 1.:  75%|███████▍  | 80/107 [01:38<00:33,  1.22s/it]Validating lr=5e-07, train epoch 1.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Validating lr=5e-07, train epoch 1.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Validating lr=5e-07, train epoch 1.:  78%|███████▊  | 83/107 [01:42<00:29,  1.23s/it]Validating lr=5e-07, train epoch 1.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Validating lr=5e-07, train epoch 1.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Validating lr=5e-07, train epoch 1.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Validating lr=5e-07, train epoch 1.:  81%|████████▏ | 87/107 [01:46<00:24,  1.22s/it]Validating lr=5e-07, train epoch 1.:  82%|████████▏ | 88/107 [01:48<00:23,  1.22s/it]Validating lr=5e-07, train epoch 1.:  83%|████████▎ | 89/107 [01:49<00:22,  1.22s/it]Validating lr=5e-07, train epoch 1.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Validating lr=5e-07, train epoch 1.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Validating lr=5e-07, train epoch 1.:  86%|████████▌ | 92/107 [01:53<00:18,  1.23s/it]Validating lr=5e-07, train epoch 1.:  87%|████████▋ | 93/107 [01:54<00:17,  1.24s/it]Validating lr=5e-07, train epoch 1.:  88%|████████▊ | 94/107 [01:55<00:16,  1.24s/it]Validating lr=5e-07, train epoch 1.:  89%|████████▉ | 95/107 [01:56<00:14,  1.24s/it]Validating lr=5e-07, train epoch 1.:  90%|████████▉ | 96/107 [01:57<00:13,  1.24s/it]Validating lr=5e-07, train epoch 1.:  91%|█████████ | 97/107 [01:59<00:12,  1.24s/it]Validating lr=5e-07, train epoch 1.:  92%|█████████▏| 98/107 [02:00<00:11,  1.24s/it]Validating lr=5e-07, train epoch 1.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Validating lr=5e-07, train epoch 1.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Validating lr=5e-07, train epoch 1.:  94%|█████████▍| 101/107 [02:04<00:07,  1.22s/it]Validating lr=5e-07, train epoch 1.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Validating lr=5e-07, train epoch 1.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Validating lr=5e-07, train epoch 1.:  97%|█████████▋| 104/107 [02:07<00:03,  1.21s/it]Validating lr=5e-07, train epoch 1.:  98%|█████████▊| 105/107 [02:08<00:02,  1.21s/it]Validating lr=5e-07, train epoch 1.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Validating lr=5e-07, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Validating lr=5e-07, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
Evaluating for lr=5e-07:   0%|          | 0/11 [00:00<?, ?it/s]Evaluating for lr=5e-07:   9%|▉         | 1/11 [00:00<00:05,  1.98it/s]Evaluating for lr=5e-07:  18%|█▊        | 2/11 [00:00<00:04,  2.05it/s]Evaluating for lr=5e-07:  27%|██▋       | 3/11 [00:01<00:03,  2.03it/s]Evaluating for lr=5e-07:  36%|███▋      | 4/11 [00:01<00:03,  2.04it/s]Evaluating for lr=5e-07:  45%|████▌     | 5/11 [00:02<00:02,  2.03it/s]Evaluating for lr=5e-07:  55%|█████▍    | 6/11 [00:02<00:02,  2.01it/s]Evaluating for lr=5e-07:  64%|██████▎   | 7/11 [00:03<00:01,  2.02it/s]Evaluating for lr=5e-07:  73%|███████▎  | 8/11 [00:03<00:01,  2.01it/s]Evaluating for lr=5e-07:  82%|████████▏ | 9/11 [00:04<00:00,  2.03it/s]Evaluating for lr=5e-07:  91%|█████████ | 10/11 [00:04<00:00,  2.00it/s]Evaluating for lr=5e-07: 100%|██████████| 11/11 [00:05<00:00,  1.99it/s]Evaluating for lr=5e-07: 100%|██████████| 11/11 [00:05<00:00,  2.01it/s]
Hyperparameter tuning process completed, using lr 0.0005!
[2025-06-25 07:45:06,778] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2025-06-25 07:45:28,420] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-06-25 07:45:28,423] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-06-25 07:45:28,423] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-06-25 07:45:28,485] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-06-25 07:45:28,485] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2025-06-25 07:45:28,485] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-06-25 07:45:28,485] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-06-25 07:45:28,485] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0005], mom=[(0.9, 0.999)]
[2025-06-25 07:45:28,485] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   amp_params ................... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15248fc697d0>
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   dump_state ................... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2025-06-25 07:45:28,486] [INFO] [config.py:1000:print]   global_rank .................. 0
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   loss_scale ................... 0
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   optimizer_name ............... adamw
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 0.0005, 'weight_decay': 0.01}
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   pld_params ................... False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   steps_per_print .............. 100000
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   train_batch_size ............. 5120
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  128
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   world_size ................... 40
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2025-06-25 07:45:28,487] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2025-06-25 07:45:28,487] [INFO] [config.py:986:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 128, 
    "train_batch_size": 5.120000e+03, 
    "steps_per_print": 1.000000e+05, 
    "gradient_accumulation_steps": 1, 
    "fp16": {
        "enabled": false
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 0.0005, 
            "weight_decay": 0.01
        }
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false
    }, 
    "zero_optimization": {
        "stage": 0
    }
}
Main training loop, train epoch 0.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 0.:   1%|          | 1/107 [00:01<02:19,  1.31s/it]Main training loop, train epoch 0.:   2%|▏         | 2/107 [00:02<02:12,  1.26s/it]Main training loop, train epoch 0.:   3%|▎         | 3/107 [00:03<02:09,  1.24s/it]Main training loop, train epoch 0.:   4%|▎         | 4/107 [00:04<02:06,  1.23s/it]Main training loop, train epoch 0.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 0.:   6%|▌         | 6/107 [00:07<02:04,  1.24s/it]Main training loop, train epoch 0.:   7%|▋         | 7/107 [00:08<02:02,  1.23s/it]Main training loop, train epoch 0.:   7%|▋         | 8/107 [00:09<02:02,  1.23s/it]Main training loop, train epoch 0.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 0.:   9%|▉         | 10/107 [00:12<01:58,  1.23s/it]Main training loop, train epoch 0.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Main training loop, train epoch 0.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Main training loop, train epoch 0.:  12%|█▏        | 13/107 [00:16<01:55,  1.22s/it]Main training loop, train epoch 0.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 0.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Main training loop, train epoch 0.:  15%|█▍        | 16/107 [00:19<01:50,  1.22s/it]Main training loop, train epoch 0.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Main training loop, train epoch 0.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Main training loop, train epoch 0.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Main training loop, train epoch 0.:  19%|█▊        | 20/107 [00:24<01:45,  1.22s/it]Main training loop, train epoch 0.:  20%|█▉        | 21/107 [00:25<01:44,  1.21s/it]Main training loop, train epoch 0.:  21%|██        | 22/107 [00:26<01:43,  1.22s/it]Main training loop, train epoch 0.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 0.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 0.:  23%|██▎       | 25/107 [00:30<01:40,  1.22s/it]Main training loop, train epoch 0.:  24%|██▍       | 26/107 [00:31<01:38,  1.22s/it]Main training loop, train epoch 0.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Main training loop, train epoch 0.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Main training loop, train epoch 0.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Main training loop, train epoch 0.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 0.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Main training loop, train epoch 0.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 0.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Main training loop, train epoch 0.:  32%|███▏      | 34/107 [00:41<01:30,  1.24s/it]Main training loop, train epoch 0.:  33%|███▎      | 35/107 [00:42<01:29,  1.24s/it]Main training loop, train epoch 0.:  34%|███▎      | 36/107 [00:44<01:28,  1.24s/it]Main training loop, train epoch 0.:  35%|███▍      | 37/107 [00:45<01:26,  1.23s/it]Main training loop, train epoch 0.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 0.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Main training loop, train epoch 0.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Main training loop, train epoch 0.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Main training loop, train epoch 0.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Main training loop, train epoch 0.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 0.:  41%|████      | 44/107 [00:54<01:17,  1.23s/it]Main training loop, train epoch 0.:  42%|████▏     | 45/107 [00:55<01:16,  1.24s/it]Main training loop, train epoch 0.:  43%|████▎     | 46/107 [00:56<01:15,  1.24s/it]Main training loop, train epoch 0.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 0.:  45%|████▍     | 48/107 [00:58<01:12,  1.23s/it]Main training loop, train epoch 0.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Main training loop, train epoch 0.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Main training loop, train epoch 0.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 0.:  49%|████▊     | 52/107 [01:03<01:07,  1.24s/it]Main training loop, train epoch 0.:  50%|████▉     | 53/107 [01:05<01:06,  1.24s/it]Main training loop, train epoch 0.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 0.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Main training loop, train epoch 0.:  52%|█████▏    | 56/107 [01:08<01:03,  1.24s/it]Main training loop, train epoch 0.:  53%|█████▎    | 57/107 [01:10<01:02,  1.24s/it]Main training loop, train epoch 0.:  54%|█████▍    | 58/107 [01:11<01:00,  1.24s/it]Main training loop, train epoch 0.:  55%|█████▌    | 59/107 [01:12<00:59,  1.25s/it]Main training loop, train epoch 0.:  56%|█████▌    | 60/107 [01:13<00:58,  1.24s/it]Main training loop, train epoch 0.:  57%|█████▋    | 61/107 [01:15<00:56,  1.23s/it]Main training loop, train epoch 0.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Main training loop, train epoch 0.:  59%|█████▉    | 63/107 [01:17<00:53,  1.23s/it]Main training loop, train epoch 0.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Main training loop, train epoch 0.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Main training loop, train epoch 0.:  62%|██████▏   | 66/107 [01:21<00:50,  1.24s/it]Main training loop, train epoch 0.:  63%|██████▎   | 67/107 [01:22<00:49,  1.24s/it]Main training loop, train epoch 0.:  64%|██████▎   | 68/107 [01:23<00:48,  1.24s/it]Main training loop, train epoch 0.:  64%|██████▍   | 69/107 [01:24<00:47,  1.24s/it]Main training loop, train epoch 0.:  65%|██████▌   | 70/107 [01:26<00:45,  1.23s/it]Main training loop, train epoch 0.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 0.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Main training loop, train epoch 0.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 0.:  69%|██████▉   | 74/107 [01:31<00:40,  1.24s/it]Main training loop, train epoch 0.:  70%|███████   | 75/107 [01:32<00:39,  1.24s/it]Main training loop, train epoch 0.:  71%|███████   | 76/107 [01:33<00:38,  1.24s/it]Main training loop, train epoch 0.:  72%|███████▏  | 77/107 [01:34<00:37,  1.24s/it]Main training loop, train epoch 0.:  73%|███████▎  | 78/107 [01:36<00:35,  1.24s/it]Main training loop, train epoch 0.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Main training loop, train epoch 0.:  75%|███████▍  | 80/107 [01:38<00:33,  1.22s/it]Main training loop, train epoch 0.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 0.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Main training loop, train epoch 0.:  78%|███████▊  | 83/107 [01:42<00:29,  1.23s/it]Main training loop, train epoch 0.:  79%|███████▊  | 84/107 [01:43<00:28,  1.22s/it]Main training loop, train epoch 0.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Main training loop, train epoch 0.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 0.:  81%|████████▏ | 87/107 [01:47<00:24,  1.23s/it]Main training loop, train epoch 0.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Main training loop, train epoch 0.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Main training loop, train epoch 0.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 0.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 0.:  86%|████████▌ | 92/107 [01:53<00:18,  1.23s/it]Main training loop, train epoch 0.:  87%|████████▋ | 93/107 [01:54<00:17,  1.22s/it]Main training loop, train epoch 0.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Main training loop, train epoch 0.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 0.:  90%|████████▉ | 96/107 [01:58<00:13,  1.22s/it]Main training loop, train epoch 0.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Main training loop, train epoch 0.:  92%|█████████▏| 98/107 [02:00<00:10,  1.22s/it]Main training loop, train epoch 0.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Main training loop, train epoch 0.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 0.:  94%|█████████▍| 101/107 [02:04<00:07,  1.22s/it]Main training loop, train epoch 0.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 0.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 0.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 0.:  98%|█████████▊| 105/107 [02:09<00:02,  1.22s/it]Main training loop, train epoch 0.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Main training loop, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 0.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 07:47:40,004] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_0 is about to be saved!
[2025-06-25 07:47:40,035] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_0/mp_rank_00_model_states.pt
[2025-06-25 07:47:40,035] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_0/mp_rank_00_model_states.pt...
Initialized deepspeed on global rank 1, local rank 1 with world size 40.
[2025-06-25 07:47:40,035] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 2, local rank 2 with world size 40.
[2025-06-25 07:47:40,035] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 3, local rank 3 with world size 40.
[2025-06-25 07:47:40,035] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 32, local rank 0 with world size 40.
[2025-06-25 07:47:40,036] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 33, local rank 1 with world size 40.
[2025-06-25 07:47:40,037] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 34, local rank 2 with world size 40.
[2025-06-25 07:47:40,036] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 35, local rank 3 with world size 40.
[2025-06-25 07:47:40,037] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 37, local rank 1 with world size 40.
[2025-06-25 07:47:40,038] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 36, local rank 0 with world size 40.
[2025-06-25 07:47:40,038] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 38, local rank 2 with world size 40.
[2025-06-25 07:47:40,038] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 39, local rank 3 with world size 40.
[2025-06-25 07:47:40,038] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 17, local rank 1 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 18, local rank 2 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 20, local rank 0 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 19, local rank 3 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 16, local rank 0 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 10, local rank 2 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 22, local rank 2 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 8, local rank 0 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 21, local rank 1 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 25, local rank 1 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 9, local rank 1 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 23, local rank 3 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 26, local rank 2 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 13, local rank 1 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 24, local rank 0 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 27, local rank 3 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 11, local rank 3 with world size 40.
[2025-06-25 07:47:40,039] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 7, local rank 3 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 12, local rank 0 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 28, local rank 0 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 30, local rank 2 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 14, local rank 2 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 15, local rank 3 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 29, local rank 1 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 4, local rank 0 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 5, local rank 1 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 31, local rank 3 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Initialized deepspeed on global rank 6, local rank 2 with world size 40.
[2025-06-25 07:47:40,040] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
[2025-06-25 07:47:42,202] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_0/mp_rank_00_model_states.pt.
[2025-06-25 07:47:42,202] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_0 is ready now!
Main training loop, train epoch 1.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 1.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Main training loop, train epoch 1.:   2%|▏         | 2/107 [00:02<02:11,  1.25s/it]Main training loop, train epoch 1.:   3%|▎         | 3/107 [00:03<02:09,  1.25s/it]Main training loop, train epoch 1.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Main training loop, train epoch 1.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 1.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Main training loop, train epoch 1.:   7%|▋         | 7/107 [00:08<02:02,  1.22s/it]Main training loop, train epoch 1.:   7%|▋         | 8/107 [00:09<02:00,  1.22s/it]Main training loop, train epoch 1.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Main training loop, train epoch 1.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Main training loop, train epoch 1.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Main training loop, train epoch 1.:  11%|█         | 12/107 [00:14<01:55,  1.22s/it]Main training loop, train epoch 1.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Main training loop, train epoch 1.:  13%|█▎        | 14/107 [00:17<01:52,  1.21s/it]Main training loop, train epoch 1.:  14%|█▍        | 15/107 [00:18<01:51,  1.21s/it]Main training loop, train epoch 1.:  15%|█▍        | 16/107 [00:19<01:51,  1.22s/it]Main training loop, train epoch 1.:  16%|█▌        | 17/107 [00:20<01:50,  1.22s/it]Main training loop, train epoch 1.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 1.:  18%|█▊        | 19/107 [00:23<01:47,  1.23s/it]Main training loop, train epoch 1.:  19%|█▊        | 20/107 [00:24<01:46,  1.22s/it]Main training loop, train epoch 1.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 1.:  21%|██        | 22/107 [00:26<01:44,  1.23s/it]Main training loop, train epoch 1.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 1.:  22%|██▏       | 24/107 [00:29<01:41,  1.23s/it]Main training loop, train epoch 1.:  23%|██▎       | 25/107 [00:30<01:41,  1.23s/it]Main training loop, train epoch 1.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 1.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Main training loop, train epoch 1.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Main training loop, train epoch 1.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Main training loop, train epoch 1.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 1.:  29%|██▉       | 31/107 [00:37<01:33,  1.23s/it]Main training loop, train epoch 1.:  30%|██▉       | 32/107 [00:39<01:31,  1.23s/it]Main training loop, train epoch 1.:  31%|███       | 33/107 [00:40<01:30,  1.22s/it]Main training loop, train epoch 1.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Main training loop, train epoch 1.:  33%|███▎      | 35/107 [00:42<01:28,  1.23s/it]Main training loop, train epoch 1.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 1.:  35%|███▍      | 37/107 [00:45<01:26,  1.23s/it]Main training loop, train epoch 1.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Main training loop, train epoch 1.:  36%|███▋      | 39/107 [00:47<01:22,  1.22s/it]Main training loop, train epoch 1.:  37%|███▋      | 40/107 [00:48<01:21,  1.22s/it]Main training loop, train epoch 1.:  38%|███▊      | 41/107 [00:50<01:20,  1.21s/it]Main training loop, train epoch 1.:  39%|███▉      | 42/107 [00:51<01:18,  1.21s/it]Main training loop, train epoch 1.:  40%|████      | 43/107 [00:52<01:18,  1.22s/it]Main training loop, train epoch 1.:  41%|████      | 44/107 [00:53<01:16,  1.22s/it]Main training loop, train epoch 1.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Main training loop, train epoch 1.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 1.:  44%|████▍     | 47/107 [00:57<01:13,  1.22s/it]Main training loop, train epoch 1.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Main training loop, train epoch 1.:  46%|████▌     | 49/107 [00:59<01:11,  1.23s/it]Main training loop, train epoch 1.:  47%|████▋     | 50/107 [01:01<01:09,  1.23s/it]Main training loop, train epoch 1.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 1.:  49%|████▊     | 52/107 [01:03<01:07,  1.24s/it]Main training loop, train epoch 1.:  50%|████▉     | 53/107 [01:04<01:06,  1.23s/it]Main training loop, train epoch 1.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Main training loop, train epoch 1.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Main training loop, train epoch 1.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 1.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 1.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 1.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 1.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Main training loop, train epoch 1.:  57%|█████▋    | 61/107 [01:14<00:56,  1.22s/it]Main training loop, train epoch 1.:  58%|█████▊    | 62/107 [01:15<00:55,  1.22s/it]Main training loop, train epoch 1.:  59%|█████▉    | 63/107 [01:17<00:53,  1.23s/it]Main training loop, train epoch 1.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Main training loop, train epoch 1.:  61%|██████    | 65/107 [01:19<00:51,  1.24s/it]Main training loop, train epoch 1.:  62%|██████▏   | 66/107 [01:20<00:50,  1.23s/it]Main training loop, train epoch 1.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Main training loop, train epoch 1.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Main training loop, train epoch 1.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 1.:  65%|██████▌   | 70/107 [01:25<00:45,  1.22s/it]Main training loop, train epoch 1.:  66%|██████▋   | 71/107 [01:26<00:44,  1.22s/it]Main training loop, train epoch 1.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 1.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Main training loop, train epoch 1.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Main training loop, train epoch 1.:  70%|███████   | 75/107 [01:31<00:39,  1.23s/it]Main training loop, train epoch 1.:  71%|███████   | 76/107 [01:33<00:37,  1.22s/it]Main training loop, train epoch 1.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Main training loop, train epoch 1.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Main training loop, train epoch 1.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Main training loop, train epoch 1.:  75%|███████▍  | 80/107 [01:37<00:33,  1.23s/it]Main training loop, train epoch 1.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Main training loop, train epoch 1.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 1.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 1.:  79%|███████▊  | 84/107 [01:42<00:28,  1.24s/it]Main training loop, train epoch 1.:  79%|███████▉  | 85/107 [01:44<00:27,  1.24s/it]Main training loop, train epoch 1.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 1.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 1.:  82%|████████▏ | 88/107 [01:47<00:23,  1.22s/it]Main training loop, train epoch 1.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Main training loop, train epoch 1.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 1.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 1.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Main training loop, train epoch 1.:  87%|████████▋ | 93/107 [01:53<00:17,  1.23s/it]Main training loop, train epoch 1.:  88%|████████▊ | 94/107 [01:55<00:16,  1.24s/it]Main training loop, train epoch 1.:  89%|████████▉ | 95/107 [01:56<00:14,  1.24s/it]Main training loop, train epoch 1.:  90%|████████▉ | 96/107 [01:57<00:13,  1.24s/it]Main training loop, train epoch 1.:  91%|█████████ | 97/107 [01:58<00:12,  1.24s/it]Main training loop, train epoch 1.:  92%|█████████▏| 98/107 [02:00<00:11,  1.24s/it]Main training loop, train epoch 1.:  93%|█████████▎| 99/107 [02:01<00:09,  1.24s/it]Main training loop, train epoch 1.:  93%|█████████▎| 100/107 [02:02<00:08,  1.24s/it]Main training loop, train epoch 1.:  94%|█████████▍| 101/107 [02:03<00:07,  1.24s/it]Main training loop, train epoch 1.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 1.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Main training loop, train epoch 1.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 1.:  98%|█████████▊| 105/107 [02:08<00:02,  1.22s/it]Main training loop, train epoch 1.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.24s/it]Main training loop, train epoch 1.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 07:49:53,585] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_1 is about to be saved!
[2025-06-25 07:49:53,657] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,657] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,657] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,657] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,658] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_1/mp_rank_00_model_states.pt
[2025-06-25 07:49:53,658] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,658] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_1/mp_rank_00_model_states.pt...
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,658] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,658] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,658] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,658] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,658] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,664] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,664] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,664] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,664] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,664] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,664] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,664] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,664] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,667] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,668] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,668] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:53,668] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
[2025-06-25 07:49:55,777] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_1/mp_rank_00_model_states.pt.
[2025-06-25 07:49:55,777] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_1 is ready now!
Testing on epoch 1.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 1.:   9%|▉         | 1/11 [00:00<00:06,  1.51it/s]Testing on epoch 1.:  18%|█▊        | 2/11 [00:01<00:05,  1.51it/s]Testing on epoch 1.:  27%|██▋       | 3/11 [00:01<00:05,  1.58it/s]Testing on epoch 1.:  36%|███▋      | 4/11 [00:02<00:04,  1.60it/s]Testing on epoch 1.:  45%|████▌     | 5/11 [00:03<00:03,  1.59it/s]Testing on epoch 1.:  55%|█████▍    | 6/11 [00:03<00:03,  1.62it/s]Testing on epoch 1.:  64%|██████▎   | 7/11 [00:04<00:02,  1.60it/s]Testing on epoch 1.:  73%|███████▎  | 8/11 [00:04<00:01,  1.65it/s]Testing on epoch 1.:  82%|████████▏ | 9/11 [00:05<00:01,  1.66it/s]Testing on epoch 1.:  91%|█████████ | 10/11 [00:06<00:00,  1.67it/s]Testing on epoch 1.: 100%|██████████| 11/11 [00:06<00:00,  1.65it/s]Testing on epoch 1.: 100%|██████████| 11/11 [00:06<00:00,  1.62it/s]
Main training loop, train epoch 2.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 2.:   1%|          | 1/107 [00:01<02:12,  1.25s/it]Main training loop, train epoch 2.:   2%|▏         | 2/107 [00:02<02:10,  1.24s/it]Main training loop, train epoch 2.:   3%|▎         | 3/107 [00:03<02:08,  1.23s/it]Main training loop, train epoch 2.:   4%|▎         | 4/107 [00:04<02:06,  1.23s/it]Main training loop, train epoch 2.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 2.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Main training loop, train epoch 2.:   7%|▋         | 7/107 [00:08<02:02,  1.22s/it]Main training loop, train epoch 2.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Main training loop, train epoch 2.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Main training loop, train epoch 2.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Main training loop, train epoch 2.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Main training loop, train epoch 2.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Main training loop, train epoch 2.:  12%|█▏        | 13/107 [00:15<01:55,  1.23s/it]Main training loop, train epoch 2.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 2.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Main training loop, train epoch 2.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Main training loop, train epoch 2.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Main training loop, train epoch 2.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 2.:  18%|█▊        | 19/107 [00:23<01:48,  1.24s/it]Main training loop, train epoch 2.:  19%|█▊        | 20/107 [00:24<01:47,  1.23s/it]Main training loop, train epoch 2.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 2.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Main training loop, train epoch 2.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 2.:  22%|██▏       | 24/107 [00:29<01:41,  1.23s/it]Main training loop, train epoch 2.:  23%|██▎       | 25/107 [00:30<01:40,  1.22s/it]Main training loop, train epoch 2.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 2.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 2.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Main training loop, train epoch 2.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Main training loop, train epoch 2.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 2.:  29%|██▉       | 31/107 [00:38<01:32,  1.22s/it]Main training loop, train epoch 2.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Main training loop, train epoch 2.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Main training loop, train epoch 2.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Main training loop, train epoch 2.:  33%|███▎      | 35/107 [00:42<01:28,  1.23s/it]Main training loop, train epoch 2.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Main training loop, train epoch 2.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 2.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Main training loop, train epoch 2.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Main training loop, train epoch 2.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Main training loop, train epoch 2.:  38%|███▊      | 41/107 [00:50<01:20,  1.23s/it]Main training loop, train epoch 2.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Main training loop, train epoch 2.:  40%|████      | 43/107 [00:52<01:18,  1.22s/it]Main training loop, train epoch 2.:  41%|████      | 44/107 [00:53<01:16,  1.22s/it]Main training loop, train epoch 2.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 2.:  43%|████▎     | 46/107 [00:56<01:14,  1.23s/it]Main training loop, train epoch 2.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 2.:  45%|████▍     | 48/107 [00:58<01:12,  1.23s/it]Main training loop, train epoch 2.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Main training loop, train epoch 2.:  47%|████▋     | 50/107 [01:01<01:09,  1.23s/it]Main training loop, train epoch 2.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Main training loop, train epoch 2.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 2.:  50%|████▉     | 53/107 [01:05<01:05,  1.22s/it]Main training loop, train epoch 2.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 2.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Main training loop, train epoch 2.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 2.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 2.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Main training loop, train epoch 2.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 2.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Main training loop, train epoch 2.:  57%|█████▋    | 61/107 [01:14<00:56,  1.22s/it]Main training loop, train epoch 2.:  58%|█████▊    | 62/107 [01:16<00:54,  1.22s/it]Main training loop, train epoch 2.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Main training loop, train epoch 2.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Main training loop, train epoch 2.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Main training loop, train epoch 2.:  62%|██████▏   | 66/107 [01:20<00:50,  1.22s/it]Main training loop, train epoch 2.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Main training loop, train epoch 2.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Main training loop, train epoch 2.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Main training loop, train epoch 2.:  65%|██████▌   | 70/107 [01:25<00:45,  1.22s/it]Main training loop, train epoch 2.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 2.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 2.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 2.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Main training loop, train epoch 2.:  70%|███████   | 75/107 [01:31<00:39,  1.22s/it]Main training loop, train epoch 2.:  71%|███████   | 76/107 [01:33<00:37,  1.22s/it]Main training loop, train epoch 2.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 2.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 2.:  74%|███████▍  | 79/107 [01:36<00:34,  1.23s/it]Main training loop, train epoch 2.:  75%|███████▍  | 80/107 [01:38<00:33,  1.22s/it]Main training loop, train epoch 2.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 2.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 2.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 2.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 2.:  79%|███████▉  | 85/107 [01:44<00:26,  1.23s/it]Main training loop, train epoch 2.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 2.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 2.:  82%|████████▏ | 88/107 [01:47<00:23,  1.23s/it]Main training loop, train epoch 2.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Main training loop, train epoch 2.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 2.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 2.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Main training loop, train epoch 2.:  87%|████████▋ | 93/107 [01:54<00:17,  1.25s/it]Main training loop, train epoch 2.:  88%|████████▊ | 94/107 [01:55<00:16,  1.25s/it]Main training loop, train epoch 2.:  89%|████████▉ | 95/107 [01:56<00:14,  1.24s/it]Main training loop, train epoch 2.:  90%|████████▉ | 96/107 [01:57<00:13,  1.24s/it]Main training loop, train epoch 2.:  91%|█████████ | 97/107 [01:59<00:12,  1.23s/it]Main training loop, train epoch 2.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Main training loop, train epoch 2.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 2.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 2.:  94%|█████████▍| 101/107 [02:03<00:07,  1.22s/it]Main training loop, train epoch 2.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 2.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 2.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 2.:  98%|█████████▊| 105/107 [02:08<00:02,  1.22s/it]Main training loop, train epoch 2.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Main training loop, train epoch 2.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 2.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 07:52:13,933] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_2 is about to be saved!
[2025-06-25 07:52:14,007] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,007] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,007] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,007] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_2/mp_rank_00_model_states.pt
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_2/mp_rank_00_model_states.pt...
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,011] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,011] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,015] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,015] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,015] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,015] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,015] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,016] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,016] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,015] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,016] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,017] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,017] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:14,016] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
[2025-06-25 07:52:16,124] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_2/mp_rank_00_model_states.pt.
[2025-06-25 07:52:16,124] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_2 is ready now!
Main training loop, train epoch 3.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 3.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Main training loop, train epoch 3.:   2%|▏         | 2/107 [00:02<02:10,  1.24s/it]Main training loop, train epoch 3.:   3%|▎         | 3/107 [00:03<02:07,  1.23s/it]Main training loop, train epoch 3.:   4%|▎         | 4/107 [00:04<02:07,  1.23s/it]Main training loop, train epoch 3.:   5%|▍         | 5/107 [00:06<02:04,  1.22s/it]Main training loop, train epoch 3.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Main training loop, train epoch 3.:   7%|▋         | 7/107 [00:08<02:01,  1.22s/it]Main training loop, train epoch 3.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Main training loop, train epoch 3.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Main training loop, train epoch 3.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Main training loop, train epoch 3.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Main training loop, train epoch 3.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Main training loop, train epoch 3.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Main training loop, train epoch 3.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 3.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Main training loop, train epoch 3.:  15%|█▍        | 16/107 [00:19<01:51,  1.23s/it]Main training loop, train epoch 3.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Main training loop, train epoch 3.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Main training loop, train epoch 3.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Main training loop, train epoch 3.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Main training loop, train epoch 3.:  20%|█▉        | 21/107 [00:25<01:45,  1.22s/it]Main training loop, train epoch 3.:  21%|██        | 22/107 [00:26<01:44,  1.23s/it]Main training loop, train epoch 3.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 3.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 3.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 3.:  24%|██▍       | 26/107 [00:31<01:39,  1.22s/it]Main training loop, train epoch 3.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Main training loop, train epoch 3.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Main training loop, train epoch 3.:  27%|██▋       | 29/107 [00:35<01:34,  1.22s/it]Main training loop, train epoch 3.:  28%|██▊       | 30/107 [00:36<01:33,  1.22s/it]Main training loop, train epoch 3.:  29%|██▉       | 31/107 [00:37<01:33,  1.23s/it]Main training loop, train epoch 3.:  30%|██▉       | 32/107 [00:39<01:31,  1.23s/it]Main training loop, train epoch 3.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Main training loop, train epoch 3.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Main training loop, train epoch 3.:  33%|███▎      | 35/107 [00:42<01:28,  1.23s/it]Main training loop, train epoch 3.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 3.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 3.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 3.:  36%|███▋      | 39/107 [00:47<01:22,  1.22s/it]Main training loop, train epoch 3.:  37%|███▋      | 40/107 [00:48<01:21,  1.22s/it]Main training loop, train epoch 3.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Main training loop, train epoch 3.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Main training loop, train epoch 3.:  40%|████      | 43/107 [00:52<01:18,  1.22s/it]Main training loop, train epoch 3.:  41%|████      | 44/107 [00:53<01:16,  1.22s/it]Main training loop, train epoch 3.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Main training loop, train epoch 3.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 3.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 3.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Main training loop, train epoch 3.:  46%|████▌     | 49/107 [00:59<01:10,  1.22s/it]Main training loop, train epoch 3.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Main training loop, train epoch 3.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Main training loop, train epoch 3.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 3.:  50%|████▉     | 53/107 [01:04<01:06,  1.22s/it]Main training loop, train epoch 3.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Main training loop, train epoch 3.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Main training loop, train epoch 3.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 3.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 3.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 3.:  55%|█████▌    | 59/107 [01:12<00:59,  1.23s/it]Main training loop, train epoch 3.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 3.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 3.:  58%|█████▊    | 62/107 [01:15<00:55,  1.23s/it]Main training loop, train epoch 3.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Main training loop, train epoch 3.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Main training loop, train epoch 3.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Main training loop, train epoch 3.:  62%|██████▏   | 66/107 [01:20<00:50,  1.22s/it]Main training loop, train epoch 3.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Main training loop, train epoch 3.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Main training loop, train epoch 3.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Main training loop, train epoch 3.:  65%|██████▌   | 70/107 [01:25<00:45,  1.22s/it]Main training loop, train epoch 3.:  66%|██████▋   | 71/107 [01:26<00:44,  1.22s/it]Main training loop, train epoch 3.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 3.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 3.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 3.:  70%|███████   | 75/107 [01:31<00:39,  1.23s/it]Main training loop, train epoch 3.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 3.:  72%|███████▏  | 77/107 [01:34<00:37,  1.24s/it]Main training loop, train epoch 3.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Main training loop, train epoch 3.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Main training loop, train epoch 3.:  75%|███████▍  | 80/107 [01:37<00:32,  1.22s/it]Main training loop, train epoch 3.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 3.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Main training loop, train epoch 3.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 3.:  79%|███████▊  | 84/107 [01:42<00:28,  1.23s/it]Main training loop, train epoch 3.:  79%|███████▉  | 85/107 [01:44<00:26,  1.23s/it]Main training loop, train epoch 3.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Main training loop, train epoch 3.:  81%|████████▏ | 87/107 [01:46<00:24,  1.24s/it]Main training loop, train epoch 3.:  82%|████████▏ | 88/107 [01:47<00:23,  1.23s/it]Main training loop, train epoch 3.:  83%|████████▎ | 89/107 [01:49<00:22,  1.24s/it]Main training loop, train epoch 3.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 3.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 3.:  86%|████████▌ | 92/107 [01:52<00:18,  1.24s/it]Main training loop, train epoch 3.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Main training loop, train epoch 3.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Main training loop, train epoch 3.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 3.:  90%|████████▉ | 96/107 [01:57<00:13,  1.24s/it]Main training loop, train epoch 3.:  91%|█████████ | 97/107 [01:58<00:12,  1.24s/it]Main training loop, train epoch 3.:  92%|█████████▏| 98/107 [02:00<00:11,  1.24s/it]Main training loop, train epoch 3.:  93%|█████████▎| 99/107 [02:01<00:09,  1.24s/it]Main training loop, train epoch 3.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Main training loop, train epoch 3.:  94%|█████████▍| 101/107 [02:03<00:07,  1.23s/it]Main training loop, train epoch 3.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 3.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Main training loop, train epoch 3.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Main training loop, train epoch 3.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Main training loop, train epoch 3.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 3.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 3.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 07:54:27,428] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_3 is about to be saved!
[2025-06-25 07:54:27,503] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,503] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,503] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,503] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_3/mp_rank_00_model_states.pt
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_3/mp_rank_00_model_states.pt...
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,505] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,507] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,507] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,507] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,507] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,507] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,510] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,510] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,510] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,510] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,510] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,510] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,511] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:27,511] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
[2025-06-25 07:54:29,642] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_3/mp_rank_00_model_states.pt.
[2025-06-25 07:54:29,642] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_3 is ready now!
Testing on epoch 3.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 3.:   9%|▉         | 1/11 [00:00<00:06,  1.52it/s]Testing on epoch 3.:  18%|█▊        | 2/11 [00:01<00:05,  1.61it/s]Testing on epoch 3.:  27%|██▋       | 3/11 [00:01<00:05,  1.55it/s]Testing on epoch 3.:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s]Testing on epoch 3.:  45%|████▌     | 5/11 [00:03<00:03,  1.57it/s]Testing on epoch 3.:  55%|█████▍    | 6/11 [00:03<00:03,  1.56it/s]Testing on epoch 3.:  64%|██████▎   | 7/11 [00:04<00:02,  1.56it/s]Testing on epoch 3.:  73%|███████▎  | 8/11 [00:05<00:01,  1.61it/s]Testing on epoch 3.:  82%|████████▏ | 9/11 [00:05<00:01,  1.58it/s]Testing on epoch 3.:  91%|█████████ | 10/11 [00:06<00:00,  1.63it/s]Testing on epoch 3.: 100%|██████████| 11/11 [00:06<00:00,  1.67it/s]Testing on epoch 3.: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s]
Main training loop, train epoch 4.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 4.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Main training loop, train epoch 4.:   2%|▏         | 2/107 [00:02<02:12,  1.26s/it]Main training loop, train epoch 4.:   3%|▎         | 3/107 [00:03<02:11,  1.26s/it]Main training loop, train epoch 4.:   4%|▎         | 4/107 [00:05<02:08,  1.25s/it]Main training loop, train epoch 4.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Main training loop, train epoch 4.:   6%|▌         | 6/107 [00:07<02:04,  1.24s/it]Main training loop, train epoch 4.:   7%|▋         | 7/107 [00:08<02:03,  1.24s/it]Main training loop, train epoch 4.:   7%|▋         | 8/107 [00:09<02:02,  1.24s/it]Main training loop, train epoch 4.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 4.:   9%|▉         | 10/107 [00:12<01:59,  1.24s/it]Main training loop, train epoch 4.:  10%|█         | 11/107 [00:13<01:58,  1.23s/it]Main training loop, train epoch 4.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Main training loop, train epoch 4.:  12%|█▏        | 13/107 [00:16<01:55,  1.23s/it]Main training loop, train epoch 4.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 4.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Main training loop, train epoch 4.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Main training loop, train epoch 4.:  16%|█▌        | 17/107 [00:21<01:51,  1.23s/it]Main training loop, train epoch 4.:  17%|█▋        | 18/107 [00:22<01:50,  1.24s/it]Main training loop, train epoch 4.:  18%|█▊        | 19/107 [00:23<01:48,  1.24s/it]Main training loop, train epoch 4.:  19%|█▊        | 20/107 [00:24<01:47,  1.24s/it]Main training loop, train epoch 4.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 4.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Main training loop, train epoch 4.:  21%|██▏       | 23/107 [00:28<01:42,  1.23s/it]Main training loop, train epoch 4.:  22%|██▏       | 24/107 [00:29<01:41,  1.23s/it]Main training loop, train epoch 4.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 4.:  24%|██▍       | 26/107 [00:32<01:39,  1.23s/it]Main training loop, train epoch 4.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Main training loop, train epoch 4.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Main training loop, train epoch 4.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Main training loop, train epoch 4.:  28%|██▊       | 30/107 [00:36<01:34,  1.22s/it]Main training loop, train epoch 4.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Main training loop, train epoch 4.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 4.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Main training loop, train epoch 4.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Main training loop, train epoch 4.:  33%|███▎      | 35/107 [00:43<01:28,  1.22s/it]Main training loop, train epoch 4.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Main training loop, train epoch 4.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 4.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 4.:  36%|███▋      | 39/107 [00:48<01:23,  1.23s/it]Main training loop, train epoch 4.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Main training loop, train epoch 4.:  38%|███▊      | 41/107 [00:50<01:21,  1.24s/it]Main training loop, train epoch 4.:  39%|███▉      | 42/107 [00:51<01:20,  1.24s/it]Main training loop, train epoch 4.:  40%|████      | 43/107 [00:52<01:19,  1.24s/it]Main training loop, train epoch 4.:  41%|████      | 44/107 [00:54<01:18,  1.24s/it]Main training loop, train epoch 4.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 4.:  43%|████▎     | 46/107 [00:56<01:15,  1.23s/it]Main training loop, train epoch 4.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 4.:  45%|████▍     | 48/107 [00:59<01:12,  1.23s/it]Main training loop, train epoch 4.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Main training loop, train epoch 4.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Main training loop, train epoch 4.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 4.:  49%|████▊     | 52/107 [01:04<01:07,  1.23s/it]Main training loop, train epoch 4.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Main training loop, train epoch 4.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 4.:  51%|█████▏    | 55/107 [01:07<01:04,  1.23s/it]Main training loop, train epoch 4.:  52%|█████▏    | 56/107 [01:08<01:03,  1.24s/it]Main training loop, train epoch 4.:  53%|█████▎    | 57/107 [01:10<01:01,  1.24s/it]Main training loop, train epoch 4.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 4.:  55%|█████▌    | 59/107 [01:12<00:59,  1.23s/it]Main training loop, train epoch 4.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 4.:  57%|█████▋    | 61/107 [01:15<00:56,  1.22s/it]Main training loop, train epoch 4.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Main training loop, train epoch 4.:  59%|█████▉    | 63/107 [01:17<00:53,  1.23s/it]Main training loop, train epoch 4.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Main training loop, train epoch 4.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Main training loop, train epoch 4.:  62%|██████▏   | 66/107 [01:21<00:49,  1.22s/it]Main training loop, train epoch 4.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Main training loop, train epoch 4.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Main training loop, train epoch 4.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Main training loop, train epoch 4.:  65%|██████▌   | 70/107 [01:26<00:45,  1.22s/it]Main training loop, train epoch 4.:  66%|██████▋   | 71/107 [01:27<00:43,  1.22s/it]Main training loop, train epoch 4.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 4.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Main training loop, train epoch 4.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 4.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Main training loop, train epoch 4.:  71%|███████   | 76/107 [01:33<00:38,  1.24s/it]Main training loop, train epoch 4.:  72%|███████▏  | 77/107 [01:34<00:37,  1.24s/it]Main training loop, train epoch 4.:  73%|███████▎  | 78/107 [01:35<00:35,  1.24s/it]Main training loop, train epoch 4.:  74%|███████▍  | 79/107 [01:37<00:34,  1.24s/it]Main training loop, train epoch 4.:  75%|███████▍  | 80/107 [01:38<00:33,  1.24s/it]Main training loop, train epoch 4.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Main training loop, train epoch 4.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 4.:  78%|███████▊  | 83/107 [01:42<00:29,  1.22s/it]Main training loop, train epoch 4.:  79%|███████▊  | 84/107 [01:43<00:28,  1.22s/it]Main training loop, train epoch 4.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Main training loop, train epoch 4.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 4.:  81%|████████▏ | 87/107 [01:47<00:24,  1.24s/it]Main training loop, train epoch 4.:  82%|████████▏ | 88/107 [01:48<00:23,  1.24s/it]Main training loop, train epoch 4.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Main training loop, train epoch 4.:  84%|████████▍ | 90/107 [01:50<00:21,  1.24s/it]Main training loop, train epoch 4.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 4.:  86%|████████▌ | 92/107 [01:53<00:18,  1.23s/it]Main training loop, train epoch 4.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Main training loop, train epoch 4.:  88%|████████▊ | 94/107 [01:55<00:16,  1.24s/it]Main training loop, train epoch 4.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 4.:  90%|████████▉ | 96/107 [01:58<00:13,  1.23s/it]Main training loop, train epoch 4.:  91%|█████████ | 97/107 [01:59<00:12,  1.23s/it]Main training loop, train epoch 4.:  92%|█████████▏| 98/107 [02:00<00:11,  1.22s/it]Main training loop, train epoch 4.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 4.:  93%|█████████▎| 100/107 [02:03<00:08,  1.23s/it]Main training loop, train epoch 4.:  94%|█████████▍| 101/107 [02:04<00:07,  1.22s/it]Main training loop, train epoch 4.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 4.:  96%|█████████▋| 103/107 [02:06<00:04,  1.24s/it]Main training loop, train epoch 4.:  97%|█████████▋| 104/107 [02:07<00:03,  1.24s/it]Main training loop, train epoch 4.:  98%|█████████▊| 105/107 [02:09<00:02,  1.23s/it]Main training loop, train epoch 4.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 4.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 4.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 07:56:48,216] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_4 is about to be saved!
[2025-06-25 07:56:48,247] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,247] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,247] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,247] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,249] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_4/mp_rank_00_model_states.pt
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_4/mp_rank_00_model_states.pt...
[2025-06-25 07:56:48,249] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,249] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,249] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,249] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,250] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,252] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,252] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,251] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:48,252] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
[2025-06-25 07:56:50,374] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_4/mp_rank_00_model_states.pt.
[2025-06-25 07:56:50,375] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_4 is ready now!
Main training loop, train epoch 5.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 5.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Main training loop, train epoch 5.:   2%|▏         | 2/107 [00:02<02:10,  1.25s/it]Main training loop, train epoch 5.:   3%|▎         | 3/107 [00:03<02:08,  1.23s/it]Main training loop, train epoch 5.:   4%|▎         | 4/107 [00:04<02:07,  1.23s/it]Main training loop, train epoch 5.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 5.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Main training loop, train epoch 5.:   7%|▋         | 7/107 [00:08<02:01,  1.22s/it]Main training loop, train epoch 5.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Main training loop, train epoch 5.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 5.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Main training loop, train epoch 5.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Main training loop, train epoch 5.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Main training loop, train epoch 5.:  12%|█▏        | 13/107 [00:15<01:55,  1.22s/it]Main training loop, train epoch 5.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 5.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Main training loop, train epoch 5.:  15%|█▍        | 16/107 [00:19<01:51,  1.22s/it]Main training loop, train epoch 5.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Main training loop, train epoch 5.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Main training loop, train epoch 5.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Main training loop, train epoch 5.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Main training loop, train epoch 5.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 5.:  21%|██        | 22/107 [00:26<01:44,  1.23s/it]Main training loop, train epoch 5.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 5.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 5.:  23%|██▎       | 25/107 [00:30<01:40,  1.22s/it]Main training loop, train epoch 5.:  24%|██▍       | 26/107 [00:31<01:39,  1.22s/it]Main training loop, train epoch 5.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Main training loop, train epoch 5.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Main training loop, train epoch 5.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Main training loop, train epoch 5.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 5.:  29%|██▉       | 31/107 [00:37<01:33,  1.23s/it]Main training loop, train epoch 5.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 5.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Main training loop, train epoch 5.:  32%|███▏      | 34/107 [00:41<01:29,  1.22s/it]Main training loop, train epoch 5.:  33%|███▎      | 35/107 [00:42<01:27,  1.22s/it]Main training loop, train epoch 5.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Main training loop, train epoch 5.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 5.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 5.:  36%|███▋      | 39/107 [00:47<01:22,  1.22s/it]Main training loop, train epoch 5.:  37%|███▋      | 40/107 [00:48<01:21,  1.22s/it]Main training loop, train epoch 5.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Main training loop, train epoch 5.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Main training loop, train epoch 5.:  40%|████      | 43/107 [00:52<01:18,  1.22s/it]Main training loop, train epoch 5.:  41%|████      | 44/107 [00:53<01:17,  1.23s/it]Main training loop, train epoch 5.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Main training loop, train epoch 5.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 5.:  44%|████▍     | 47/107 [00:57<01:13,  1.22s/it]Main training loop, train epoch 5.:  45%|████▍     | 48/107 [00:58<01:11,  1.22s/it]Main training loop, train epoch 5.:  46%|████▌     | 49/107 [00:59<01:11,  1.22s/it]Main training loop, train epoch 5.:  47%|████▋     | 50/107 [01:01<01:09,  1.23s/it]Main training loop, train epoch 5.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Main training loop, train epoch 5.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 5.:  50%|████▉     | 53/107 [01:04<01:06,  1.23s/it]Main training loop, train epoch 5.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Main training loop, train epoch 5.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Main training loop, train epoch 5.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Main training loop, train epoch 5.:  53%|█████▎    | 57/107 [01:09<01:00,  1.22s/it]Main training loop, train epoch 5.:  54%|█████▍    | 58/107 [01:10<00:59,  1.22s/it]Main training loop, train epoch 5.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 5.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Main training loop, train epoch 5.:  57%|█████▋    | 61/107 [01:14<00:56,  1.22s/it]Main training loop, train epoch 5.:  58%|█████▊    | 62/107 [01:15<00:54,  1.22s/it]Main training loop, train epoch 5.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Main training loop, train epoch 5.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Main training loop, train epoch 5.:  61%|██████    | 65/107 [01:19<00:51,  1.21s/it]Main training loop, train epoch 5.:  62%|██████▏   | 66/107 [01:20<00:49,  1.22s/it]Main training loop, train epoch 5.:  63%|██████▎   | 67/107 [01:21<00:48,  1.22s/it]Main training loop, train epoch 5.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Main training loop, train epoch 5.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Main training loop, train epoch 5.:  65%|██████▌   | 70/107 [01:25<00:45,  1.22s/it]Main training loop, train epoch 5.:  66%|██████▋   | 71/107 [01:26<00:44,  1.22s/it]Main training loop, train epoch 5.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 5.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 5.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 5.:  70%|███████   | 75/107 [01:31<00:39,  1.23s/it]Main training loop, train epoch 5.:  71%|███████   | 76/107 [01:32<00:37,  1.22s/it]Main training loop, train epoch 5.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 5.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Main training loop, train epoch 5.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Main training loop, train epoch 5.:  75%|███████▍  | 80/107 [01:37<00:33,  1.23s/it]Main training loop, train epoch 5.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Main training loop, train epoch 5.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Main training loop, train epoch 5.:  78%|███████▊  | 83/107 [01:41<00:29,  1.22s/it]Main training loop, train epoch 5.:  79%|███████▊  | 84/107 [01:42<00:27,  1.22s/it]Main training loop, train epoch 5.:  79%|███████▉  | 85/107 [01:43<00:27,  1.23s/it]Main training loop, train epoch 5.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 5.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 5.:  82%|████████▏ | 88/107 [01:47<00:23,  1.24s/it]Main training loop, train epoch 5.:  83%|████████▎ | 89/107 [01:48<00:22,  1.24s/it]Main training loop, train epoch 5.:  84%|████████▍ | 90/107 [01:50<00:21,  1.25s/it]Main training loop, train epoch 5.:  85%|████████▌ | 91/107 [01:51<00:19,  1.24s/it]Main training loop, train epoch 5.:  86%|████████▌ | 92/107 [01:52<00:18,  1.24s/it]Main training loop, train epoch 5.:  87%|████████▋ | 93/107 [01:54<00:17,  1.28s/it]Main training loop, train epoch 5.:  88%|████████▊ | 94/107 [01:55<00:17,  1.32s/it]Main training loop, train epoch 5.:  89%|████████▉ | 95/107 [01:56<00:16,  1.34s/it]Main training loop, train epoch 5.:  90%|████████▉ | 96/107 [01:58<00:14,  1.34s/it]Main training loop, train epoch 5.:  91%|█████████ | 97/107 [01:59<00:13,  1.31s/it]Main training loop, train epoch 5.:  92%|█████████▏| 98/107 [02:00<00:11,  1.28s/it]Main training loop, train epoch 5.:  93%|█████████▎| 99/107 [02:01<00:10,  1.26s/it]Main training loop, train epoch 5.:  93%|█████████▎| 100/107 [02:03<00:08,  1.25s/it]Main training loop, train epoch 5.:  94%|█████████▍| 101/107 [02:04<00:07,  1.25s/it]Main training loop, train epoch 5.:  95%|█████████▌| 102/107 [02:05<00:06,  1.24s/it]Main training loop, train epoch 5.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 5.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Main training loop, train epoch 5.:  98%|█████████▊| 105/107 [02:09<00:02,  1.23s/it]Main training loop, train epoch 5.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 5.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 5.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 07:59:02,080] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_5 is about to be saved!
[2025-06-25 07:59:02,104] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_5/mp_rank_00_model_states.pt
[2025-06-25 07:59:02,104] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_5/mp_rank_00_model_states.pt...
[2025-06-25 07:59:02,104] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,104] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,104] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,105] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,105] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,105] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,105] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,105] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,105] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,105] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,105] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,107] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,107] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,107] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,107] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,108] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,108] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,108] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,108] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,109] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,109] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,109] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,109] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,109] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,109] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,109] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,109] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,111] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,111] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,111] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,111] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,112] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,113] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,113] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,113] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,113] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,113] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,113] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:02,113] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
[2025-06-25 07:59:04,257] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_5/mp_rank_00_model_states.pt.
[2025-06-25 07:59:04,258] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_5 is ready now!
Testing on epoch 5.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 5.:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s]Testing on epoch 5.:  18%|█▊        | 2/11 [00:01<00:06,  1.47it/s]Testing on epoch 5.:  27%|██▋       | 3/11 [00:02<00:05,  1.48it/s]Testing on epoch 5.:  36%|███▋      | 4/11 [00:02<00:04,  1.55it/s]Testing on epoch 5.:  45%|████▌     | 5/11 [00:03<00:03,  1.59it/s]Testing on epoch 5.:  55%|█████▍    | 6/11 [00:03<00:03,  1.65it/s]Testing on epoch 5.:  64%|██████▎   | 7/11 [00:04<00:02,  1.69it/s]Testing on epoch 5.:  73%|███████▎  | 8/11 [00:04<00:01,  1.71it/s]Testing on epoch 5.:  82%|████████▏ | 9/11 [00:05<00:01,  1.73it/s]Testing on epoch 5.:  91%|█████████ | 10/11 [00:06<00:00,  1.64it/s]Testing on epoch 5.: 100%|██████████| 11/11 [00:06<00:00,  1.57it/s]Testing on epoch 5.: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s]
Main training loop, train epoch 6.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 6.:   1%|          | 1/107 [00:01<02:10,  1.23s/it]Main training loop, train epoch 6.:   2%|▏         | 2/107 [00:02<02:08,  1.23s/it]Main training loop, train epoch 6.:   3%|▎         | 3/107 [00:03<02:06,  1.22s/it]Main training loop, train epoch 6.:   4%|▎         | 4/107 [00:04<02:04,  1.21s/it]Main training loop, train epoch 6.:   5%|▍         | 5/107 [00:06<02:04,  1.22s/it]Main training loop, train epoch 6.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Main training loop, train epoch 6.:   7%|▋         | 7/107 [00:08<02:02,  1.22s/it]Main training loop, train epoch 6.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Main training loop, train epoch 6.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 6.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Main training loop, train epoch 6.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Main training loop, train epoch 6.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Main training loop, train epoch 6.:  12%|█▏        | 13/107 [00:15<01:55,  1.23s/it]Main training loop, train epoch 6.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 6.:  14%|█▍        | 15/107 [00:18<01:52,  1.23s/it]Main training loop, train epoch 6.:  15%|█▍        | 16/107 [00:19<01:51,  1.23s/it]Main training loop, train epoch 6.:  16%|█▌        | 17/107 [00:20<01:50,  1.22s/it]Main training loop, train epoch 6.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 6.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Main training loop, train epoch 6.:  19%|█▊        | 20/107 [00:24<01:47,  1.24s/it]Main training loop, train epoch 6.:  20%|█▉        | 21/107 [00:25<01:46,  1.24s/it]Main training loop, train epoch 6.:  21%|██        | 22/107 [00:27<01:45,  1.24s/it]Main training loop, train epoch 6.:  21%|██▏       | 23/107 [00:28<01:44,  1.24s/it]Main training loop, train epoch 6.:  22%|██▏       | 24/107 [00:29<01:42,  1.24s/it]Main training loop, train epoch 6.:  23%|██▎       | 25/107 [00:30<01:41,  1.24s/it]Main training loop, train epoch 6.:  24%|██▍       | 26/107 [00:31<01:40,  1.24s/it]Main training loop, train epoch 6.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 6.:  26%|██▌       | 28/107 [00:34<01:37,  1.24s/it]Main training loop, train epoch 6.:  27%|██▋       | 29/107 [00:35<01:36,  1.24s/it]Main training loop, train epoch 6.:  28%|██▊       | 30/107 [00:36<01:35,  1.24s/it]Main training loop, train epoch 6.:  29%|██▉       | 31/107 [00:38<01:34,  1.24s/it]Main training loop, train epoch 6.:  30%|██▉       | 32/107 [00:39<01:32,  1.24s/it]Main training loop, train epoch 6.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Main training loop, train epoch 6.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Main training loop, train epoch 6.:  33%|███▎      | 35/107 [00:43<01:28,  1.23s/it]Main training loop, train epoch 6.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 6.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 6.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 6.:  36%|███▋      | 39/107 [00:47<01:23,  1.22s/it]Main training loop, train epoch 6.:  37%|███▋      | 40/107 [00:49<01:22,  1.22s/it]Main training loop, train epoch 6.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Main training loop, train epoch 6.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Main training loop, train epoch 6.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 6.:  41%|████      | 44/107 [00:54<01:17,  1.23s/it]Main training loop, train epoch 6.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 6.:  43%|████▎     | 46/107 [00:56<01:15,  1.23s/it]Main training loop, train epoch 6.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 6.:  45%|████▍     | 48/107 [00:59<01:12,  1.23s/it]Main training loop, train epoch 6.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Main training loop, train epoch 6.:  47%|████▋     | 50/107 [01:01<01:10,  1.24s/it]Main training loop, train epoch 6.:  48%|████▊     | 51/107 [01:02<01:09,  1.24s/it]Main training loop, train epoch 6.:  49%|████▊     | 52/107 [01:04<01:08,  1.24s/it]Main training loop, train epoch 6.:  50%|████▉     | 53/107 [01:05<01:07,  1.24s/it]Main training loop, train epoch 6.:  50%|█████     | 54/107 [01:06<01:05,  1.24s/it]Main training loop, train epoch 6.:  51%|█████▏    | 55/107 [01:07<01:04,  1.24s/it]Main training loop, train epoch 6.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 6.:  53%|█████▎    | 57/107 [01:10<01:01,  1.23s/it]Main training loop, train epoch 6.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Main training loop, train epoch 6.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 6.:  56%|█████▌    | 60/107 [01:13<00:58,  1.24s/it]Main training loop, train epoch 6.:  57%|█████▋    | 61/107 [01:15<00:56,  1.23s/it]Main training loop, train epoch 6.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Main training loop, train epoch 6.:  59%|█████▉    | 63/107 [01:17<00:54,  1.24s/it]Main training loop, train epoch 6.:  60%|█████▉    | 64/107 [01:18<00:53,  1.24s/it]Main training loop, train epoch 6.:  61%|██████    | 65/107 [01:20<00:52,  1.24s/it]Main training loop, train epoch 6.:  62%|██████▏   | 66/107 [01:21<00:50,  1.24s/it]Main training loop, train epoch 6.:  63%|██████▎   | 67/107 [01:22<00:49,  1.24s/it]Main training loop, train epoch 6.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Main training loop, train epoch 6.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 6.:  65%|██████▌   | 70/107 [01:26<00:45,  1.23s/it]Main training loop, train epoch 6.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 6.:  67%|██████▋   | 72/107 [01:28<00:42,  1.23s/it]Main training loop, train epoch 6.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 6.:  69%|██████▉   | 74/107 [01:31<00:40,  1.22s/it]Main training loop, train epoch 6.:  70%|███████   | 75/107 [01:32<00:39,  1.22s/it]Main training loop, train epoch 6.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 6.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 6.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Main training loop, train epoch 6.:  74%|███████▍  | 79/107 [01:37<00:34,  1.22s/it]Main training loop, train epoch 6.:  75%|███████▍  | 80/107 [01:38<00:32,  1.22s/it]Main training loop, train epoch 6.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 6.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Main training loop, train epoch 6.:  78%|███████▊  | 83/107 [01:42<00:29,  1.22s/it]Main training loop, train epoch 6.:  79%|███████▊  | 84/107 [01:43<00:28,  1.22s/it]Main training loop, train epoch 6.:  79%|███████▉  | 85/107 [01:44<00:26,  1.23s/it]Main training loop, train epoch 6.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 6.:  81%|████████▏ | 87/107 [01:47<00:24,  1.23s/it]Main training loop, train epoch 6.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Main training loop, train epoch 6.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Main training loop, train epoch 6.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 6.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 6.:  86%|████████▌ | 92/107 [01:53<00:18,  1.23s/it]Main training loop, train epoch 6.:  87%|████████▋ | 93/107 [01:54<00:17,  1.24s/it]Main training loop, train epoch 6.:  88%|████████▊ | 94/107 [01:55<00:16,  1.23s/it]Main training loop, train epoch 6.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 6.:  90%|████████▉ | 96/107 [01:58<00:13,  1.24s/it]Main training loop, train epoch 6.:  91%|█████████ | 97/107 [01:59<00:12,  1.24s/it]Main training loop, train epoch 6.:  92%|█████████▏| 98/107 [02:00<00:11,  1.24s/it]Main training loop, train epoch 6.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 6.:  93%|█████████▎| 100/107 [02:03<00:08,  1.23s/it]Main training loop, train epoch 6.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Main training loop, train epoch 6.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 6.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Main training loop, train epoch 6.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 6.:  98%|█████████▊| 105/107 [02:09<00:02,  1.22s/it]Main training loop, train epoch 6.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Main training loop, train epoch 6.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 6.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:01:22,768] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_6 is about to be saved!
[2025-06-25 08:01:22,799] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,799] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,799] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,799] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,801] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,801] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,801] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,801] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,801] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,801] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,802] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_6/mp_rank_00_model_states.pt
[2025-06-25 08:01:22,802] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_6/mp_rank_00_model_states.pt...
[2025-06-25 08:01:22,801] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,801] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,804] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:22,804] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
[2025-06-25 08:01:24,920] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_6/mp_rank_00_model_states.pt.
[2025-06-25 08:01:24,920] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_6 is ready now!
Main training loop, train epoch 7.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 7.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Main training loop, train epoch 7.:   2%|▏         | 2/107 [00:02<02:09,  1.23s/it]Main training loop, train epoch 7.:   3%|▎         | 3/107 [00:03<02:07,  1.23s/it]Main training loop, train epoch 7.:   4%|▎         | 4/107 [00:04<02:08,  1.24s/it]Main training loop, train epoch 7.:   5%|▍         | 5/107 [00:06<02:07,  1.25s/it]Main training loop, train epoch 7.:   6%|▌         | 6/107 [00:07<02:05,  1.24s/it]Main training loop, train epoch 7.:   7%|▋         | 7/107 [00:08<02:03,  1.23s/it]Main training loop, train epoch 7.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Main training loop, train epoch 7.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 7.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Main training loop, train epoch 7.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Main training loop, train epoch 7.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Main training loop, train epoch 7.:  12%|█▏        | 13/107 [00:15<01:55,  1.23s/it]Main training loop, train epoch 7.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 7.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Main training loop, train epoch 7.:  15%|█▍        | 16/107 [00:19<01:51,  1.22s/it]Main training loop, train epoch 7.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Main training loop, train epoch 7.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 7.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Main training loop, train epoch 7.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Main training loop, train epoch 7.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 7.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Main training loop, train epoch 7.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 7.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 7.:  23%|██▎       | 25/107 [00:30<01:40,  1.22s/it]Main training loop, train epoch 7.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 7.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 7.:  26%|██▌       | 28/107 [00:34<01:36,  1.23s/it]Main training loop, train epoch 7.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Main training loop, train epoch 7.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 7.:  29%|██▉       | 31/107 [00:38<01:33,  1.22s/it]Main training loop, train epoch 7.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Main training loop, train epoch 7.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Main training loop, train epoch 7.:  32%|███▏      | 34/107 [00:41<01:29,  1.22s/it]Main training loop, train epoch 7.:  33%|███▎      | 35/107 [00:42<01:27,  1.22s/it]Main training loop, train epoch 7.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Main training loop, train epoch 7.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 7.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 7.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Main training loop, train epoch 7.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Main training loop, train epoch 7.:  38%|███▊      | 41/107 [00:50<01:21,  1.24s/it]Main training loop, train epoch 7.:  39%|███▉      | 42/107 [00:51<01:20,  1.23s/it]Main training loop, train epoch 7.:  40%|████      | 43/107 [00:52<01:19,  1.24s/it]Main training loop, train epoch 7.:  41%|████      | 44/107 [00:54<01:17,  1.24s/it]Main training loop, train epoch 7.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 7.:  43%|████▎     | 46/107 [00:56<01:15,  1.23s/it]Main training loop, train epoch 7.:  44%|████▍     | 47/107 [00:57<01:14,  1.24s/it]Main training loop, train epoch 7.:  45%|████▍     | 48/107 [00:59<01:13,  1.24s/it]Main training loop, train epoch 7.:  46%|████▌     | 49/107 [01:00<01:11,  1.24s/it]Main training loop, train epoch 7.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Main training loop, train epoch 7.:  48%|████▊     | 51/107 [01:02<01:09,  1.23s/it]Main training loop, train epoch 7.:  49%|████▊     | 52/107 [01:03<01:07,  1.23s/it]Main training loop, train epoch 7.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Main training loop, train epoch 7.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 7.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Main training loop, train epoch 7.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 7.:  53%|█████▎    | 57/107 [01:10<01:01,  1.23s/it]Main training loop, train epoch 7.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 7.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 7.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 7.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 7.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Main training loop, train epoch 7.:  59%|█████▉    | 63/107 [01:17<00:54,  1.24s/it]Main training loop, train epoch 7.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Main training loop, train epoch 7.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Main training loop, train epoch 7.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Main training loop, train epoch 7.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Main training loop, train epoch 7.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Main training loop, train epoch 7.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Main training loop, train epoch 7.:  65%|██████▌   | 70/107 [01:26<00:45,  1.22s/it]Main training loop, train epoch 7.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 7.:  67%|██████▋   | 72/107 [01:28<00:42,  1.23s/it]Main training loop, train epoch 7.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 7.:  69%|██████▉   | 74/107 [01:30<00:40,  1.24s/it]Main training loop, train epoch 7.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Main training loop, train epoch 7.:  71%|███████   | 76/107 [01:33<00:37,  1.23s/it]Main training loop, train epoch 7.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Main training loop, train epoch 7.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 7.:  74%|███████▍  | 79/107 [01:37<00:34,  1.22s/it]Main training loop, train epoch 7.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Main training loop, train epoch 7.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Main training loop, train epoch 7.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 7.:  78%|███████▊  | 83/107 [01:42<00:29,  1.23s/it]Main training loop, train epoch 7.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 7.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Main training loop, train epoch 7.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 7.:  81%|████████▏ | 87/107 [01:46<00:24,  1.24s/it]Main training loop, train epoch 7.:  82%|████████▏ | 88/107 [01:48<00:23,  1.24s/it]Main training loop, train epoch 7.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Main training loop, train epoch 7.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 7.:  85%|████████▌ | 91/107 [01:51<00:19,  1.22s/it]Main training loop, train epoch 7.:  86%|████████▌ | 92/107 [01:53<00:18,  1.22s/it]Main training loop, train epoch 7.:  87%|████████▋ | 93/107 [01:54<00:16,  1.21s/it]Main training loop, train epoch 7.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Main training loop, train epoch 7.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Main training loop, train epoch 7.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Main training loop, train epoch 7.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Main training loop, train epoch 7.:  92%|█████████▏| 98/107 [02:00<00:10,  1.22s/it]Main training loop, train epoch 7.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Main training loop, train epoch 7.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 7.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Main training loop, train epoch 7.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 7.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 7.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 7.:  98%|█████████▊| 105/107 [02:08<00:02,  1.22s/it]Main training loop, train epoch 7.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Main training loop, train epoch 7.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 7.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:03:36,357] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_7 is about to be saved!
[2025-06-25 08:03:36,388] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,388] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,388] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,388] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_7/mp_rank_00_model_states.pt
[2025-06-25 08:03:36,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_7/mp_rank_00_model_states.pt...
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,390] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,392] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,392] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,392] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:36,391] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
[2025-06-25 08:03:38,511] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_7/mp_rank_00_model_states.pt.
[2025-06-25 08:03:38,512] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_7 is ready now!
Testing on epoch 7.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 7.:   9%|▉         | 1/11 [00:00<00:06,  1.49it/s]Testing on epoch 7.:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s]Testing on epoch 7.:  27%|██▋       | 3/11 [00:01<00:05,  1.60it/s]Testing on epoch 7.:  36%|███▋      | 4/11 [00:02<00:04,  1.60it/s]Testing on epoch 7.:  45%|████▌     | 5/11 [00:03<00:03,  1.62it/s]Testing on epoch 7.:  55%|█████▍    | 6/11 [00:03<00:03,  1.60it/s]Testing on epoch 7.:  64%|██████▎   | 7/11 [00:04<00:02,  1.62it/s]Testing on epoch 7.:  73%|███████▎  | 8/11 [00:04<00:01,  1.65it/s]Testing on epoch 7.:  82%|████████▏ | 9/11 [00:05<00:01,  1.62it/s]Testing on epoch 7.:  91%|█████████ | 10/11 [00:06<00:00,  1.63it/s]Testing on epoch 7.: 100%|██████████| 11/11 [00:06<00:00,  1.64it/s]Testing on epoch 7.: 100%|██████████| 11/11 [00:06<00:00,  1.62it/s]
Main training loop, train epoch 8.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 8.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Main training loop, train epoch 8.:   2%|▏         | 2/107 [00:02<02:11,  1.25s/it]Main training loop, train epoch 8.:   3%|▎         | 3/107 [00:03<02:08,  1.24s/it]Main training loop, train epoch 8.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Main training loop, train epoch 8.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Main training loop, train epoch 8.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Main training loop, train epoch 8.:   7%|▋         | 7/107 [00:08<02:03,  1.23s/it]Main training loop, train epoch 8.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Main training loop, train epoch 8.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Main training loop, train epoch 8.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Main training loop, train epoch 8.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Main training loop, train epoch 8.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Main training loop, train epoch 8.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Main training loop, train epoch 8.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 8.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Main training loop, train epoch 8.:  15%|█▍        | 16/107 [00:19<01:50,  1.22s/it]Main training loop, train epoch 8.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Main training loop, train epoch 8.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Main training loop, train epoch 8.:  18%|█▊        | 19/107 [00:23<01:46,  1.22s/it]Main training loop, train epoch 8.:  19%|█▊        | 20/107 [00:24<01:45,  1.22s/it]Main training loop, train epoch 8.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 8.:  21%|██        | 22/107 [00:26<01:43,  1.22s/it]Main training loop, train epoch 8.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 8.:  22%|██▏       | 24/107 [00:29<01:40,  1.21s/it]Main training loop, train epoch 8.:  23%|██▎       | 25/107 [00:30<01:39,  1.22s/it]Main training loop, train epoch 8.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 8.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 8.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Main training loop, train epoch 8.:  27%|██▋       | 29/107 [00:35<01:36,  1.24s/it]Main training loop, train epoch 8.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 8.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Main training loop, train epoch 8.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 8.:  31%|███       | 33/107 [00:40<01:30,  1.22s/it]Main training loop, train epoch 8.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Main training loop, train epoch 8.:  33%|███▎      | 35/107 [00:42<01:28,  1.23s/it]Main training loop, train epoch 8.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 8.:  35%|███▍      | 37/107 [00:45<01:27,  1.25s/it]Main training loop, train epoch 8.:  36%|███▌      | 38/107 [00:46<01:25,  1.24s/it]Main training loop, train epoch 8.:  36%|███▋      | 39/107 [00:47<01:24,  1.24s/it]Main training loop, train epoch 8.:  37%|███▋      | 40/107 [00:49<01:22,  1.24s/it]Main training loop, train epoch 8.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Main training loop, train epoch 8.:  39%|███▉      | 42/107 [00:51<01:19,  1.23s/it]Main training loop, train epoch 8.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 8.:  41%|████      | 44/107 [00:54<01:17,  1.23s/it]Main training loop, train epoch 8.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Main training loop, train epoch 8.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 8.:  44%|████▍     | 47/107 [00:57<01:13,  1.22s/it]Main training loop, train epoch 8.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Main training loop, train epoch 8.:  46%|████▌     | 49/107 [01:00<01:10,  1.22s/it]Main training loop, train epoch 8.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Main training loop, train epoch 8.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 8.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 8.:  50%|████▉     | 53/107 [01:05<01:06,  1.24s/it]Main training loop, train epoch 8.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 8.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Main training loop, train epoch 8.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 8.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 8.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 8.:  55%|█████▌    | 59/107 [01:12<00:59,  1.23s/it]Main training loop, train epoch 8.:  56%|█████▌    | 60/107 [01:13<00:58,  1.23s/it]Main training loop, train epoch 8.:  57%|█████▋    | 61/107 [01:14<00:56,  1.24s/it]Main training loop, train epoch 8.:  58%|█████▊    | 62/107 [01:16<00:55,  1.24s/it]Main training loop, train epoch 8.:  59%|█████▉    | 63/107 [01:17<00:54,  1.24s/it]Main training loop, train epoch 8.:  60%|█████▉    | 64/107 [01:18<00:53,  1.24s/it]Main training loop, train epoch 8.:  61%|██████    | 65/107 [01:19<00:52,  1.24s/it]Main training loop, train epoch 8.:  62%|██████▏   | 66/107 [01:21<00:51,  1.25s/it]Main training loop, train epoch 8.:  63%|██████▎   | 67/107 [01:22<00:49,  1.24s/it]Main training loop, train epoch 8.:  64%|██████▎   | 68/107 [01:23<00:48,  1.23s/it]Main training loop, train epoch 8.:  64%|██████▍   | 69/107 [01:24<00:47,  1.24s/it]Main training loop, train epoch 8.:  65%|██████▌   | 70/107 [01:26<00:45,  1.23s/it]Main training loop, train epoch 8.:  66%|██████▋   | 71/107 [01:27<00:44,  1.24s/it]Main training loop, train epoch 8.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Main training loop, train epoch 8.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Main training loop, train epoch 8.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Main training loop, train epoch 8.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Main training loop, train epoch 8.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 8.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 8.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Main training loop, train epoch 8.:  74%|███████▍  | 79/107 [01:37<00:34,  1.22s/it]Main training loop, train epoch 8.:  75%|███████▍  | 80/107 [01:38<00:32,  1.22s/it]Main training loop, train epoch 8.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 8.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 8.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 8.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 8.:  79%|███████▉  | 85/107 [01:44<00:27,  1.23s/it]Main training loop, train epoch 8.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 8.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 8.:  82%|████████▏ | 88/107 [01:48<00:23,  1.24s/it]Main training loop, train epoch 8.:  83%|████████▎ | 89/107 [01:49<00:22,  1.24s/it]Main training loop, train epoch 8.:  84%|████████▍ | 90/107 [01:50<00:21,  1.24s/it]Main training loop, train epoch 8.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 8.:  86%|████████▌ | 92/107 [01:53<00:18,  1.24s/it]Main training loop, train epoch 8.:  87%|████████▋ | 93/107 [01:54<00:17,  1.24s/it]Main training loop, train epoch 8.:  88%|████████▊ | 94/107 [01:55<00:16,  1.23s/it]Main training loop, train epoch 8.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 8.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Main training loop, train epoch 8.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Main training loop, train epoch 8.:  92%|█████████▏| 98/107 [02:00<00:10,  1.22s/it]Main training loop, train epoch 8.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Main training loop, train epoch 8.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Main training loop, train epoch 8.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Main training loop, train epoch 8.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 8.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 8.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 8.:  98%|█████████▊| 105/107 [02:09<00:02,  1.23s/it]Main training loop, train epoch 8.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 8.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 8.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:05:56,920] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_8 is about to be saved!
[2025-06-25 08:05:56,930] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_8/mp_rank_00_model_states.pt
[2025-06-25 08:05:56,930] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_8/mp_rank_00_model_states.pt...
[2025-06-25 08:05:56,930] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,930] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,930] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,931] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,932] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,932] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,932] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,932] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,932] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,932] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,932] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,933] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,933] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,933] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,934] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:56,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
[2025-06-25 08:05:59,081] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_8/mp_rank_00_model_states.pt.
[2025-06-25 08:05:59,081] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_8 is ready now!
Main training loop, train epoch 9.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 9.:   1%|          | 1/107 [00:01<02:12,  1.25s/it]Main training loop, train epoch 9.:   2%|▏         | 2/107 [00:02<02:10,  1.24s/it]Main training loop, train epoch 9.:   3%|▎         | 3/107 [00:03<02:09,  1.25s/it]Main training loop, train epoch 9.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Main training loop, train epoch 9.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 9.:   6%|▌         | 6/107 [00:07<02:03,  1.23s/it]Main training loop, train epoch 9.:   7%|▋         | 7/107 [00:08<02:02,  1.23s/it]Main training loop, train epoch 9.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Main training loop, train epoch 9.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 9.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Main training loop, train epoch 9.:  10%|█         | 11/107 [00:13<01:58,  1.23s/it]Main training loop, train epoch 9.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Main training loop, train epoch 9.:  12%|█▏        | 13/107 [00:16<01:55,  1.23s/it]Main training loop, train epoch 9.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 9.:  14%|█▍        | 15/107 [00:18<01:53,  1.24s/it]Main training loop, train epoch 9.:  15%|█▍        | 16/107 [00:19<01:52,  1.24s/it]Main training loop, train epoch 9.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Main training loop, train epoch 9.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 9.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Main training loop, train epoch 9.:  19%|█▊        | 20/107 [00:24<01:47,  1.24s/it]Main training loop, train epoch 9.:  20%|█▉        | 21/107 [00:25<01:46,  1.24s/it]Main training loop, train epoch 9.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Main training loop, train epoch 9.:  21%|██▏       | 23/107 [00:28<01:43,  1.23s/it]Main training loop, train epoch 9.:  22%|██▏       | 24/107 [00:29<01:41,  1.23s/it]Main training loop, train epoch 9.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 9.:  24%|██▍       | 26/107 [00:32<01:39,  1.23s/it]Main training loop, train epoch 9.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 9.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Main training loop, train epoch 9.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Main training loop, train epoch 9.:  28%|██▊       | 30/107 [00:36<01:33,  1.22s/it]Main training loop, train epoch 9.:  29%|██▉       | 31/107 [00:38<01:32,  1.22s/it]Main training loop, train epoch 9.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Main training loop, train epoch 9.:  31%|███       | 33/107 [00:40<01:30,  1.22s/it]Main training loop, train epoch 9.:  32%|███▏      | 34/107 [00:41<01:28,  1.22s/it]Main training loop, train epoch 9.:  33%|███▎      | 35/107 [00:43<01:27,  1.22s/it]Main training loop, train epoch 9.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Main training loop, train epoch 9.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 9.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 9.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Main training loop, train epoch 9.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Main training loop, train epoch 9.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Main training loop, train epoch 9.:  39%|███▉      | 42/107 [00:51<01:19,  1.23s/it]Main training loop, train epoch 9.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 9.:  41%|████      | 44/107 [00:54<01:17,  1.24s/it]Main training loop, train epoch 9.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 9.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 9.:  44%|████▍     | 47/107 [00:57<01:13,  1.22s/it]Main training loop, train epoch 9.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Main training loop, train epoch 9.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Main training loop, train epoch 9.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Main training loop, train epoch 9.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 9.:  49%|████▊     | 52/107 [01:03<01:07,  1.23s/it]Main training loop, train epoch 9.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Main training loop, train epoch 9.:  50%|█████     | 54/107 [01:06<01:04,  1.23s/it]Main training loop, train epoch 9.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Main training loop, train epoch 9.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 9.:  53%|█████▎    | 57/107 [01:10<01:01,  1.22s/it]Main training loop, train epoch 9.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Main training loop, train epoch 9.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 9.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 9.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 9.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Main training loop, train epoch 9.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Main training loop, train epoch 9.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Main training loop, train epoch 9.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Main training loop, train epoch 9.:  62%|██████▏   | 66/107 [01:21<00:49,  1.22s/it]Main training loop, train epoch 9.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Main training loop, train epoch 9.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Main training loop, train epoch 9.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 9.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Main training loop, train epoch 9.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 9.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 9.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 9.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 9.:  70%|███████   | 75/107 [01:32<00:39,  1.22s/it]Main training loop, train epoch 9.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 9.:  72%|███████▏  | 77/107 [01:34<00:37,  1.24s/it]Main training loop, train epoch 9.:  73%|███████▎  | 78/107 [01:35<00:35,  1.24s/it]Main training loop, train epoch 9.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Main training loop, train epoch 9.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Main training loop, train epoch 9.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Main training loop, train epoch 9.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Main training loop, train epoch 9.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 9.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 9.:  79%|███████▉  | 85/107 [01:44<00:27,  1.23s/it]Main training loop, train epoch 9.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 9.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 9.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Main training loop, train epoch 9.:  83%|████████▎ | 89/107 [01:49<00:22,  1.22s/it]Main training loop, train epoch 9.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 9.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 9.:  86%|████████▌ | 92/107 [01:52<00:18,  1.22s/it]Main training loop, train epoch 9.:  87%|████████▋ | 93/107 [01:54<00:17,  1.22s/it]Main training loop, train epoch 9.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Main training loop, train epoch 9.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 9.:  90%|████████▉ | 96/107 [01:57<00:13,  1.24s/it]Main training loop, train epoch 9.:  91%|█████████ | 97/107 [01:59<00:12,  1.23s/it]Main training loop, train epoch 9.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Main training loop, train epoch 9.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Main training loop, train epoch 9.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 9.:  94%|█████████▍| 101/107 [02:03<00:07,  1.22s/it]Main training loop, train epoch 9.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 9.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Main training loop, train epoch 9.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Main training loop, train epoch 9.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Main training loop, train epoch 9.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 9.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 9.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:08:10,497] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_9 is about to be saved!
[2025-06-25 08:08:10,528] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,528] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,528] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,528] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,529] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_9/mp_rank_00_model_states.pt
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_9/mp_rank_00_model_states.pt...
[2025-06-25 08:08:10,529] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,529] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,529] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,532] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,532] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,532] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,532] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,533] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,533] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,533] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,533] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,533] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,533] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,534] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:10,534] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
[2025-06-25 08:08:12,694] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_9/mp_rank_00_model_states.pt.
[2025-06-25 08:08:12,694] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_9 is ready now!
Testing on epoch 9.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 9.:   9%|▉         | 1/11 [00:00<00:06,  1.62it/s]Testing on epoch 9.:  18%|█▊        | 2/11 [00:01<00:05,  1.66it/s]Testing on epoch 9.:  27%|██▋       | 3/11 [00:01<00:04,  1.71it/s]Testing on epoch 9.:  36%|███▋      | 4/11 [00:02<00:04,  1.64it/s]Testing on epoch 9.:  45%|████▌     | 5/11 [00:02<00:03,  1.67it/s]Testing on epoch 9.:  55%|█████▍    | 6/11 [00:03<00:02,  1.67it/s]Testing on epoch 9.:  64%|██████▎   | 7/11 [00:04<00:02,  1.73it/s]Testing on epoch 9.:  73%|███████▎  | 8/11 [00:04<00:01,  1.73it/s]Testing on epoch 9.:  82%|████████▏ | 9/11 [00:05<00:01,  1.70it/s]Testing on epoch 9.:  91%|█████████ | 10/11 [00:05<00:00,  1.71it/s]Testing on epoch 9.: 100%|██████████| 11/11 [00:06<00:00,  1.73it/s]Testing on epoch 9.: 100%|██████████| 11/11 [00:06<00:00,  1.70it/s]
Main training loop, train epoch 10.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 10.:   1%|          | 1/107 [00:01<02:11,  1.24s/it]Main training loop, train epoch 10.:   2%|▏         | 2/107 [00:02<02:09,  1.23s/it]Main training loop, train epoch 10.:   3%|▎         | 3/107 [00:03<02:07,  1.23s/it]Main training loop, train epoch 10.:   4%|▎         | 4/107 [00:04<02:05,  1.22s/it]Main training loop, train epoch 10.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 10.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Main training loop, train epoch 10.:   7%|▋         | 7/107 [00:08<02:02,  1.22s/it]Main training loop, train epoch 10.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Main training loop, train epoch 10.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Main training loop, train epoch 10.:   9%|▉         | 10/107 [00:12<01:58,  1.23s/it]Main training loop, train epoch 10.:  10%|█         | 11/107 [00:13<01:58,  1.23s/it]Main training loop, train epoch 10.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Main training loop, train epoch 10.:  12%|█▏        | 13/107 [00:15<01:55,  1.23s/it]Main training loop, train epoch 10.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 10.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Main training loop, train epoch 10.:  15%|█▍        | 16/107 [00:19<01:51,  1.23s/it]Main training loop, train epoch 10.:  16%|█▌        | 17/107 [00:20<01:51,  1.24s/it]Main training loop, train epoch 10.:  17%|█▋        | 18/107 [00:22<01:50,  1.24s/it]Main training loop, train epoch 10.:  18%|█▊        | 19/107 [00:23<01:48,  1.24s/it]Main training loop, train epoch 10.:  19%|█▊        | 20/107 [00:24<01:47,  1.23s/it]Main training loop, train epoch 10.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 10.:  21%|██        | 22/107 [00:27<01:43,  1.22s/it]Main training loop, train epoch 10.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 10.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 10.:  23%|██▎       | 25/107 [00:30<01:40,  1.22s/it]Main training loop, train epoch 10.:  24%|██▍       | 26/107 [00:31<01:38,  1.22s/it]Main training loop, train epoch 10.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Main training loop, train epoch 10.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Main training loop, train epoch 10.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Main training loop, train epoch 10.:  28%|██▊       | 30/107 [00:36<01:34,  1.22s/it]Main training loop, train epoch 10.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Main training loop, train epoch 10.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 10.:  31%|███       | 33/107 [00:40<01:31,  1.24s/it]Main training loop, train epoch 10.:  32%|███▏      | 34/107 [00:41<01:30,  1.23s/it]Main training loop, train epoch 10.:  33%|███▎      | 35/107 [00:42<01:28,  1.23s/it]Main training loop, train epoch 10.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 10.:  35%|███▍      | 37/107 [00:45<01:26,  1.23s/it]Main training loop, train epoch 10.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Main training loop, train epoch 10.:  36%|███▋      | 39/107 [00:47<01:24,  1.24s/it]Main training loop, train epoch 10.:  37%|███▋      | 40/107 [00:49<01:22,  1.24s/it]Main training loop, train epoch 10.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Main training loop, train epoch 10.:  39%|███▉      | 42/107 [00:51<01:20,  1.23s/it]Main training loop, train epoch 10.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 10.:  41%|████      | 44/107 [00:54<01:17,  1.23s/it]Main training loop, train epoch 10.:  42%|████▏     | 45/107 [00:55<01:15,  1.23s/it]Main training loop, train epoch 10.:  43%|████▎     | 46/107 [00:56<01:14,  1.23s/it]Main training loop, train epoch 10.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 10.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Main training loop, train epoch 10.:  46%|████▌     | 49/107 [01:00<01:11,  1.22s/it]Main training loop, train epoch 10.:  47%|████▋     | 50/107 [01:01<01:09,  1.23s/it]Main training loop, train epoch 10.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 10.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 10.:  50%|████▉     | 53/107 [01:05<01:06,  1.22s/it]Main training loop, train epoch 10.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Main training loop, train epoch 10.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Main training loop, train epoch 10.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Main training loop, train epoch 10.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 10.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 10.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 10.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 10.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 10.:  58%|█████▊    | 62/107 [01:16<00:55,  1.22s/it]Main training loop, train epoch 10.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Main training loop, train epoch 10.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Main training loop, train epoch 10.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Main training loop, train epoch 10.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Main training loop, train epoch 10.:  63%|██████▎   | 67/107 [01:22<00:49,  1.24s/it]Main training loop, train epoch 10.:  64%|██████▎   | 68/107 [01:23<00:48,  1.24s/it]Main training loop, train epoch 10.:  64%|██████▍   | 69/107 [01:24<00:46,  1.24s/it]Main training loop, train epoch 10.:  65%|██████▌   | 70/107 [01:25<00:45,  1.24s/it]Main training loop, train epoch 10.:  66%|██████▋   | 71/107 [01:27<00:44,  1.24s/it]Main training loop, train epoch 10.:  67%|██████▋   | 72/107 [01:28<00:43,  1.24s/it]Main training loop, train epoch 10.:  68%|██████▊   | 73/107 [01:29<00:42,  1.24s/it]Main training loop, train epoch 10.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 10.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Main training loop, train epoch 10.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 10.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Main training loop, train epoch 10.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 10.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Main training loop, train epoch 10.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Main training loop, train epoch 10.:  76%|███████▌  | 81/107 [01:39<00:32,  1.24s/it]Main training loop, train epoch 10.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 10.:  78%|███████▊  | 83/107 [01:42<00:29,  1.24s/it]Main training loop, train epoch 10.:  79%|███████▊  | 84/107 [01:43<00:28,  1.24s/it]Main training loop, train epoch 10.:  79%|███████▉  | 85/107 [01:44<00:27,  1.25s/it]Main training loop, train epoch 10.:  80%|████████  | 86/107 [01:45<00:26,  1.24s/it]Main training loop, train epoch 10.:  81%|████████▏ | 87/107 [01:46<00:24,  1.24s/it]Main training loop, train epoch 10.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Main training loop, train epoch 10.:  83%|████████▎ | 89/107 [01:49<00:22,  1.23s/it]Main training loop, train epoch 10.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 10.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 10.:  86%|████████▌ | 92/107 [01:53<00:18,  1.23s/it]Main training loop, train epoch 10.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Main training loop, train epoch 10.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Main training loop, train epoch 10.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Main training loop, train epoch 10.:  90%|████████▉ | 96/107 [01:58<00:13,  1.22s/it]Main training loop, train epoch 10.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Main training loop, train epoch 10.:  92%|█████████▏| 98/107 [02:00<00:11,  1.22s/it]Main training loop, train epoch 10.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Main training loop, train epoch 10.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 10.:  94%|█████████▍| 101/107 [02:04<00:07,  1.22s/it]Main training loop, train epoch 10.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 10.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Main training loop, train epoch 10.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 10.:  98%|█████████▊| 105/107 [02:09<00:02,  1.22s/it]Main training loop, train epoch 10.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Main training loop, train epoch 10.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 10.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:10:30,668] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_10 is about to be saved!
[2025-06-25 08:10:30,752] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,752] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,755] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,757] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,757] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,757] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,757] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,759] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_10/mp_rank_00_model_states.pt
[2025-06-25 08:10:30,759] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_10/mp_rank_00_model_states.pt...
[2025-06-25 08:10:30,760] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,762] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,762] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,762] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,762] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,765] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,766] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,766] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,766] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:30,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
[2025-06-25 08:10:32,873] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_10/mp_rank_00_model_states.pt.
[2025-06-25 08:10:32,873] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_10 is ready now!
Main training loop, train epoch 11.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 11.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Main training loop, train epoch 11.:   2%|▏         | 2/107 [00:02<02:11,  1.25s/it]Main training loop, train epoch 11.:   3%|▎         | 3/107 [00:03<02:09,  1.24s/it]Main training loop, train epoch 11.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Main training loop, train epoch 11.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Main training loop, train epoch 11.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Main training loop, train epoch 11.:   7%|▋         | 7/107 [00:08<02:03,  1.24s/it]Main training loop, train epoch 11.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Main training loop, train epoch 11.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 11.:   9%|▉         | 10/107 [00:12<01:58,  1.23s/it]Main training loop, train epoch 11.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Main training loop, train epoch 11.:  11%|█         | 12/107 [00:14<01:55,  1.22s/it]Main training loop, train epoch 11.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Main training loop, train epoch 11.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 11.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Main training loop, train epoch 11.:  15%|█▍        | 16/107 [00:19<01:51,  1.22s/it]Main training loop, train epoch 11.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Main training loop, train epoch 11.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Main training loop, train epoch 11.:  18%|█▊        | 19/107 [00:23<01:48,  1.23s/it]Main training loop, train epoch 11.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Main training loop, train epoch 11.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 11.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Main training loop, train epoch 11.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 11.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 11.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 11.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 11.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 11.:  26%|██▌       | 28/107 [00:34<01:36,  1.23s/it]Main training loop, train epoch 11.:  27%|██▋       | 29/107 [00:35<01:35,  1.23s/it]Main training loop, train epoch 11.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 11.:  29%|██▉       | 31/107 [00:38<01:32,  1.22s/it]Main training loop, train epoch 11.:  30%|██▉       | 32/107 [00:39<01:31,  1.21s/it]Main training loop, train epoch 11.:  31%|███       | 33/107 [00:40<01:30,  1.22s/it]Main training loop, train epoch 11.:  32%|███▏      | 34/107 [00:41<01:29,  1.22s/it]Main training loop, train epoch 11.:  33%|███▎      | 35/107 [00:42<01:27,  1.22s/it]Main training loop, train epoch 11.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Main training loop, train epoch 11.:  35%|███▍      | 37/107 [00:45<01:25,  1.23s/it]Main training loop, train epoch 11.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 11.:  36%|███▋      | 39/107 [00:47<01:22,  1.22s/it]Main training loop, train epoch 11.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Main training loop, train epoch 11.:  38%|███▊      | 41/107 [00:50<01:19,  1.21s/it]Main training loop, train epoch 11.:  39%|███▉      | 42/107 [00:51<01:18,  1.21s/it]Main training loop, train epoch 11.:  40%|████      | 43/107 [00:52<01:17,  1.21s/it]Main training loop, train epoch 11.:  41%|████      | 44/107 [00:53<01:16,  1.22s/it]Main training loop, train epoch 11.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Main training loop, train epoch 11.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 11.:  44%|████▍     | 47/107 [00:57<01:13,  1.22s/it]Main training loop, train epoch 11.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Main training loop, train epoch 11.:  46%|████▌     | 49/107 [00:59<01:10,  1.22s/it]Main training loop, train epoch 11.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Main training loop, train epoch 11.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 11.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 11.:  50%|████▉     | 53/107 [01:04<01:05,  1.22s/it]Main training loop, train epoch 11.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Main training loop, train epoch 11.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Main training loop, train epoch 11.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 11.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 11.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 11.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 11.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 11.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 11.:  58%|█████▊    | 62/107 [01:15<00:55,  1.23s/it]Main training loop, train epoch 11.:  59%|█████▉    | 63/107 [01:17<00:54,  1.23s/it]Main training loop, train epoch 11.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Main training loop, train epoch 11.:  61%|██████    | 65/107 [01:19<00:52,  1.24s/it]Main training loop, train epoch 11.:  62%|██████▏   | 66/107 [01:20<00:50,  1.23s/it]Main training loop, train epoch 11.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Main training loop, train epoch 11.:  64%|██████▎   | 68/107 [01:23<00:48,  1.23s/it]Main training loop, train epoch 11.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 11.:  65%|██████▌   | 70/107 [01:25<00:45,  1.24s/it]Main training loop, train epoch 11.:  66%|██████▋   | 71/107 [01:27<00:44,  1.24s/it]Main training loop, train epoch 11.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Main training loop, train epoch 11.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 11.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Main training loop, train epoch 11.:  70%|███████   | 75/107 [01:31<00:39,  1.23s/it]Main training loop, train epoch 11.:  71%|███████   | 76/107 [01:33<00:37,  1.22s/it]Main training loop, train epoch 11.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Main training loop, train epoch 11.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 11.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Main training loop, train epoch 11.:  75%|███████▍  | 80/107 [01:38<00:32,  1.22s/it]Main training loop, train epoch 11.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 11.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Main training loop, train epoch 11.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 11.:  79%|███████▊  | 84/107 [01:42<00:28,  1.23s/it]Main training loop, train epoch 11.:  79%|███████▉  | 85/107 [01:44<00:26,  1.23s/it]Main training loop, train epoch 11.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Main training loop, train epoch 11.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 11.:  82%|████████▏ | 88/107 [01:47<00:23,  1.24s/it]Main training loop, train epoch 11.:  83%|████████▎ | 89/107 [01:49<00:22,  1.24s/it]Main training loop, train epoch 11.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 11.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 11.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Main training loop, train epoch 11.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Main training loop, train epoch 11.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Main training loop, train epoch 11.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 11.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Main training loop, train epoch 11.:  91%|█████████ | 97/107 [01:58<00:12,  1.23s/it]Main training loop, train epoch 11.:  92%|█████████▏| 98/107 [02:00<00:11,  1.22s/it]Main training loop, train epoch 11.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Main training loop, train epoch 11.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 11.:  94%|█████████▍| 101/107 [02:03<00:07,  1.22s/it]Main training loop, train epoch 11.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 11.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 11.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Main training loop, train epoch 11.:  98%|█████████▊| 105/107 [02:08<00:02,  1.24s/it]Main training loop, train epoch 11.:  99%|█████████▉| 106/107 [02:10<00:01,  1.24s/it]Main training loop, train epoch 11.: 100%|██████████| 107/107 [02:11<00:00,  1.24s/it]Main training loop, train epoch 11.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:12:44,173] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_11 is about to be saved!
[2025-06-25 08:12:44,204] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,204] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,204] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,204] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_11/mp_rank_00_model_states.pt
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_11/mp_rank_00_model_states.pt...
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,208] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,208] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,209] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,209] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,210] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,210] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,210] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:44,210] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
[2025-06-25 08:12:46,422] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_11/mp_rank_00_model_states.pt.
[2025-06-25 08:12:46,422] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_11 is ready now!
Testing on epoch 11.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 11.:   9%|▉         | 1/11 [00:00<00:06,  1.62it/s]Testing on epoch 11.:  18%|█▊        | 2/11 [00:01<00:05,  1.63it/s]Testing on epoch 11.:  27%|██▋       | 3/11 [00:01<00:04,  1.72it/s]Testing on epoch 11.:  36%|███▋      | 4/11 [00:02<00:04,  1.73it/s]Testing on epoch 11.:  45%|████▌     | 5/11 [00:03<00:03,  1.60it/s]Testing on epoch 11.:  55%|█████▍    | 6/11 [00:03<00:03,  1.57it/s]Testing on epoch 11.:  64%|██████▎   | 7/11 [00:04<00:02,  1.57it/s]Testing on epoch 11.:  73%|███████▎  | 8/11 [00:04<00:01,  1.59it/s]Testing on epoch 11.:  82%|████████▏ | 9/11 [00:05<00:01,  1.68it/s]Testing on epoch 11.:  91%|█████████ | 10/11 [00:06<00:00,  1.73it/s]Testing on epoch 11.: 100%|██████████| 11/11 [00:06<00:00,  1.74it/s]Testing on epoch 11.: 100%|██████████| 11/11 [00:06<00:00,  1.67it/s]
Main training loop, train epoch 12.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 12.:   1%|          | 1/107 [00:01<02:11,  1.24s/it]Main training loop, train epoch 12.:   2%|▏         | 2/107 [00:02<02:10,  1.25s/it]Main training loop, train epoch 12.:   3%|▎         | 3/107 [00:03<02:09,  1.25s/it]Main training loop, train epoch 12.:   4%|▎         | 4/107 [00:04<02:08,  1.25s/it]Main training loop, train epoch 12.:   5%|▍         | 5/107 [00:06<02:07,  1.25s/it]Main training loop, train epoch 12.:   6%|▌         | 6/107 [00:07<02:05,  1.24s/it]Main training loop, train epoch 12.:   7%|▋         | 7/107 [00:08<02:03,  1.24s/it]Main training loop, train epoch 12.:   7%|▋         | 8/107 [00:09<02:02,  1.24s/it]Main training loop, train epoch 12.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 12.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Main training loop, train epoch 12.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Main training loop, train epoch 12.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Main training loop, train epoch 12.:  12%|█▏        | 13/107 [00:16<01:55,  1.23s/it]Main training loop, train epoch 12.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 12.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Main training loop, train epoch 12.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Main training loop, train epoch 12.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Main training loop, train epoch 12.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 12.:  18%|█▊        | 19/107 [00:23<01:47,  1.23s/it]Main training loop, train epoch 12.:  19%|█▊        | 20/107 [00:24<01:46,  1.22s/it]Main training loop, train epoch 12.:  20%|█▉        | 21/107 [00:25<01:45,  1.22s/it]Main training loop, train epoch 12.:  21%|██        | 22/107 [00:27<01:43,  1.22s/it]Main training loop, train epoch 12.:  21%|██▏       | 23/107 [00:28<01:41,  1.21s/it]Main training loop, train epoch 12.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 12.:  23%|██▎       | 25/107 [00:30<01:40,  1.22s/it]Main training loop, train epoch 12.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 12.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 12.:  26%|██▌       | 28/107 [00:34<01:36,  1.23s/it]Main training loop, train epoch 12.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Main training loop, train epoch 12.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 12.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Main training loop, train epoch 12.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 12.:  31%|███       | 33/107 [00:40<01:30,  1.22s/it]Main training loop, train epoch 12.:  32%|███▏      | 34/107 [00:41<01:29,  1.22s/it]Main training loop, train epoch 12.:  33%|███▎      | 35/107 [00:43<01:28,  1.22s/it]Main training loop, train epoch 12.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Main training loop, train epoch 12.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 12.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 12.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Main training loop, train epoch 12.:  37%|███▋      | 40/107 [00:49<01:22,  1.22s/it]Main training loop, train epoch 12.:  38%|███▊      | 41/107 [00:50<01:20,  1.23s/it]Main training loop, train epoch 12.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Main training loop, train epoch 12.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 12.:  41%|████      | 44/107 [00:54<01:16,  1.22s/it]Main training loop, train epoch 12.:  42%|████▏     | 45/107 [00:55<01:15,  1.23s/it]Main training loop, train epoch 12.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 12.:  44%|████▍     | 47/107 [00:57<01:13,  1.22s/it]Main training loop, train epoch 12.:  45%|████▍     | 48/107 [00:58<01:11,  1.22s/it]Main training loop, train epoch 12.:  46%|████▌     | 49/107 [01:00<01:10,  1.22s/it]Main training loop, train epoch 12.:  47%|████▋     | 50/107 [01:01<01:09,  1.23s/it]Main training loop, train epoch 12.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 12.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 12.:  50%|████▉     | 53/107 [01:04<01:05,  1.22s/it]Main training loop, train epoch 12.:  50%|█████     | 54/107 [01:06<01:04,  1.21s/it]Main training loop, train epoch 12.:  51%|█████▏    | 55/107 [01:07<01:03,  1.21s/it]Main training loop, train epoch 12.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Main training loop, train epoch 12.:  53%|█████▎    | 57/107 [01:09<01:01,  1.22s/it]Main training loop, train epoch 12.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Main training loop, train epoch 12.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 12.:  56%|█████▌    | 60/107 [01:13<00:57,  1.21s/it]Main training loop, train epoch 12.:  57%|█████▋    | 61/107 [01:14<00:56,  1.22s/it]Main training loop, train epoch 12.:  58%|█████▊    | 62/107 [01:15<00:55,  1.22s/it]Main training loop, train epoch 12.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Main training loop, train epoch 12.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Main training loop, train epoch 12.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Main training loop, train epoch 12.:  62%|██████▏   | 66/107 [01:20<00:49,  1.21s/it]Main training loop, train epoch 12.:  63%|██████▎   | 67/107 [01:22<00:48,  1.21s/it]Main training loop, train epoch 12.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Main training loop, train epoch 12.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Main training loop, train epoch 12.:  65%|██████▌   | 70/107 [01:25<00:45,  1.22s/it]Main training loop, train epoch 12.:  66%|██████▋   | 71/107 [01:26<00:44,  1.22s/it]Main training loop, train epoch 12.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 12.:  68%|██████▊   | 73/107 [01:29<00:41,  1.21s/it]Main training loop, train epoch 12.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 12.:  70%|███████   | 75/107 [01:31<00:39,  1.23s/it]Main training loop, train epoch 12.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 12.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Main training loop, train epoch 12.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 12.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Main training loop, train epoch 12.:  75%|███████▍  | 80/107 [01:37<00:33,  1.22s/it]Main training loop, train epoch 12.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 12.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 12.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 12.:  79%|███████▊  | 84/107 [01:42<00:28,  1.23s/it]Main training loop, train epoch 12.:  79%|███████▉  | 85/107 [01:44<00:26,  1.23s/it]Main training loop, train epoch 12.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Main training loop, train epoch 12.:  81%|████████▏ | 87/107 [01:46<00:24,  1.22s/it]Main training loop, train epoch 12.:  82%|████████▏ | 88/107 [01:47<00:23,  1.22s/it]Main training loop, train epoch 12.:  83%|████████▎ | 89/107 [01:48<00:21,  1.22s/it]Main training loop, train epoch 12.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 12.:  85%|████████▌ | 91/107 [01:51<00:19,  1.22s/it]Main training loop, train epoch 12.:  86%|████████▌ | 92/107 [01:52<00:18,  1.22s/it]Main training loop, train epoch 12.:  87%|████████▋ | 93/107 [01:53<00:17,  1.22s/it]Main training loop, train epoch 12.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Main training loop, train epoch 12.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 12.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Main training loop, train epoch 12.:  91%|█████████ | 97/107 [01:58<00:12,  1.22s/it]Main training loop, train epoch 12.:  92%|█████████▏| 98/107 [01:59<00:10,  1.22s/it]Main training loop, train epoch 12.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Main training loop, train epoch 12.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 12.:  94%|█████████▍| 101/107 [02:03<00:07,  1.23s/it]Main training loop, train epoch 12.:  95%|█████████▌| 102/107 [02:04<00:06,  1.23s/it]Main training loop, train epoch 12.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 12.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Main training loop, train epoch 12.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Main training loop, train epoch 12.:  99%|█████████▉| 106/107 [02:09<00:01,  1.23s/it]Main training loop, train epoch 12.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 12.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]
[2025-06-25 08:15:04,157] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_12 is about to be saved!
[2025-06-25 08:15:04,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,188] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_12/mp_rank_00_model_states.pt
[2025-06-25 08:15:04,188] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_12/mp_rank_00_model_states.pt...
[2025-06-25 08:15:04,189] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,189] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,189] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,189] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,189] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,189] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,189] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,191] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,192] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,193] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,193] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,193] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:04,193] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
[2025-06-25 08:15:06,383] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_12/mp_rank_00_model_states.pt.
[2025-06-25 08:15:06,383] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_12 is ready now!
Main training loop, train epoch 13.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 13.:   1%|          | 1/107 [00:01<02:14,  1.27s/it]Main training loop, train epoch 13.:   2%|▏         | 2/107 [00:02<02:10,  1.24s/it]Main training loop, train epoch 13.:   3%|▎         | 3/107 [00:03<02:08,  1.23s/it]Main training loop, train epoch 13.:   4%|▎         | 4/107 [00:04<02:07,  1.23s/it]Main training loop, train epoch 13.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 13.:   6%|▌         | 6/107 [00:07<02:04,  1.24s/it]Main training loop, train epoch 13.:   7%|▋         | 7/107 [00:08<02:03,  1.23s/it]Main training loop, train epoch 13.:   7%|▋         | 8/107 [00:09<02:02,  1.24s/it]Main training loop, train epoch 13.:   8%|▊         | 9/107 [00:11<02:01,  1.24s/it]Main training loop, train epoch 13.:   9%|▉         | 10/107 [00:12<02:00,  1.24s/it]Main training loop, train epoch 13.:  10%|█         | 11/107 [00:13<01:58,  1.23s/it]Main training loop, train epoch 13.:  11%|█         | 12/107 [00:14<01:56,  1.23s/it]Main training loop, train epoch 13.:  12%|█▏        | 13/107 [00:16<01:54,  1.22s/it]Main training loop, train epoch 13.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 13.:  14%|█▍        | 15/107 [00:18<01:52,  1.23s/it]Main training loop, train epoch 13.:  15%|█▍        | 16/107 [00:19<01:51,  1.23s/it]Main training loop, train epoch 13.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Main training loop, train epoch 13.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Main training loop, train epoch 13.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Main training loop, train epoch 13.:  19%|█▊        | 20/107 [00:24<01:47,  1.23s/it]Main training loop, train epoch 13.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 13.:  21%|██        | 22/107 [00:27<01:43,  1.22s/it]Main training loop, train epoch 13.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 13.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 13.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 13.:  24%|██▍       | 26/107 [00:31<01:40,  1.23s/it]Main training loop, train epoch 13.:  25%|██▌       | 27/107 [00:33<01:39,  1.24s/it]Main training loop, train epoch 13.:  26%|██▌       | 28/107 [00:34<01:38,  1.24s/it]Main training loop, train epoch 13.:  27%|██▋       | 29/107 [00:35<01:36,  1.24s/it]Main training loop, train epoch 13.:  28%|██▊       | 30/107 [00:36<01:35,  1.24s/it]Main training loop, train epoch 13.:  29%|██▉       | 31/107 [00:38<01:33,  1.24s/it]Main training loop, train epoch 13.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 13.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Main training loop, train epoch 13.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Main training loop, train epoch 13.:  33%|███▎      | 35/107 [00:43<01:28,  1.22s/it]Main training loop, train epoch 13.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 13.:  35%|███▍      | 37/107 [00:45<01:25,  1.23s/it]Main training loop, train epoch 13.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 13.:  36%|███▋      | 39/107 [00:47<01:23,  1.22s/it]Main training loop, train epoch 13.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Main training loop, train epoch 13.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Main training loop, train epoch 13.:  39%|███▉      | 42/107 [00:51<01:19,  1.23s/it]Main training loop, train epoch 13.:  40%|████      | 43/107 [00:52<01:19,  1.24s/it]Main training loop, train epoch 13.:  41%|████      | 44/107 [00:54<01:17,  1.24s/it]Main training loop, train epoch 13.:  42%|████▏     | 45/107 [00:55<01:17,  1.24s/it]Main training loop, train epoch 13.:  43%|████▎     | 46/107 [00:56<01:15,  1.24s/it]Main training loop, train epoch 13.:  44%|████▍     | 47/107 [00:57<01:14,  1.24s/it]Main training loop, train epoch 13.:  45%|████▍     | 48/107 [00:59<01:13,  1.24s/it]Main training loop, train epoch 13.:  46%|████▌     | 49/107 [01:00<01:11,  1.24s/it]Main training loop, train epoch 13.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Main training loop, train epoch 13.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 13.:  49%|████▊     | 52/107 [01:04<01:07,  1.22s/it]Main training loop, train epoch 13.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Main training loop, train epoch 13.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 13.:  51%|█████▏    | 55/107 [01:07<01:04,  1.23s/it]Main training loop, train epoch 13.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Main training loop, train epoch 13.:  53%|█████▎    | 57/107 [01:10<01:01,  1.22s/it]Main training loop, train epoch 13.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 13.:  55%|█████▌    | 59/107 [01:12<00:58,  1.23s/it]Main training loop, train epoch 13.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 13.:  57%|█████▋    | 61/107 [01:15<00:56,  1.22s/it]Main training loop, train epoch 13.:  58%|█████▊    | 62/107 [01:16<00:54,  1.22s/it]Main training loop, train epoch 13.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Main training loop, train epoch 13.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Main training loop, train epoch 13.:  61%|██████    | 65/107 [01:19<00:51,  1.23s/it]Main training loop, train epoch 13.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Main training loop, train epoch 13.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Main training loop, train epoch 13.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Main training loop, train epoch 13.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Main training loop, train epoch 13.:  65%|██████▌   | 70/107 [01:26<00:45,  1.22s/it]Main training loop, train epoch 13.:  66%|██████▋   | 71/107 [01:27<00:44,  1.22s/it]Main training loop, train epoch 13.:  67%|██████▋   | 72/107 [01:28<00:42,  1.23s/it]Main training loop, train epoch 13.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Main training loop, train epoch 13.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Main training loop, train epoch 13.:  70%|███████   | 75/107 [01:32<00:39,  1.22s/it]Main training loop, train epoch 13.:  71%|███████   | 76/107 [01:33<00:37,  1.22s/it]Main training loop, train epoch 13.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 13.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 13.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Main training loop, train epoch 13.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Main training loop, train epoch 13.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 13.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Main training loop, train epoch 13.:  78%|███████▊  | 83/107 [01:41<00:29,  1.22s/it]Main training loop, train epoch 13.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 13.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Main training loop, train epoch 13.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Main training loop, train epoch 13.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 13.:  82%|████████▏ | 88/107 [01:48<00:23,  1.23s/it]Main training loop, train epoch 13.:  83%|████████▎ | 89/107 [01:49<00:21,  1.22s/it]Main training loop, train epoch 13.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 13.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 13.:  86%|████████▌ | 92/107 [01:52<00:18,  1.22s/it]Main training loop, train epoch 13.:  87%|████████▋ | 93/107 [01:54<00:17,  1.22s/it]Main training loop, train epoch 13.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Main training loop, train epoch 13.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Main training loop, train epoch 13.:  90%|████████▉ | 96/107 [01:57<00:13,  1.22s/it]Main training loop, train epoch 13.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Main training loop, train epoch 13.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Main training loop, train epoch 13.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 13.:  93%|█████████▎| 100/107 [02:02<00:08,  1.24s/it]Main training loop, train epoch 13.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Main training loop, train epoch 13.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 13.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 13.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Main training loop, train epoch 13.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Main training loop, train epoch 13.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 13.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 13.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:17:17,813] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_13 is about to be saved!
[2025-06-25 08:17:17,864] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,864] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,864] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,864] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,865] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,865] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,865] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,865] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_13/mp_rank_00_model_states.pt
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_13/mp_rank_00_model_states.pt...
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,866] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,867] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,869] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,869] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,869] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:17,869] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
[2025-06-25 08:17:20,026] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_13/mp_rank_00_model_states.pt.
[2025-06-25 08:17:20,026] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_13 is ready now!
Testing on epoch 13.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 13.:   9%|▉         | 1/11 [00:00<00:06,  1.65it/s]Testing on epoch 13.:  18%|█▊        | 2/11 [00:01<00:05,  1.62it/s]Testing on epoch 13.:  27%|██▋       | 3/11 [00:01<00:04,  1.60it/s]Testing on epoch 13.:  36%|███▋      | 4/11 [00:02<00:04,  1.61it/s]Testing on epoch 13.:  45%|████▌     | 5/11 [00:03<00:03,  1.60it/s]Testing on epoch 13.:  55%|█████▍    | 6/11 [00:03<00:03,  1.59it/s]Testing on epoch 13.:  64%|██████▎   | 7/11 [00:04<00:02,  1.63it/s]Testing on epoch 13.:  73%|███████▎  | 8/11 [00:04<00:01,  1.61it/s]Testing on epoch 13.:  82%|████████▏ | 9/11 [00:05<00:01,  1.60it/s]Testing on epoch 13.:  91%|█████████ | 10/11 [00:06<00:00,  1.64it/s]Testing on epoch 13.: 100%|██████████| 11/11 [00:06<00:00,  1.65it/s]Testing on epoch 13.: 100%|██████████| 11/11 [00:06<00:00,  1.62it/s]
Main training loop, train epoch 14.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 14.:   1%|          | 1/107 [00:01<02:12,  1.25s/it]Main training loop, train epoch 14.:   2%|▏         | 2/107 [00:02<02:10,  1.24s/it]Main training loop, train epoch 14.:   3%|▎         | 3/107 [00:03<02:08,  1.23s/it]Main training loop, train epoch 14.:   4%|▎         | 4/107 [00:04<02:06,  1.23s/it]Main training loop, train epoch 14.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 14.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Main training loop, train epoch 14.:   7%|▋         | 7/107 [00:08<02:02,  1.23s/it]Main training loop, train epoch 14.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Main training loop, train epoch 14.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 14.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Main training loop, train epoch 14.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Main training loop, train epoch 14.:  11%|█         | 12/107 [00:14<01:55,  1.22s/it]Main training loop, train epoch 14.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Main training loop, train epoch 14.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 14.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Main training loop, train epoch 14.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Main training loop, train epoch 14.:  16%|█▌        | 17/107 [00:20<01:51,  1.24s/it]Main training loop, train epoch 14.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 14.:  18%|█▊        | 19/107 [00:23<01:48,  1.24s/it]Main training loop, train epoch 14.:  19%|█▊        | 20/107 [00:24<01:46,  1.23s/it]Main training loop, train epoch 14.:  20%|█▉        | 21/107 [00:25<01:45,  1.23s/it]Main training loop, train epoch 14.:  21%|██        | 22/107 [00:27<01:44,  1.23s/it]Main training loop, train epoch 14.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 14.:  22%|██▏       | 24/107 [00:29<01:41,  1.23s/it]Main training loop, train epoch 14.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 14.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 14.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 14.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Main training loop, train epoch 14.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Main training loop, train epoch 14.:  28%|██▊       | 30/107 [00:36<01:34,  1.22s/it]Main training loop, train epoch 14.:  29%|██▉       | 31/107 [00:38<01:32,  1.22s/it]Main training loop, train epoch 14.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Main training loop, train epoch 14.:  31%|███       | 33/107 [00:40<01:30,  1.23s/it]Main training loop, train epoch 14.:  32%|███▏      | 34/107 [00:41<01:29,  1.23s/it]Main training loop, train epoch 14.:  33%|███▎      | 35/107 [00:42<01:28,  1.22s/it]Main training loop, train epoch 14.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 14.:  35%|███▍      | 37/107 [00:45<01:25,  1.23s/it]Main training loop, train epoch 14.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 14.:  36%|███▋      | 39/107 [00:47<01:22,  1.22s/it]Main training loop, train epoch 14.:  37%|███▋      | 40/107 [00:49<01:21,  1.21s/it]Main training loop, train epoch 14.:  38%|███▊      | 41/107 [00:50<01:20,  1.23s/it]Main training loop, train epoch 14.:  39%|███▉      | 42/107 [00:51<01:19,  1.23s/it]Main training loop, train epoch 14.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 14.:  41%|████      | 44/107 [00:53<01:17,  1.23s/it]Main training loop, train epoch 14.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 14.:  43%|████▎     | 46/107 [00:56<01:15,  1.24s/it]Main training loop, train epoch 14.:  44%|████▍     | 47/107 [00:57<01:14,  1.23s/it]Main training loop, train epoch 14.:  45%|████▍     | 48/107 [00:58<01:12,  1.23s/it]Main training loop, train epoch 14.:  46%|████▌     | 49/107 [01:00<01:11,  1.24s/it]Main training loop, train epoch 14.:  47%|████▋     | 50/107 [01:01<01:10,  1.24s/it]Main training loop, train epoch 14.:  48%|████▊     | 51/107 [01:02<01:09,  1.24s/it]Main training loop, train epoch 14.:  49%|████▊     | 52/107 [01:03<01:07,  1.24s/it]Main training loop, train epoch 14.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Main training loop, train epoch 14.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 14.:  51%|█████▏    | 55/107 [01:07<01:04,  1.23s/it]Main training loop, train epoch 14.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 14.:  53%|█████▎    | 57/107 [01:10<01:01,  1.23s/it]Main training loop, train epoch 14.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 14.:  55%|█████▌    | 59/107 [01:12<00:59,  1.24s/it]Main training loop, train epoch 14.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 14.:  57%|█████▋    | 61/107 [01:14<00:56,  1.24s/it]Main training loop, train epoch 14.:  58%|█████▊    | 62/107 [01:16<00:55,  1.24s/it]Main training loop, train epoch 14.:  59%|█████▉    | 63/107 [01:17<00:54,  1.23s/it]Main training loop, train epoch 14.:  60%|█████▉    | 64/107 [01:18<00:52,  1.23s/it]Main training loop, train epoch 14.:  61%|██████    | 65/107 [01:19<00:51,  1.24s/it]Main training loop, train epoch 14.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Main training loop, train epoch 14.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Main training loop, train epoch 14.:  64%|██████▎   | 68/107 [01:23<00:48,  1.23s/it]Main training loop, train epoch 14.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 14.:  65%|██████▌   | 70/107 [01:26<00:45,  1.23s/it]Main training loop, train epoch 14.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 14.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Main training loop, train epoch 14.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 14.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 14.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Main training loop, train epoch 14.:  71%|███████   | 76/107 [01:33<00:37,  1.23s/it]Main training loop, train epoch 14.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 14.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 14.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Main training loop, train epoch 14.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Main training loop, train epoch 14.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Main training loop, train epoch 14.:  77%|███████▋  | 82/107 [01:40<00:30,  1.22s/it]Main training loop, train epoch 14.:  78%|███████▊  | 83/107 [01:42<00:29,  1.22s/it]Main training loop, train epoch 14.:  79%|███████▊  | 84/107 [01:43<00:28,  1.22s/it]Main training loop, train epoch 14.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Main training loop, train epoch 14.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Main training loop, train epoch 14.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 14.:  82%|████████▏ | 88/107 [01:48<00:23,  1.22s/it]Main training loop, train epoch 14.:  83%|████████▎ | 89/107 [01:49<00:21,  1.22s/it]Main training loop, train epoch 14.:  84%|████████▍ | 90/107 [01:50<00:20,  1.22s/it]Main training loop, train epoch 14.:  85%|████████▌ | 91/107 [01:51<00:19,  1.22s/it]Main training loop, train epoch 14.:  86%|████████▌ | 92/107 [01:52<00:18,  1.22s/it]Main training loop, train epoch 14.:  87%|████████▋ | 93/107 [01:54<00:17,  1.22s/it]Main training loop, train epoch 14.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Main training loop, train epoch 14.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Main training loop, train epoch 14.:  90%|████████▉ | 96/107 [01:57<00:13,  1.22s/it]Main training loop, train epoch 14.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Main training loop, train epoch 14.:  92%|█████████▏| 98/107 [02:00<00:10,  1.22s/it]Main training loop, train epoch 14.:  93%|█████████▎| 99/107 [02:01<00:09,  1.22s/it]Main training loop, train epoch 14.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 14.:  94%|█████████▍| 101/107 [02:03<00:07,  1.22s/it]Main training loop, train epoch 14.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 14.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Main training loop, train epoch 14.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 14.:  98%|█████████▊| 105/107 [02:08<00:02,  1.22s/it]Main training loop, train epoch 14.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 14.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 14.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:19:38,232] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_14 is about to be saved!
[2025-06-25 08:19:38,265] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,266] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,266] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,266] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_14/mp_rank_00_model_states.pt
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_14/mp_rank_00_model_states.pt...
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:38,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
[2025-06-25 08:19:40,392] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_14/mp_rank_00_model_states.pt.
[2025-06-25 08:19:40,393] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_14 is ready now!
Main training loop, train epoch 15.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 15.:   1%|          | 1/107 [00:01<02:12,  1.25s/it]Main training loop, train epoch 15.:   2%|▏         | 2/107 [00:02<02:08,  1.22s/it]Main training loop, train epoch 15.:   3%|▎         | 3/107 [00:03<02:06,  1.21s/it]Main training loop, train epoch 15.:   4%|▎         | 4/107 [00:04<02:06,  1.23s/it]Main training loop, train epoch 15.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Main training loop, train epoch 15.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Main training loop, train epoch 15.:   7%|▋         | 7/107 [00:08<02:02,  1.23s/it]Main training loop, train epoch 15.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Main training loop, train epoch 15.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Main training loop, train epoch 15.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Main training loop, train epoch 15.:  10%|█         | 11/107 [00:13<01:57,  1.23s/it]Main training loop, train epoch 15.:  11%|█         | 12/107 [00:14<01:57,  1.23s/it]Main training loop, train epoch 15.:  12%|█▏        | 13/107 [00:15<01:56,  1.23s/it]Main training loop, train epoch 15.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 15.:  14%|█▍        | 15/107 [00:18<01:52,  1.23s/it]Main training loop, train epoch 15.:  15%|█▍        | 16/107 [00:19<01:51,  1.23s/it]Main training loop, train epoch 15.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Main training loop, train epoch 15.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 15.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Main training loop, train epoch 15.:  19%|█▊        | 20/107 [00:24<01:45,  1.22s/it]Main training loop, train epoch 15.:  20%|█▉        | 21/107 [00:25<01:43,  1.21s/it]Main training loop, train epoch 15.:  21%|██        | 22/107 [00:26<01:43,  1.21s/it]Main training loop, train epoch 15.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 15.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 15.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 15.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 15.:  25%|██▌       | 27/107 [00:33<01:37,  1.22s/it]Main training loop, train epoch 15.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Main training loop, train epoch 15.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Main training loop, train epoch 15.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 15.:  29%|██▉       | 31/107 [00:37<01:33,  1.22s/it]Main training loop, train epoch 15.:  30%|██▉       | 32/107 [00:39<01:31,  1.22s/it]Main training loop, train epoch 15.:  31%|███       | 33/107 [00:40<01:30,  1.22s/it]Main training loop, train epoch 15.:  32%|███▏      | 34/107 [00:41<01:28,  1.22s/it]Main training loop, train epoch 15.:  33%|███▎      | 35/107 [00:42<01:27,  1.22s/it]Main training loop, train epoch 15.:  34%|███▎      | 36/107 [00:44<01:26,  1.22s/it]Main training loop, train epoch 15.:  35%|███▍      | 37/107 [00:45<01:25,  1.22s/it]Main training loop, train epoch 15.:  36%|███▌      | 38/107 [00:46<01:24,  1.22s/it]Main training loop, train epoch 15.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Main training loop, train epoch 15.:  37%|███▋      | 40/107 [00:49<01:22,  1.24s/it]Main training loop, train epoch 15.:  38%|███▊      | 41/107 [00:50<01:21,  1.23s/it]Main training loop, train epoch 15.:  39%|███▉      | 42/107 [00:51<01:19,  1.23s/it]Main training loop, train epoch 15.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 15.:  41%|████      | 44/107 [00:53<01:17,  1.23s/it]Main training loop, train epoch 15.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 15.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 15.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 15.:  45%|████▍     | 48/107 [00:58<01:12,  1.23s/it]Main training loop, train epoch 15.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Main training loop, train epoch 15.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Main training loop, train epoch 15.:  48%|████▊     | 51/107 [01:02<01:09,  1.23s/it]Main training loop, train epoch 15.:  49%|████▊     | 52/107 [01:03<01:07,  1.23s/it]Main training loop, train epoch 15.:  50%|████▉     | 53/107 [01:04<01:06,  1.23s/it]Main training loop, train epoch 15.:  50%|█████     | 54/107 [01:06<01:05,  1.24s/it]Main training loop, train epoch 15.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Main training loop, train epoch 15.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 15.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 15.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 15.:  55%|█████▌    | 59/107 [01:12<00:59,  1.23s/it]Main training loop, train epoch 15.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 15.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 15.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Main training loop, train epoch 15.:  59%|█████▉    | 63/107 [01:17<00:54,  1.23s/it]Main training loop, train epoch 15.:  60%|█████▉    | 64/107 [01:18<00:53,  1.24s/it]Main training loop, train epoch 15.:  61%|██████    | 65/107 [01:19<00:52,  1.24s/it]Main training loop, train epoch 15.:  62%|██████▏   | 66/107 [01:21<00:50,  1.24s/it]Main training loop, train epoch 15.:  63%|██████▎   | 67/107 [01:22<00:49,  1.24s/it]Main training loop, train epoch 15.:  64%|██████▎   | 68/107 [01:23<00:48,  1.23s/it]Main training loop, train epoch 15.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 15.:  65%|██████▌   | 70/107 [01:25<00:45,  1.24s/it]Main training loop, train epoch 15.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 15.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 15.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Main training loop, train epoch 15.:  69%|██████▉   | 74/107 [01:30<00:40,  1.22s/it]Main training loop, train epoch 15.:  70%|███████   | 75/107 [01:32<00:39,  1.22s/it]Main training loop, train epoch 15.:  71%|███████   | 76/107 [01:33<00:37,  1.22s/it]Main training loop, train epoch 15.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 15.:  73%|███████▎  | 78/107 [01:35<00:35,  1.21s/it]Main training loop, train epoch 15.:  74%|███████▍  | 79/107 [01:36<00:34,  1.22s/it]Main training loop, train epoch 15.:  75%|███████▍  | 80/107 [01:38<00:32,  1.22s/it]Main training loop, train epoch 15.:  76%|███████▌  | 81/107 [01:39<00:32,  1.23s/it]Main training loop, train epoch 15.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 15.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 15.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 15.:  79%|███████▉  | 85/107 [01:44<00:27,  1.23s/it]Main training loop, train epoch 15.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 15.:  81%|████████▏ | 87/107 [01:46<00:24,  1.22s/it]Main training loop, train epoch 15.:  82%|████████▏ | 88/107 [01:47<00:23,  1.23s/it]Main training loop, train epoch 15.:  83%|████████▎ | 89/107 [01:49<00:22,  1.22s/it]Main training loop, train epoch 15.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 15.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 15.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Main training loop, train epoch 15.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Main training loop, train epoch 15.:  88%|████████▊ | 94/107 [01:55<00:16,  1.23s/it]Main training loop, train epoch 15.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 15.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Main training loop, train epoch 15.:  91%|█████████ | 97/107 [01:59<00:12,  1.24s/it]Main training loop, train epoch 15.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Main training loop, train epoch 15.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 15.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 15.:  94%|█████████▍| 101/107 [02:03<00:07,  1.22s/it]Main training loop, train epoch 15.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 15.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 15.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 15.:  98%|█████████▊| 105/107 [02:08<00:02,  1.22s/it]Main training loop, train epoch 15.:  99%|█████████▉| 106/107 [02:10<00:01,  1.22s/it]Main training loop, train epoch 15.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 15.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:21:51,688] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_15 is about to be saved!
[2025-06-25 08:21:51,723] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,723] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,723] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,723] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_15/mp_rank_00_model_states.pt
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_15/mp_rank_00_model_states.pt...
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,726] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:51,727] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
[2025-06-25 08:21:53,853] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_15/mp_rank_00_model_states.pt.
[2025-06-25 08:21:53,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_15 is ready now!
Testing on epoch 15.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 15.:   9%|▉         | 1/11 [00:00<00:06,  1.53it/s]Testing on epoch 15.:  18%|█▊        | 2/11 [00:01<00:05,  1.69it/s]Testing on epoch 15.:  27%|██▋       | 3/11 [00:01<00:04,  1.69it/s]Testing on epoch 15.:  36%|███▋      | 4/11 [00:02<00:04,  1.69it/s]Testing on epoch 15.:  45%|████▌     | 5/11 [00:02<00:03,  1.76it/s]Testing on epoch 15.:  55%|█████▍    | 6/11 [00:03<00:02,  1.73it/s]Testing on epoch 15.:  64%|██████▎   | 7/11 [00:04<00:02,  1.67it/s]Testing on epoch 15.:  73%|███████▎  | 8/11 [00:04<00:01,  1.70it/s]Testing on epoch 15.:  82%|████████▏ | 9/11 [00:05<00:01,  1.68it/s]Testing on epoch 15.:  91%|█████████ | 10/11 [00:05<00:00,  1.71it/s]Testing on epoch 15.: 100%|██████████| 11/11 [00:06<00:00,  1.73it/s]Testing on epoch 15.: 100%|██████████| 11/11 [00:06<00:00,  1.71it/s]
Main training loop, train epoch 16.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 16.:   1%|          | 1/107 [00:01<02:10,  1.23s/it]Main training loop, train epoch 16.:   2%|▏         | 2/107 [00:02<02:08,  1.23s/it]Main training loop, train epoch 16.:   3%|▎         | 3/107 [00:03<02:07,  1.22s/it]Main training loop, train epoch 16.:   4%|▎         | 4/107 [00:04<02:05,  1.22s/it]Main training loop, train epoch 16.:   5%|▍         | 5/107 [00:06<02:04,  1.22s/it]Main training loop, train epoch 16.:   6%|▌         | 6/107 [00:07<02:03,  1.22s/it]Main training loop, train epoch 16.:   7%|▋         | 7/107 [00:08<02:02,  1.22s/it]Main training loop, train epoch 16.:   7%|▋         | 8/107 [00:09<02:01,  1.23s/it]Main training loop, train epoch 16.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Main training loop, train epoch 16.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Main training loop, train epoch 16.:  10%|█         | 11/107 [00:13<01:56,  1.22s/it]Main training loop, train epoch 16.:  11%|█         | 12/107 [00:14<01:55,  1.22s/it]Main training loop, train epoch 16.:  12%|█▏        | 13/107 [00:15<01:55,  1.23s/it]Main training loop, train epoch 16.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 16.:  14%|█▍        | 15/107 [00:18<01:53,  1.23s/it]Main training loop, train epoch 16.:  15%|█▍        | 16/107 [00:19<01:52,  1.23s/it]Main training loop, train epoch 16.:  16%|█▌        | 17/107 [00:20<01:51,  1.24s/it]Main training loop, train epoch 16.:  17%|█▋        | 18/107 [00:22<01:50,  1.24s/it]Main training loop, train epoch 16.:  18%|█▊        | 19/107 [00:23<01:48,  1.24s/it]Main training loop, train epoch 16.:  19%|█▊        | 20/107 [00:24<01:47,  1.24s/it]Main training loop, train epoch 16.:  20%|█▉        | 21/107 [00:25<01:46,  1.23s/it]Main training loop, train epoch 16.:  21%|██        | 22/107 [00:27<01:45,  1.24s/it]Main training loop, train epoch 16.:  21%|██▏       | 23/107 [00:28<01:43,  1.24s/it]Main training loop, train epoch 16.:  22%|██▏       | 24/107 [00:29<01:42,  1.24s/it]Main training loop, train epoch 16.:  23%|██▎       | 25/107 [00:30<01:41,  1.24s/it]Main training loop, train epoch 16.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 16.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 16.:  26%|██▌       | 28/107 [00:34<01:36,  1.22s/it]Main training loop, train epoch 16.:  27%|██▋       | 29/107 [00:35<01:35,  1.22s/it]Main training loop, train epoch 16.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 16.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Main training loop, train epoch 16.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 16.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Main training loop, train epoch 16.:  32%|███▏      | 34/107 [00:41<01:30,  1.23s/it]Main training loop, train epoch 16.:  33%|███▎      | 35/107 [00:43<01:29,  1.24s/it]Main training loop, train epoch 16.:  34%|███▎      | 36/107 [00:44<01:28,  1.24s/it]Main training loop, train epoch 16.:  35%|███▍      | 37/107 [00:45<01:26,  1.23s/it]Main training loop, train epoch 16.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Main training loop, train epoch 16.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Main training loop, train epoch 16.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Main training loop, train epoch 16.:  38%|███▊      | 41/107 [00:50<01:21,  1.24s/it]Main training loop, train epoch 16.:  39%|███▉      | 42/107 [00:51<01:20,  1.24s/it]Main training loop, train epoch 16.:  40%|████      | 43/107 [00:52<01:18,  1.23s/it]Main training loop, train epoch 16.:  41%|████      | 44/107 [00:54<01:17,  1.22s/it]Main training loop, train epoch 16.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 16.:  43%|████▎     | 46/107 [00:56<01:14,  1.23s/it]Main training loop, train epoch 16.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 16.:  45%|████▍     | 48/107 [00:59<01:12,  1.23s/it]Main training loop, train epoch 16.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Main training loop, train epoch 16.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Main training loop, train epoch 16.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 16.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 16.:  50%|████▉     | 53/107 [01:05<01:05,  1.22s/it]Main training loop, train epoch 16.:  50%|█████     | 54/107 [01:06<01:04,  1.22s/it]Main training loop, train epoch 16.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Main training loop, train epoch 16.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Main training loop, train epoch 16.:  53%|█████▎    | 57/107 [01:10<01:00,  1.21s/it]Main training loop, train epoch 16.:  54%|█████▍    | 58/107 [01:11<00:59,  1.21s/it]Main training loop, train epoch 16.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 16.:  56%|█████▌    | 60/107 [01:13<00:57,  1.23s/it]Main training loop, train epoch 16.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 16.:  58%|█████▊    | 62/107 [01:16<00:55,  1.22s/it]Main training loop, train epoch 16.:  59%|█████▉    | 63/107 [01:17<00:53,  1.22s/it]Main training loop, train epoch 16.:  60%|█████▉    | 64/107 [01:18<00:52,  1.22s/it]Main training loop, train epoch 16.:  61%|██████    | 65/107 [01:19<00:51,  1.22s/it]Main training loop, train epoch 16.:  62%|██████▏   | 66/107 [01:20<00:49,  1.21s/it]Main training loop, train epoch 16.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Main training loop, train epoch 16.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Main training loop, train epoch 16.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 16.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Main training loop, train epoch 16.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 16.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Main training loop, train epoch 16.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 16.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 16.:  70%|███████   | 75/107 [01:32<00:39,  1.24s/it]Main training loop, train epoch 16.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 16.:  72%|███████▏  | 77/107 [01:34<00:37,  1.23s/it]Main training loop, train epoch 16.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 16.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Main training loop, train epoch 16.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Main training loop, train epoch 16.:  76%|███████▌  | 81/107 [01:39<00:31,  1.23s/it]Main training loop, train epoch 16.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 16.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 16.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 16.:  79%|███████▉  | 85/107 [01:44<00:26,  1.22s/it]Main training loop, train epoch 16.:  80%|████████  | 86/107 [01:45<00:25,  1.22s/it]Main training loop, train epoch 16.:  81%|████████▏ | 87/107 [01:46<00:24,  1.22s/it]Main training loop, train epoch 16.:  82%|████████▏ | 88/107 [01:48<00:23,  1.22s/it]Main training loop, train epoch 16.:  83%|████████▎ | 89/107 [01:49<00:21,  1.22s/it]Main training loop, train epoch 16.:  84%|████████▍ | 90/107 [01:50<00:20,  1.22s/it]Main training loop, train epoch 16.:  85%|████████▌ | 91/107 [01:51<00:19,  1.22s/it]Main training loop, train epoch 16.:  86%|████████▌ | 92/107 [01:52<00:18,  1.22s/it]Main training loop, train epoch 16.:  87%|████████▋ | 93/107 [01:54<00:17,  1.24s/it]Main training loop, train epoch 16.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Main training loop, train epoch 16.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Main training loop, train epoch 16.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Main training loop, train epoch 16.:  91%|█████████ | 97/107 [01:59<00:12,  1.23s/it]Main training loop, train epoch 16.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Main training loop, train epoch 16.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 16.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Main training loop, train epoch 16.:  94%|█████████▍| 101/107 [02:03<00:07,  1.22s/it]Main training loop, train epoch 16.:  95%|█████████▌| 102/107 [02:05<00:06,  1.22s/it]Main training loop, train epoch 16.:  96%|█████████▋| 103/107 [02:06<00:04,  1.22s/it]Main training loop, train epoch 16.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 16.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Main training loop, train epoch 16.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 16.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 16.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:24:11,700] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_16 is about to be saved!
[2025-06-25 08:24:11,735] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,735] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,735] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,735] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,737] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_16/mp_rank_00_model_states.pt
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_16/mp_rank_00_model_states.pt...
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,737] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,737] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,738] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:11,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
[2025-06-25 08:24:13,863] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_16/mp_rank_00_model_states.pt.
[2025-06-25 08:24:13,863] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_16 is ready now!
Main training loop, train epoch 17.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 17.:   1%|          | 1/107 [00:01<02:13,  1.26s/it]Main training loop, train epoch 17.:   2%|▏         | 2/107 [00:02<02:09,  1.24s/it]Main training loop, train epoch 17.:   3%|▎         | 3/107 [00:03<02:08,  1.23s/it]Main training loop, train epoch 17.:   4%|▎         | 4/107 [00:04<02:06,  1.23s/it]Main training loop, train epoch 17.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Main training loop, train epoch 17.:   6%|▌         | 6/107 [00:07<02:05,  1.24s/it]Main training loop, train epoch 17.:   7%|▋         | 7/107 [00:08<02:02,  1.23s/it]Main training loop, train epoch 17.:   7%|▋         | 8/107 [00:09<02:01,  1.22s/it]Main training loop, train epoch 17.:   8%|▊         | 9/107 [00:11<01:59,  1.22s/it]Main training loop, train epoch 17.:   9%|▉         | 10/107 [00:12<01:58,  1.22s/it]Main training loop, train epoch 17.:  10%|█         | 11/107 [00:13<01:56,  1.22s/it]Main training loop, train epoch 17.:  11%|█         | 12/107 [00:14<01:55,  1.22s/it]Main training loop, train epoch 17.:  12%|█▏        | 13/107 [00:15<01:54,  1.22s/it]Main training loop, train epoch 17.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 17.:  14%|█▍        | 15/107 [00:18<01:52,  1.23s/it]Main training loop, train epoch 17.:  15%|█▍        | 16/107 [00:19<01:51,  1.22s/it]Main training loop, train epoch 17.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Main training loop, train epoch 17.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Main training loop, train epoch 17.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Main training loop, train epoch 17.:  19%|█▊        | 20/107 [00:24<01:46,  1.22s/it]Main training loop, train epoch 17.:  20%|█▉        | 21/107 [00:25<01:44,  1.22s/it]Main training loop, train epoch 17.:  21%|██        | 22/107 [00:26<01:43,  1.22s/it]Main training loop, train epoch 17.:  21%|██▏       | 23/107 [00:28<01:41,  1.21s/it]Main training loop, train epoch 17.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 17.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 17.:  24%|██▍       | 26/107 [00:31<01:39,  1.22s/it]Main training loop, train epoch 17.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 17.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Main training loop, train epoch 17.:  27%|██▋       | 29/107 [00:35<01:36,  1.23s/it]Main training loop, train epoch 17.:  28%|██▊       | 30/107 [00:36<01:35,  1.23s/it]Main training loop, train epoch 17.:  29%|██▉       | 31/107 [00:37<01:33,  1.23s/it]Main training loop, train epoch 17.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 17.:  31%|███       | 33/107 [00:40<01:31,  1.24s/it]Main training loop, train epoch 17.:  32%|███▏      | 34/107 [00:41<01:30,  1.23s/it]Main training loop, train epoch 17.:  33%|███▎      | 35/107 [00:42<01:28,  1.23s/it]Main training loop, train epoch 17.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 17.:  35%|███▍      | 37/107 [00:45<01:26,  1.24s/it]Main training loop, train epoch 17.:  36%|███▌      | 38/107 [00:46<01:25,  1.24s/it]Main training loop, train epoch 17.:  36%|███▋      | 39/107 [00:47<01:23,  1.23s/it]Main training loop, train epoch 17.:  37%|███▋      | 40/107 [00:49<01:22,  1.23s/it]Main training loop, train epoch 17.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Main training loop, train epoch 17.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Main training loop, train epoch 17.:  40%|████      | 43/107 [00:52<01:18,  1.22s/it]Main training loop, train epoch 17.:  41%|████      | 44/107 [00:53<01:17,  1.23s/it]Main training loop, train epoch 17.:  42%|████▏     | 45/107 [00:55<01:16,  1.23s/it]Main training loop, train epoch 17.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 17.:  44%|████▍     | 47/107 [00:57<01:12,  1.22s/it]Main training loop, train epoch 17.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Main training loop, train epoch 17.:  46%|████▌     | 49/107 [01:00<01:10,  1.22s/it]Main training loop, train epoch 17.:  47%|████▋     | 50/107 [01:01<01:09,  1.22s/it]Main training loop, train epoch 17.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Main training loop, train epoch 17.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 17.:  50%|████▉     | 53/107 [01:04<01:06,  1.23s/it]Main training loop, train epoch 17.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 17.:  51%|█████▏    | 55/107 [01:07<01:03,  1.23s/it]Main training loop, train epoch 17.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 17.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 17.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 17.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 17.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Main training loop, train epoch 17.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 17.:  58%|█████▊    | 62/107 [01:16<00:55,  1.24s/it]Main training loop, train epoch 17.:  59%|█████▉    | 63/107 [01:17<00:54,  1.24s/it]Main training loop, train epoch 17.:  60%|█████▉    | 64/107 [01:18<00:53,  1.24s/it]Main training loop, train epoch 17.:  61%|██████    | 65/107 [01:19<00:51,  1.24s/it]Main training loop, train epoch 17.:  62%|██████▏   | 66/107 [01:20<00:50,  1.24s/it]Main training loop, train epoch 17.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Main training loop, train epoch 17.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Main training loop, train epoch 17.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 17.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Main training loop, train epoch 17.:  66%|██████▋   | 71/107 [01:27<00:44,  1.24s/it]Main training loop, train epoch 17.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Main training loop, train epoch 17.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 17.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 17.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Main training loop, train epoch 17.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 17.:  72%|███████▏  | 77/107 [01:34<00:36,  1.23s/it]Main training loop, train epoch 17.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 17.:  74%|███████▍  | 79/107 [01:37<00:34,  1.24s/it]Main training loop, train epoch 17.:  75%|███████▍  | 80/107 [01:38<00:33,  1.24s/it]Main training loop, train epoch 17.:  76%|███████▌  | 81/107 [01:39<00:32,  1.25s/it]Main training loop, train epoch 17.:  77%|███████▋  | 82/107 [01:40<00:30,  1.24s/it]Main training loop, train epoch 17.:  78%|███████▊  | 83/107 [01:41<00:29,  1.23s/it]Main training loop, train epoch 17.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 17.:  79%|███████▉  | 85/107 [01:44<00:27,  1.23s/it]Main training loop, train epoch 17.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 17.:  81%|████████▏ | 87/107 [01:46<00:24,  1.23s/it]Main training loop, train epoch 17.:  82%|████████▏ | 88/107 [01:48<00:23,  1.24s/it]Main training loop, train epoch 17.:  83%|████████▎ | 89/107 [01:49<00:22,  1.24s/it]Main training loop, train epoch 17.:  84%|████████▍ | 90/107 [01:50<00:21,  1.24s/it]Main training loop, train epoch 17.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 17.:  86%|████████▌ | 92/107 [01:53<00:18,  1.24s/it]Main training loop, train epoch 17.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Main training loop, train epoch 17.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Main training loop, train epoch 17.:  89%|████████▉ | 95/107 [01:56<00:14,  1.22s/it]Main training loop, train epoch 17.:  90%|████████▉ | 96/107 [01:57<00:13,  1.22s/it]Main training loop, train epoch 17.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Main training loop, train epoch 17.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Main training loop, train epoch 17.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 17.:  93%|█████████▎| 100/107 [02:02<00:08,  1.22s/it]Main training loop, train epoch 17.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Main training loop, train epoch 17.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 17.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 17.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Main training loop, train epoch 17.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Main training loop, train epoch 17.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 17.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 17.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:26:25,376] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_17 is about to be saved!
[2025-06-25 08:26:25,407] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,407] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,407] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,407] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,410] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_17/mp_rank_00_model_states.pt
[2025-06-25 08:26:25,410] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_17/mp_rank_00_model_states.pt...
[2025-06-25 08:26:25,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,411] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,413] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,412] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,413] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:25,413] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
[2025-06-25 08:26:27,531] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_17/mp_rank_00_model_states.pt.
[2025-06-25 08:26:27,531] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_17 is ready now!
Testing on epoch 17.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 17.:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s]Testing on epoch 17.:  18%|█▊        | 2/11 [00:01<00:05,  1.65it/s]Testing on epoch 17.:  27%|██▋       | 3/11 [00:01<00:04,  1.64it/s]Testing on epoch 17.:  36%|███▋      | 4/11 [00:02<00:04,  1.66it/s]Testing on epoch 17.:  45%|████▌     | 5/11 [00:02<00:03,  1.71it/s]Testing on epoch 17.:  55%|█████▍    | 6/11 [00:03<00:03,  1.63it/s]Testing on epoch 17.:  64%|██████▎   | 7/11 [00:04<00:02,  1.64it/s]Testing on epoch 17.:  73%|███████▎  | 8/11 [00:04<00:01,  1.61it/s]Testing on epoch 17.:  82%|████████▏ | 9/11 [00:05<00:01,  1.64it/s]Testing on epoch 17.:  91%|█████████ | 10/11 [00:06<00:00,  1.58it/s]Testing on epoch 17.: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s]Testing on epoch 17.: 100%|██████████| 11/11 [00:06<00:00,  1.61it/s]
Main training loop, train epoch 18.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 18.:   1%|          | 1/107 [00:01<02:09,  1.23s/it]Main training loop, train epoch 18.:   2%|▏         | 2/107 [00:02<02:07,  1.21s/it]Main training loop, train epoch 18.:   3%|▎         | 3/107 [00:03<02:06,  1.21s/it]Main training loop, train epoch 18.:   4%|▎         | 4/107 [00:04<02:05,  1.22s/it]Main training loop, train epoch 18.:   5%|▍         | 5/107 [00:06<02:05,  1.23s/it]Main training loop, train epoch 18.:   6%|▌         | 6/107 [00:07<02:04,  1.23s/it]Main training loop, train epoch 18.:   7%|▋         | 7/107 [00:08<02:03,  1.23s/it]Main training loop, train epoch 18.:   7%|▋         | 8/107 [00:09<02:02,  1.24s/it]Main training loop, train epoch 18.:   8%|▊         | 9/107 [00:11<02:00,  1.23s/it]Main training loop, train epoch 18.:   9%|▉         | 10/107 [00:12<01:59,  1.23s/it]Main training loop, train epoch 18.:  10%|█         | 11/107 [00:13<01:57,  1.22s/it]Main training loop, train epoch 18.:  11%|█         | 12/107 [00:14<01:55,  1.22s/it]Main training loop, train epoch 18.:  12%|█▏        | 13/107 [00:15<01:55,  1.23s/it]Main training loop, train epoch 18.:  13%|█▎        | 14/107 [00:17<01:53,  1.22s/it]Main training loop, train epoch 18.:  14%|█▍        | 15/107 [00:18<01:51,  1.22s/it]Main training loop, train epoch 18.:  15%|█▍        | 16/107 [00:19<01:51,  1.22s/it]Main training loop, train epoch 18.:  16%|█▌        | 17/107 [00:20<01:50,  1.23s/it]Main training loop, train epoch 18.:  17%|█▋        | 18/107 [00:22<01:49,  1.23s/it]Main training loop, train epoch 18.:  18%|█▊        | 19/107 [00:23<01:47,  1.23s/it]Main training loop, train epoch 18.:  19%|█▊        | 20/107 [00:24<01:46,  1.22s/it]Main training loop, train epoch 18.:  20%|█▉        | 21/107 [00:25<01:45,  1.22s/it]Main training loop, train epoch 18.:  21%|██        | 22/107 [00:26<01:44,  1.23s/it]Main training loop, train epoch 18.:  21%|██▏       | 23/107 [00:28<01:42,  1.23s/it]Main training loop, train epoch 18.:  22%|██▏       | 24/107 [00:29<01:41,  1.22s/it]Main training loop, train epoch 18.:  23%|██▎       | 25/107 [00:30<01:40,  1.22s/it]Main training loop, train epoch 18.:  24%|██▍       | 26/107 [00:31<01:38,  1.22s/it]Main training loop, train epoch 18.:  25%|██▌       | 27/107 [00:33<01:38,  1.23s/it]Main training loop, train epoch 18.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Main training loop, train epoch 18.:  27%|██▋       | 29/107 [00:35<01:36,  1.23s/it]Main training loop, train epoch 18.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 18.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Main training loop, train epoch 18.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 18.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Main training loop, train epoch 18.:  32%|███▏      | 34/107 [00:41<01:30,  1.24s/it]Main training loop, train epoch 18.:  33%|███▎      | 35/107 [00:42<01:28,  1.24s/it]Main training loop, train epoch 18.:  34%|███▎      | 36/107 [00:44<01:27,  1.23s/it]Main training loop, train epoch 18.:  35%|███▍      | 37/107 [00:45<01:25,  1.23s/it]Main training loop, train epoch 18.:  36%|███▌      | 38/107 [00:46<01:24,  1.23s/it]Main training loop, train epoch 18.:  36%|███▋      | 39/107 [00:47<01:23,  1.22s/it]Main training loop, train epoch 18.:  37%|███▋      | 40/107 [00:49<01:21,  1.22s/it]Main training loop, train epoch 18.:  38%|███▊      | 41/107 [00:50<01:20,  1.22s/it]Main training loop, train epoch 18.:  39%|███▉      | 42/107 [00:51<01:19,  1.22s/it]Main training loop, train epoch 18.:  40%|████      | 43/107 [00:52<01:18,  1.22s/it]Main training loop, train epoch 18.:  41%|████      | 44/107 [00:53<01:16,  1.22s/it]Main training loop, train epoch 18.:  42%|████▏     | 45/107 [00:55<01:15,  1.22s/it]Main training loop, train epoch 18.:  43%|████▎     | 46/107 [00:56<01:14,  1.22s/it]Main training loop, train epoch 18.:  44%|████▍     | 47/107 [00:57<01:13,  1.23s/it]Main training loop, train epoch 18.:  45%|████▍     | 48/107 [00:58<01:12,  1.22s/it]Main training loop, train epoch 18.:  46%|████▌     | 49/107 [01:00<01:10,  1.22s/it]Main training loop, train epoch 18.:  47%|████▋     | 50/107 [01:01<01:09,  1.21s/it]Main training loop, train epoch 18.:  48%|████▊     | 51/107 [01:02<01:08,  1.22s/it]Main training loop, train epoch 18.:  49%|████▊     | 52/107 [01:03<01:07,  1.22s/it]Main training loop, train epoch 18.:  50%|████▉     | 53/107 [01:04<01:06,  1.23s/it]Main training loop, train epoch 18.:  50%|█████     | 54/107 [01:06<01:05,  1.23s/it]Main training loop, train epoch 18.:  51%|█████▏    | 55/107 [01:07<01:04,  1.23s/it]Main training loop, train epoch 18.:  52%|█████▏    | 56/107 [01:08<01:02,  1.23s/it]Main training loop, train epoch 18.:  53%|█████▎    | 57/107 [01:09<01:01,  1.23s/it]Main training loop, train epoch 18.:  54%|█████▍    | 58/107 [01:11<01:00,  1.23s/it]Main training loop, train epoch 18.:  55%|█████▌    | 59/107 [01:12<00:58,  1.23s/it]Main training loop, train epoch 18.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Main training loop, train epoch 18.:  57%|█████▋    | 61/107 [01:14<00:56,  1.23s/it]Main training loop, train epoch 18.:  58%|█████▊    | 62/107 [01:16<00:55,  1.23s/it]Main training loop, train epoch 18.:  59%|█████▉    | 63/107 [01:17<00:54,  1.23s/it]Main training loop, train epoch 18.:  60%|█████▉    | 64/107 [01:18<00:53,  1.24s/it]Main training loop, train epoch 18.:  61%|██████    | 65/107 [01:19<00:52,  1.24s/it]Main training loop, train epoch 18.:  62%|██████▏   | 66/107 [01:20<00:50,  1.23s/it]Main training loop, train epoch 18.:  63%|██████▎   | 67/107 [01:22<00:49,  1.23s/it]Main training loop, train epoch 18.:  64%|██████▎   | 68/107 [01:23<00:47,  1.23s/it]Main training loop, train epoch 18.:  64%|██████▍   | 69/107 [01:24<00:46,  1.23s/it]Main training loop, train epoch 18.:  65%|██████▌   | 70/107 [01:25<00:45,  1.23s/it]Main training loop, train epoch 18.:  66%|██████▋   | 71/107 [01:27<00:44,  1.23s/it]Main training loop, train epoch 18.:  67%|██████▋   | 72/107 [01:28<00:43,  1.23s/it]Main training loop, train epoch 18.:  68%|██████▊   | 73/107 [01:29<00:41,  1.23s/it]Main training loop, train epoch 18.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 18.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Main training loop, train epoch 18.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 18.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 18.:  73%|███████▎  | 78/107 [01:35<00:35,  1.22s/it]Main training loop, train epoch 18.:  74%|███████▍  | 79/107 [01:36<00:34,  1.23s/it]Main training loop, train epoch 18.:  75%|███████▍  | 80/107 [01:38<00:33,  1.23s/it]Main training loop, train epoch 18.:  76%|███████▌  | 81/107 [01:39<00:31,  1.22s/it]Main training loop, train epoch 18.:  77%|███████▋  | 82/107 [01:40<00:30,  1.23s/it]Main training loop, train epoch 18.:  78%|███████▊  | 83/107 [01:41<00:29,  1.22s/it]Main training loop, train epoch 18.:  79%|███████▊  | 84/107 [01:43<00:28,  1.23s/it]Main training loop, train epoch 18.:  79%|███████▉  | 85/107 [01:44<00:27,  1.24s/it]Main training loop, train epoch 18.:  80%|████████  | 86/107 [01:45<00:26,  1.24s/it]Main training loop, train epoch 18.:  81%|████████▏ | 87/107 [01:46<00:24,  1.24s/it]Main training loop, train epoch 18.:  82%|████████▏ | 88/107 [01:48<00:23,  1.24s/it]Main training loop, train epoch 18.:  83%|████████▎ | 89/107 [01:49<00:22,  1.24s/it]Main training loop, train epoch 18.:  84%|████████▍ | 90/107 [01:50<00:21,  1.24s/it]Main training loop, train epoch 18.:  85%|████████▌ | 91/107 [01:51<00:19,  1.24s/it]Main training loop, train epoch 18.:  86%|████████▌ | 92/107 [01:52<00:18,  1.23s/it]Main training loop, train epoch 18.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Main training loop, train epoch 18.:  88%|████████▊ | 94/107 [01:55<00:15,  1.23s/it]Main training loop, train epoch 18.:  89%|████████▉ | 95/107 [01:56<00:14,  1.23s/it]Main training loop, train epoch 18.:  90%|████████▉ | 96/107 [01:57<00:13,  1.23s/it]Main training loop, train epoch 18.:  91%|█████████ | 97/107 [01:59<00:12,  1.23s/it]Main training loop, train epoch 18.:  92%|█████████▏| 98/107 [02:00<00:11,  1.23s/it]Main training loop, train epoch 18.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 18.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Main training loop, train epoch 18.:  94%|█████████▍| 101/107 [02:04<00:07,  1.23s/it]Main training loop, train epoch 18.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 18.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 18.:  97%|█████████▋| 104/107 [02:07<00:03,  1.22s/it]Main training loop, train epoch 18.:  98%|█████████▊| 105/107 [02:08<00:02,  1.23s/it]Main training loop, train epoch 18.:  99%|█████████▉| 106/107 [02:10<00:01,  1.24s/it]Main training loop, train epoch 18.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]Main training loop, train epoch 18.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:28:45,820] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_18 is about to be saved!
[2025-06-25 08:28:45,851] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,851] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,851] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,851] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,853] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,853] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_18/mp_rank_00_model_states.pt
[2025-06-25 08:28:45,853] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,853] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_18/mp_rank_00_model_states.pt...
[2025-06-25 08:28:45,853] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,853] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,853] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,853] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,855] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,855] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,855] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,855] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,855] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,856] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,856] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,856] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:45,856] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
[2025-06-25 08:28:47,966] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_18/mp_rank_00_model_states.pt.
[2025-06-25 08:28:47,967] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_18 is ready now!
Main training loop, train epoch 19.:   0%|          | 0/107 [00:00<?, ?it/s]Main training loop, train epoch 19.:   1%|          | 1/107 [00:01<02:14,  1.26s/it]Main training loop, train epoch 19.:   2%|▏         | 2/107 [00:02<02:10,  1.24s/it]Main training loop, train epoch 19.:   3%|▎         | 3/107 [00:03<02:09,  1.24s/it]Main training loop, train epoch 19.:   4%|▎         | 4/107 [00:04<02:07,  1.24s/it]Main training loop, train epoch 19.:   5%|▍         | 5/107 [00:06<02:06,  1.24s/it]Main training loop, train epoch 19.:   6%|▌         | 6/107 [00:07<02:05,  1.24s/it]Main training loop, train epoch 19.:   7%|▋         | 7/107 [00:08<02:04,  1.24s/it]Main training loop, train epoch 19.:   7%|▋         | 8/107 [00:09<02:02,  1.24s/it]Main training loop, train epoch 19.:   8%|▊         | 9/107 [00:11<02:01,  1.24s/it]Main training loop, train epoch 19.:   9%|▉         | 10/107 [00:12<01:59,  1.24s/it]Main training loop, train epoch 19.:  10%|█         | 11/107 [00:13<01:58,  1.23s/it]Main training loop, train epoch 19.:  11%|█         | 12/107 [00:14<01:56,  1.22s/it]Main training loop, train epoch 19.:  12%|█▏        | 13/107 [00:16<01:54,  1.22s/it]Main training loop, train epoch 19.:  13%|█▎        | 14/107 [00:17<01:54,  1.23s/it]Main training loop, train epoch 19.:  14%|█▍        | 15/107 [00:18<01:52,  1.22s/it]Main training loop, train epoch 19.:  15%|█▍        | 16/107 [00:19<01:50,  1.22s/it]Main training loop, train epoch 19.:  16%|█▌        | 17/107 [00:20<01:49,  1.22s/it]Main training loop, train epoch 19.:  17%|█▋        | 18/107 [00:22<01:48,  1.22s/it]Main training loop, train epoch 19.:  18%|█▊        | 19/107 [00:23<01:47,  1.22s/it]Main training loop, train epoch 19.:  19%|█▊        | 20/107 [00:24<01:45,  1.22s/it]Main training loop, train epoch 19.:  20%|█▉        | 21/107 [00:25<01:45,  1.22s/it]Main training loop, train epoch 19.:  21%|██        | 22/107 [00:27<01:44,  1.22s/it]Main training loop, train epoch 19.:  21%|██▏       | 23/107 [00:28<01:42,  1.22s/it]Main training loop, train epoch 19.:  22%|██▏       | 24/107 [00:29<01:42,  1.23s/it]Main training loop, train epoch 19.:  23%|██▎       | 25/107 [00:30<01:40,  1.23s/it]Main training loop, train epoch 19.:  24%|██▍       | 26/107 [00:31<01:39,  1.23s/it]Main training loop, train epoch 19.:  25%|██▌       | 27/107 [00:33<01:38,  1.24s/it]Main training loop, train epoch 19.:  26%|██▌       | 28/107 [00:34<01:37,  1.23s/it]Main training loop, train epoch 19.:  27%|██▋       | 29/107 [00:35<01:36,  1.23s/it]Main training loop, train epoch 19.:  28%|██▊       | 30/107 [00:36<01:34,  1.23s/it]Main training loop, train epoch 19.:  29%|██▉       | 31/107 [00:38<01:33,  1.23s/it]Main training loop, train epoch 19.:  30%|██▉       | 32/107 [00:39<01:32,  1.23s/it]Main training loop, train epoch 19.:  31%|███       | 33/107 [00:40<01:31,  1.23s/it]Main training loop, train epoch 19.:  32%|███▏      | 34/107 [00:41<01:30,  1.24s/it]Main training loop, train epoch 19.:  33%|███▎      | 35/107 [00:43<01:29,  1.24s/it]Main training loop, train epoch 19.:  34%|███▎      | 36/107 [00:44<01:27,  1.24s/it]Main training loop, train epoch 19.:  35%|███▍      | 37/107 [00:45<01:26,  1.24s/it]Main training loop, train epoch 19.:  36%|███▌      | 38/107 [00:46<01:25,  1.23s/it]Main training loop, train epoch 19.:  36%|███▋      | 39/107 [00:48<01:24,  1.24s/it]Main training loop, train epoch 19.:  37%|███▋      | 40/107 [00:49<01:22,  1.24s/it]Main training loop, train epoch 19.:  38%|███▊      | 41/107 [00:50<01:21,  1.24s/it]Main training loop, train epoch 19.:  39%|███▉      | 42/107 [00:51<01:21,  1.25s/it]Main training loop, train epoch 19.:  40%|████      | 43/107 [00:53<01:19,  1.25s/it]Main training loop, train epoch 19.:  41%|████      | 44/107 [00:54<01:17,  1.24s/it]Main training loop, train epoch 19.:  42%|████▏     | 45/107 [00:55<01:16,  1.24s/it]Main training loop, train epoch 19.:  43%|████▎     | 46/107 [00:56<01:15,  1.23s/it]Main training loop, train epoch 19.:  44%|████▍     | 47/107 [00:57<01:13,  1.22s/it]Main training loop, train epoch 19.:  45%|████▍     | 48/107 [00:59<01:12,  1.23s/it]Main training loop, train epoch 19.:  46%|████▌     | 49/107 [01:00<01:11,  1.23s/it]Main training loop, train epoch 19.:  47%|████▋     | 50/107 [01:01<01:10,  1.23s/it]Main training loop, train epoch 19.:  48%|████▊     | 51/107 [01:02<01:08,  1.23s/it]Main training loop, train epoch 19.:  49%|████▊     | 52/107 [01:04<01:07,  1.22s/it]Main training loop, train epoch 19.:  50%|████▉     | 53/107 [01:05<01:06,  1.23s/it]Main training loop, train epoch 19.:  50%|█████     | 54/107 [01:06<01:04,  1.23s/it]Main training loop, train epoch 19.:  51%|█████▏    | 55/107 [01:07<01:03,  1.22s/it]Main training loop, train epoch 19.:  52%|█████▏    | 56/107 [01:08<01:02,  1.22s/it]Main training loop, train epoch 19.:  53%|█████▎    | 57/107 [01:10<01:01,  1.22s/it]Main training loop, train epoch 19.:  54%|█████▍    | 58/107 [01:11<00:59,  1.22s/it]Main training loop, train epoch 19.:  55%|█████▌    | 59/107 [01:12<00:58,  1.22s/it]Main training loop, train epoch 19.:  56%|█████▌    | 60/107 [01:13<00:57,  1.22s/it]Main training loop, train epoch 19.:  57%|█████▋    | 61/107 [01:15<00:56,  1.23s/it]Main training loop, train epoch 19.:  58%|█████▊    | 62/107 [01:16<00:55,  1.22s/it]Main training loop, train epoch 19.:  59%|█████▉    | 63/107 [01:17<00:54,  1.23s/it]Main training loop, train epoch 19.:  60%|█████▉    | 64/107 [01:18<00:53,  1.23s/it]Main training loop, train epoch 19.:  61%|██████    | 65/107 [01:20<00:51,  1.24s/it]Main training loop, train epoch 19.:  62%|██████▏   | 66/107 [01:21<00:50,  1.23s/it]Main training loop, train epoch 19.:  63%|██████▎   | 67/107 [01:22<00:48,  1.22s/it]Main training loop, train epoch 19.:  64%|██████▎   | 68/107 [01:23<00:47,  1.22s/it]Main training loop, train epoch 19.:  64%|██████▍   | 69/107 [01:24<00:46,  1.22s/it]Main training loop, train epoch 19.:  65%|██████▌   | 70/107 [01:26<00:45,  1.22s/it]Main training loop, train epoch 19.:  66%|██████▋   | 71/107 [01:27<00:43,  1.22s/it]Main training loop, train epoch 19.:  67%|██████▋   | 72/107 [01:28<00:42,  1.22s/it]Main training loop, train epoch 19.:  68%|██████▊   | 73/107 [01:29<00:41,  1.22s/it]Main training loop, train epoch 19.:  69%|██████▉   | 74/107 [01:30<00:40,  1.23s/it]Main training loop, train epoch 19.:  70%|███████   | 75/107 [01:32<00:39,  1.23s/it]Main training loop, train epoch 19.:  71%|███████   | 76/107 [01:33<00:38,  1.23s/it]Main training loop, train epoch 19.:  72%|███████▏  | 77/107 [01:34<00:36,  1.22s/it]Main training loop, train epoch 19.:  73%|███████▎  | 78/107 [01:35<00:35,  1.23s/it]Main training loop, train epoch 19.:  74%|███████▍  | 79/107 [01:37<00:34,  1.23s/it]Main training loop, train epoch 19.:  75%|███████▍  | 80/107 [01:38<00:33,  1.24s/it]Main training loop, train epoch 19.:  76%|███████▌  | 81/107 [01:39<00:33,  1.27s/it]Main training loop, train epoch 19.:  77%|███████▋  | 82/107 [01:40<00:31,  1.26s/it]Main training loop, train epoch 19.:  78%|███████▊  | 83/107 [01:42<00:29,  1.25s/it]Main training loop, train epoch 19.:  79%|███████▊  | 84/107 [01:43<00:28,  1.24s/it]Main training loop, train epoch 19.:  79%|███████▉  | 85/107 [01:44<00:27,  1.24s/it]Main training loop, train epoch 19.:  80%|████████  | 86/107 [01:45<00:25,  1.23s/it]Main training loop, train epoch 19.:  81%|████████▏ | 87/107 [01:47<00:24,  1.23s/it]Main training loop, train epoch 19.:  82%|████████▏ | 88/107 [01:48<00:23,  1.22s/it]Main training loop, train epoch 19.:  83%|████████▎ | 89/107 [01:49<00:22,  1.22s/it]Main training loop, train epoch 19.:  84%|████████▍ | 90/107 [01:50<00:20,  1.23s/it]Main training loop, train epoch 19.:  85%|████████▌ | 91/107 [01:51<00:19,  1.23s/it]Main training loop, train epoch 19.:  86%|████████▌ | 92/107 [01:53<00:18,  1.22s/it]Main training loop, train epoch 19.:  87%|████████▋ | 93/107 [01:54<00:17,  1.23s/it]Main training loop, train epoch 19.:  88%|████████▊ | 94/107 [01:55<00:15,  1.22s/it]Main training loop, train epoch 19.:  89%|████████▉ | 95/107 [01:56<00:14,  1.21s/it]Main training loop, train epoch 19.:  90%|████████▉ | 96/107 [01:58<00:13,  1.22s/it]Main training loop, train epoch 19.:  91%|█████████ | 97/107 [01:59<00:12,  1.22s/it]Main training loop, train epoch 19.:  92%|█████████▏| 98/107 [02:00<00:10,  1.22s/it]Main training loop, train epoch 19.:  93%|█████████▎| 99/107 [02:01<00:09,  1.23s/it]Main training loop, train epoch 19.:  93%|█████████▎| 100/107 [02:02<00:08,  1.23s/it]Main training loop, train epoch 19.:  94%|█████████▍| 101/107 [02:04<00:07,  1.24s/it]Main training loop, train epoch 19.:  95%|█████████▌| 102/107 [02:05<00:06,  1.23s/it]Main training loop, train epoch 19.:  96%|█████████▋| 103/107 [02:06<00:04,  1.23s/it]Main training loop, train epoch 19.:  97%|█████████▋| 104/107 [02:07<00:03,  1.23s/it]Main training loop, train epoch 19.:  98%|█████████▊| 105/107 [02:09<00:02,  1.22s/it]Main training loop, train epoch 19.:  99%|█████████▉| 106/107 [02:10<00:01,  1.23s/it]Main training loop, train epoch 19.: 100%|██████████| 107/107 [02:11<00:00,  1.22s/it]Main training loop, train epoch 19.: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it]
[2025-06-25 08:30:59,600] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint epoch_19 is about to be saved!
[2025-06-25 08:30:59,676] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,676] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,676] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,676] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,677] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,679] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,679] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_19/mp_rank_00_model_states.pt
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,679] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,679] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_19/mp_rank_00_model_states.pt...
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,679] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,679] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,679] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,679] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,678] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:30:59,684] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
[2025-06-25 08:31:01,782] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /eagle/ParaLLMs/weather_load_forecasting/results/exp14_illi_tfm_parallel_redo/checkpoint/epoch_19/mp_rank_00_model_states.pt.
[2025-06-25 08:31:01,783] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint epoch_19 is ready now!
Testing on epoch 19.:   0%|          | 0/11 [00:00<?, ?it/s]Testing on epoch 19.:   9%|▉         | 1/11 [00:00<00:05,  1.72it/s]Testing on epoch 19.:  18%|█▊        | 2/11 [00:01<00:05,  1.69it/s]Testing on epoch 19.:  27%|██▋       | 3/11 [00:01<00:04,  1.67it/s]Testing on epoch 19.:  36%|███▋      | 4/11 [00:02<00:04,  1.62it/s]Testing on epoch 19.:  45%|████▌     | 5/11 [00:03<00:03,  1.59it/s]Testing on epoch 19.:  55%|█████▍    | 6/11 [00:03<00:03,  1.59it/s]Testing on epoch 19.:  64%|██████▎   | 7/11 [00:04<00:02,  1.66it/s]Testing on epoch 19.:  73%|███████▎  | 8/11 [00:04<00:01,  1.63it/s]Testing on epoch 19.:  82%|████████▏ | 9/11 [00:05<00:01,  1.62it/s]Testing on epoch 19.:  91%|█████████ | 10/11 [00:06<00:00,  1.67it/s]Testing on epoch 19.: 100%|██████████| 11/11 [00:06<00:00,  1.65it/s]Testing on epoch 19.: 100%|██████████| 11/11 [00:06<00:00,  1.64it/s]
Application 45788fc1 resources: utime=92359s stime=100112s maxrss=5745664KB inblock=24377262 oublock=64650936 minflt=32400001 majflt=87909 nvcsw=16354920 nivcsw=12050268
Training completed
